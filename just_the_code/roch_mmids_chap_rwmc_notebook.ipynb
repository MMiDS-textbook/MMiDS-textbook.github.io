{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c99ea23e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-cell",
     "colab-keep"
    ]
   },
   "source": [
    "***\n",
    "\n",
    "*Course:* [Math 535](https://people.math.wisc.edu/~roch/mmids/) - Mathematical Methods in Data Science (MMiDS)  \n",
    "*Chapter:* 5-Random walks on graphs and Markov chains  \n",
    "*Author:* [Sebastien Roch](https://people.math.wisc.edu/~roch/), Department of Mathematics, University of Wisconsin-Madison  \n",
    "*Updated:* Jan 20, 2024   \n",
    "*Copyright:* &copy; 2024 Sebastien Roch\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8db3c4",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# You will need the files:\n",
    "#     * mmids.py\n",
    "#     * mathworld-adjacency.csv\n",
    "#     * mathworld-titles.csv\n",
    "# from https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/tree/main/utils\n",
    "#\n",
    "# IF RUNNING ON GOOGLE COLAB (RECOMMENDED):\n",
    "# \"Upload to session storage\" from the Files tab on the left\n",
    "# Alternative instructions: https://colab.research.google.com/notebooks/io.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc27862",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# PYTHON 3\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import mmids\n",
    "seed = 535\n",
    "rng = np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aa615d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "## Motivating example: discovering relevant mathematical topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dff188b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "A common task in network analysis is to identify \"central\" vertices in a graph. Centrality is a vague concept. It can be defined in many different ways depending on the context and the type of network. Quoting from [Wikipedia](https://en.wikipedia.org/wiki/Centrality):\n",
    "\n",
    "> In graph theory and network analysis, indicators of centrality assign numbers or rankings to nodes within a graph corresponding to their network position. Applications include identifying the most influential person(s) in a social network, key infrastructure nodes in the Internet or urban networks, super-spreaders of disease, and brain networks. [...] Centrality indices are answers to the question \"What characterizes an important vertex?\" The answer is given in terms of a real-valued function on the vertices of a graph, where the values produced are expected to provide a ranking which identifies the most important nodes. The word \"importance\" has a wide number of meanings, leading to many different definitions of centrality. \n",
    "\n",
    "In an undirected graph, a natural approach is to look at the degree of a vertex as a measure of its importance (also referred to as degree centrality). But it is hardly the only one. One could for instance look at the average distance to all other nodes (its reciprocal is the [closeness centrality](https://en.wikipedia.org/wiki/Closeness_centrality)) or at the number of shortest paths between pairs of vertices going through the vertex (known as [betweenness centrality](https://en.wikipedia.org/wiki/Betweenness_centrality)). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2d4b3c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "What if the graph is directed? Things are somewhat more complicated there. For instance, there is now the in-degree as well as the out-degree. \n",
    "\n",
    "Let us look at a particular example of practical importance, the World Wide Web (from now on, the Web). In this case, the vertices are webpages and a directed edge from $u$ to $v$ indicates a hyperlink from page $u$ to page $v$. The Web is much too large to analyze here. Instead, we will consider a tiny (but still interesting!) subset of it, the pages of [Wolfram's MathWorld](https://mathworld.wolfram.com), a wonderful mathematics resource. \n",
    "\n",
    "Each page of MathWorld concerns a particular mathematical concept, e.g., [scale-free network](https://mathworld.wolfram.com/Scale-FreeNetwork.html). A definition and notable properties are described. Importantly for us, in a section entitled \"SEE ALSO\", other related mathematical concepts are listed with a link to their MathWorld page. In the case of scale-free networks, the [small world network](https://mathworld.wolfram.com/SmallWorldNetwork.html) topic is referenced, among others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdccb302",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The resulting directed graph is available through the [NetSet](https://netset.telecom-paris.fr/index.html) datasets and can be downloaded [here](https://netset.telecom-paris.fr/pages/mathworld.html). We load it now. For convenience, we have reformatted it into the files `mathworld-adjacency.csv` and `mathworld-titles.csv`, which are available on the [GitHub of the book](https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/tree/main/utils/datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096874e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df_edges = pd.read_csv('mathworld-adjacency.csv')\n",
    "df_edges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edb0a53",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "It consists in a list of directed edges. For example, the first one is an edge from vertex `0` to vertex `2`. The second one is from `1` to `47` and so on. \n",
    "\n",
    "There is a total of $49069$ edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aedc84",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df_edges.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcb0669",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The second file contains the titles of the pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c21e22c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df_titles = pd.read_csv('mathworld-titles.csv')\n",
    "df_titles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac807f2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "So the first edge above is from `Alexander's Horned Sphere` to `Antoine's Horned Sphere`. That is, the [latter](https://mathworld.wolfram.com/AntoinesHornedSphere.html) is listed in the \"SEE ALSO\" section of the [former](https://mathworld.wolfram.com/AlexandersHornedSphere.html). \n",
    "\n",
    "There are $12362$ topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17103108",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df_titles.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e487e5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We construct the graph by adding the edges one by one. We first convert `df_edges` into a Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb5639a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "edgelist = df_edges[['from','to']].to_numpy()\n",
    "print(edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcad0e73",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n = 12362\n",
    "G = nx.empty_graph(n, create_using=nx.DiGraph)\n",
    "for i in range(edgelist.shape[0]):\n",
    "    G.add_edge(edgelist[i,0], edgelist[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb497c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "G.in_degree(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872d9255",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "while that of `Antoine's Horned Sphere` is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721c4856",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "G.in_degree(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bfc7ab",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "suggesting that the former is more central than the latter, at least in the sense that it is referenced more often.\n",
    "\n",
    "But is that the right measure? Consider the following: `Antoine's Horned Sphere` receives only one reference, but it is from a seemingly relatively important vertex, `Alexander's Horned Sphere`. How can one take this into account in quantifying its importance in the network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98be67b9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We will come back to this question later in this chapter. To hint at things to come, it will turn out that \"exploring the graph at random\" provides a powerful perspective on centrality.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32483bca",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\newcommand{\\P}{\\mathbb{P}}$ $\\newcommand{\\E}{\\mathbb{E}}$ $\\newcommand{\\S}{\\mathcal{S}}$ $\\newcommand{\\indep}{\\perp\\!\\!\\!\\perp}$    $\\newcommand{\\bmu}{\\boldsymbol{\\mu}}$ $\\newcommand{\\bpi}{\\boldsymbol{\\pi}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d099f7d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "## Elements of finite Markov chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cd02b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**EXAMPLE:** **(Random Walk on the Petersen Graph)** Let $G = (V,E)$ be the Petersen graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681cdc94",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "G_petersen = nx.petersen_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bc19ad",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "nx.draw_networkx(G_petersen, pos=nx.circular_layout(G_petersen), labels={i: i+1 for i in range(10)}, \n",
    "                 node_size=600, node_color='black', font_size=16, font_color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c640944",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Each vertex $i$ has degree $3$, that is, it has three neighbors which we denote $v_{i,1}, v_{i,2}, v_{i,3}$ in some arbitrary order. For instance, denoting the vertices by $1,\\ldots, 10$ as above, vertex $9$ has neighbors $v_{9,1} = 4, v_{9,2} = 6, v_{9,3} = 7$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723385b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We consider the following random walk on $G$. We start at $X_0 = 1$. Then, for each $t\\geq 0$, we let $X_{t+1}$ be a uniformly chosen neighbor of $X_t$, independently of the previous history. That is, we jump at random from neighbor to neighbor. Formally, fix $X_0 = 1$ and let $(Z_t)_{t \\geq 0}$ be an i.i.d. sequence of random variables taking values in $\\{1,2,3\\}$ satisfying\n",
    "\n",
    "$$\n",
    "\\mathbb{P}[Z_t = 1] = \\mathbb{P}[Z_t = 2] = \\mathbb{P}[Z_t = 3] = 1/3.\n",
    "$$\n",
    "\n",
    "Then define, for all $t \\geq 0$,\n",
    "$\n",
    "X_{t+1}\n",
    "= f(X_t, Z_t)\n",
    "= v_{i,Z_t}\n",
    "$\n",
    "if $X_t = v_i$.\n",
    "\n",
    "By an argument similar to the previous example, $(X_t)_{t \\geq 0}$ is a Markov chain.\n",
    "Also as in the previous example, one can pick $X_0$ according to an initial distribution, independently from the sequence $(Z_t)_{t \\geq 0}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521efed7",
   "metadata": {
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\lhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf99bbf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**EXAMPLE:** **(Random Walk on the Petersen Graph, continued)** Consider again the random walk on the Petersen graph $G = (V,E)$. We number the vertices $1, 2,\\ldots, 10$. To compute the transition matrix, we list for each vertex its neighbors and put the value $1/3$ in the corresponding columns. For instance, vertex $1$ has neighbors $2$, $5$ and $6$, so row $1$ has $1/3$ in columns $2$, $5$, and $6$. And so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5280ee2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "nx.draw_networkx(G_petersen, pos=nx.circular_layout(G_petersen), labels={i: i+1 for i in range(10)}, \n",
    "                 node_size=600, node_color='black', font_size=16, font_color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87db9218",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We get:\n",
    "\n",
    "$$\n",
    "P = \\begin{pmatrix}\n",
    "0 & 1/3 & 0 & 0 & 1/3 & 1/3 & 0 & 0 & 0 & 0\\\\\n",
    "1/3 & 0 & 1/3 & 0 & 0 & 0 & 1/3 & 0 & 0 & 0\\\\\n",
    "0 & 1/3 & 0 & 1/3 & 0 & 0 & 0 & 1/3 & 0 & 0\\\\\n",
    "0 & 0 & 1/3 & 0 & 1/3 & 0 & 0 & 0 & 1/3 & 0\\\\\n",
    "1/3 & 0 & 0 & 1/3 & 0 & 0 & 0 & 0 & 0 & 1/3\\\\\n",
    "1/3 & 0 & 0 & 0 & 0 & 0 & 0 & 1/3 & 1/3 & 0\\\\\n",
    "0 & 1/3 & 0 & 0 & 0 & 0 & 0 & 0 & 1/3 & 1/3\\\\\n",
    "0 & 0 & 1/3 & 0 & 0 & 1/3 & 0 & 0 & 0 & 1/3\\\\\n",
    "0 & 0 & 0 & 1/3 & 0 & 1/3 & 1/3 & 0 & 0 & 0\\\\\n",
    "0 & 0 & 0 & 0 & 1/3 & 0 & 1/3 & 1/3 & 0 & 0\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf48098",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We have already encountered a matrix that encodes the neighbors of each vertex, the adjacency matrix. Here we can recover the transition matrix by multiplying the adjacency matrix by $1/3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26868c3b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "A_petersen = nx.adjacency_matrix(G_petersen).toarray()\n",
    "P_petersen = (1/3) * A_petersen\n",
    "print(P_petersen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330f7bb7",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\lhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203da6f1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**EXAMPLE:** **(Robot Vacuum, continued)** Returning to our *Robot Vacuum Example*, the transition graph of the chain can be obtained by thinking of $P$ as the weighted adjacency matrix of the transition graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0144b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "P_robot = np.array([\n",
    "[0, 0.8, 0, 0.2, 0, 0, 0, 0, 0],\n",
    "[0.3, 0, 0.2, 0, 0, 0.5, 0, 0, 0],\n",
    "[0, 0.6, 0, 0, 0, 0.4, 0, 0, 0],\n",
    "[0.1, 0.1, 0, 0, 0.8, 0, 0, 0, 0],\n",
    "[0, 0, 0, 0.25, 0, 0, 0.75, 0, 0],\n",
    "[0, 0.15, 0.15, 0, 0, 0, 0, 0.35, 0.35],\n",
    "[0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "[0, 0, 0, 0, 0.3, 0.4, 0.2, 0, 0.1],\n",
    "[0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
    "]\n",
    ")\n",
    "print(P_robot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509460bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We define a graph from its adjancency matrix. See [`networkx.from_numpy_array()`](https://networkx.org/documentation/stable/reference/generated/networkx.convert_matrix.from_numpy_array.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed22cb6e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "G_robot = nx.from_numpy_array(P_robot, create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d9abdc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Drawing edge weights on a directed graph in a readable fashion is not straighforward. We will not do this here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc7c9d0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "n_robot = P_robot.shape[0]\n",
    "nx.draw_networkx(G_robot, pos=nx.circular_layout(G_robot), \n",
    "                 labels={i: i+1 for i in range(n_robot)}, \n",
    "                 node_size=600, node_color='black', font_size=16, font_color='white', \n",
    "                 connectionstyle='arc3, rad = 0.2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eeda13",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\lhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052a32a0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**NUMERICAL CORNER:** Once we have specified a transition matrix (and an initial distribution), we can simulate the corresponding Markov chain. This is useful to compute (approximately) probabilities of complex events through the law of large numbers. Here is some code to generate one sample path up to some given time $T$. We assume that the state space is $[n]$. We use [`rng.choice`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.choice.html) to generate each transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8868dd5",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "rng = default_rng(535)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e81d2c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def SamplePath(mu, P, T):\n",
    "    n = mu.shape[0] # size of state space\n",
    "    X = np.zeros(T+1) # initialization of sampe path\n",
    "    for i in range(T+1):\n",
    "        if i == 0: # initial distribution\n",
    "            X[i] = rng.choice(a=np.arange(start=1,stop=n+1),p=mu)\n",
    "        else: # next state is chosen from current state row\n",
    "            X[i] = rng.choice(a=np.arange(start=1,stop=n+1),p=P[int(X[i-1]-1),:])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04166b1c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Let's try with our *Robot Vacuum*. We take the initial distribution to be the uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df20cc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mu = np.ones(n_robot) / n_robot\n",
    "SamplePath(mu, P_robot, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f4cf46",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "For example, we can use a simulation to approximate the expected number of times that room $9$ is visited up to time $10$. To do this, we run the simulation a large number of times (say $1000$) and count the average number of visits to $9$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc2fa0a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "z = 9 # state of interest\n",
    "N_samples = 1000 # number of repetitions\n",
    "visits_to_z = np.zeros(N_samples) # initialization of number of visits\n",
    "\n",
    "for i in range(N_samples):\n",
    "    visits_to_z[i] = np.count_nonzero(SamplePath(mu, P_robot, 10) == z)\n",
    "\n",
    "print(np.mean(visits_to_z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d09b433",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\lhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37c9678",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\newcommand{\\P}{\\mathbb{P}}$ $\\newcommand{\\E}{\\mathbb{E}}$ $\\newcommand{\\S}{\\mathcal{S}}$ $\\newcommand{\\indep}{\\perp\\!\\!\\!\\perp}$ $\\newcommand{\\bmu}{\\boldsymbol{\\mu}}$ $\\newcommand{\\bpi}{\\boldsymbol{\\pi}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86407c89",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "## Limit behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcd639d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**EXAMPLE:** **(Robot Vacuum, continued)** Going back to the *Robot Vacuum Example*, recall the transition graph above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53b6609",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "P_robot = np.array([\n",
    "[0, 0.8, 0, 0.2, 0, 0, 0, 0, 0],\n",
    "[0.3, 0, 0.2, 0, 0, 0.5, 0, 0, 0],\n",
    "[0, 0.6, 0, 0, 0, 0.4, 0, 0, 0],\n",
    "[0.1, 0.1, 0, 0, 0.8, 0, 0, 0, 0],\n",
    "[0, 0, 0, 0.25, 0, 0, 0.75, 0, 0],\n",
    "[0, 0.15, 0.15, 0, 0, 0, 0, 0.35, 0.35],\n",
    "[0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "[0, 0, 0, 0, 0.3, 0.4, 0.2, 0, 0.1],\n",
    "[0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
    "]\n",
    ")\n",
    "G_robot = nx.from_numpy_array(P_robot, create_using=nx.DiGraph)\n",
    "n_robot = P_robot.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f733d40d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "nx.draw_networkx(G_robot, pos=nx.circular_layout(G_robot), \n",
    "                 labels={i: i+1 for i in range(n_robot)}, \n",
    "                 node_size=600, node_color='black', font_size=16, font_color='white', \n",
    "                 connectionstyle='arc3, rad = 0.2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff2eb8a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "While there is no direct edge from $4$ to $3$, we do have $4 \\to 3$ through the path $(4,2), (2,3)$. Do we have $3 \\to 4$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81600cf",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\lhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbbd59d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**EXAMPLE:** **(Two Sinks)** Consider the following random walk on a digraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36053b8c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "G_sinks = nx.DiGraph()\n",
    "\n",
    "for i in range(5):\n",
    "    G_sinks.add_node(i)\n",
    "\n",
    "G_sinks.add_edge(0, 0, weight=1/3)\n",
    "G_sinks.add_edge(0, 1, weight=1/3)\n",
    "G_sinks.add_edge(1, 1, weight=1/3)\n",
    "G_sinks.add_edge(1, 2, weight=1/3)\n",
    "G_sinks.add_edge(2, 2, weight=1)\n",
    "G_sinks.add_edge(3, 3, weight=1)\n",
    "G_sinks.add_edge(0, 4, weight=1/3)\n",
    "G_sinks.add_edge(1, 4, weight=1/3)\n",
    "G_sinks.add_edge(4, 3, weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a46d8ca",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "nx.draw_networkx(G_sinks, pos=nx.circular_layout(G_sinks), \n",
    "                 labels={i: i+1 for i in range(5)}, \n",
    "                 node_size=600, node_color='black', font_size=16, font_color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287ebe32",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Here we have $1 \\to 4$ (Why?). The *Communication Lemma* implies that, when started at $1$, $(X_t)_{t \\geq 0}$ visits $4$ with positive probability. But that probability is not one. Indeed we also have $1 \\to 3$ (Why?), so there is a positive probability of visiting $3$ as well. But if we do so before visiting $4$, we stay at $3$ forever hence cannot subsequently reach $4$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2400feb2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "In fact, intuitively, if we run this chain long enough we will either get stuck at $3$ or get stuck at $4$. These give rise to different stationary distributions. The transition probability is the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21981ae6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "P_sinks = nx.adjacency_matrix(G_sinks).toarray()\n",
    "print(P_sinks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531b07af",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "It is easy to check that $\\bpi = (0,0,1,0,0)$ and $\\bpi' = (0,0,0,1,0)$ are both stationary distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c5c45c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pi = np.array([0.,0.,1.,0.,0.])\n",
    "pi_prime = np.array([0.,0.,0.,1.,0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e070386",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "P_sinks.T @ pi.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f658efa9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "P_sinks.T @ pi_prime.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef253649",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "In fact, there are infinitely many stationary distributions in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b10f66e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\lhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b3c1ce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**EXAMPLE:** **(Robot Vacuum and Two Sinks, continued)** Because irreducibility is ultimately a graph-theoretic property, it is easy to check using `NetworkX`. For this, we use the function [`is_strongly_connected()`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.components.is_strongly_connected.html). Consider again the *Robot Vacuum Example*. This one turns out to be irreducible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a8020",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(nx.is_strongly_connected(G_robot))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552a8d31",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The *Two Sinks Example*, on the other hand, is not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651c6112",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(nx.is_strongly_connected(G_sinks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac78d22e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\lhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d475e4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**NUMERICAL CORNER:** In general, computing stationary distributions is not as straigthforward as in the simple example we considered above. We conclude this section with some numerical recipes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ee3afe",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Going back to the *Robot Vacuum*, finding a solution to $\\bpi P =\\bpi$ in this case is not obvious. One way to do this is to note that, taking transposes, this condition is equivalent to $P^T \\bpi^T = \\bpi^T$. That is, $\\bpi^T$ is an eigenvector of $P^T$ with eigenvalue $1$. (Or, as we noted previously, the row vector $\\bpi$ is a left eigenvector of $P$ with eigenvalue $1$.) It must also satisfy $\\bpi \\geq 0$ with at least one entry non-zero. Here, we use NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e2b5a1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "w, v = LA.eig(P_robot.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73beb968",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The first eigenvalue is approximately $1$, as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f9891c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2250f211",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The corresponding eigenvector is approximately non-negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a8759e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(v[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b17668",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "To obtain a stationary distribution, we remove the imaginary part and normalize it to sum to $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c041c0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pi_robot = np.real(v[:,0]) / np.sum(np.real(v[:,0]))\n",
    "print(pi_robot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91d3ed2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Alternatively, we can solve the linear system\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^n \\pi_i p_{i,j} = \\pi_j, \\qquad \\forall j \\in [n].\n",
    "$$\n",
    "\n",
    "It turns out that the last equation is a linear combination over the other equations (see *Exercise 3.48*), so we remove it and replace it instead with the condition $\\sum_{i=1}^n \\pi_i = 1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9160de1b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The left-hand side of the resulting linear system is (after taking the transpose to work with column vectors):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06063b31",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "A = np.copy(P_robot.T) - np.diag(np.ones(n_robot))\n",
    "A[n_robot-1,:] = np.ones(n_robot)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10a59a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The right-hand side of the resulting linear system is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba99a59",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "b = np.concatenate((np.zeros(n_robot-1),[1.]))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3051e838",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We solve the linear system using [`numpy.linalg.solve()`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.solve.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef3f2e3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pi_robot_solve = LA.solve(A,b)\n",
    "print(pi_robot_solve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f14cca",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "This last approach is known as \"Replace an Equation\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9135c0b7",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\lhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592f6d6d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**NUMERICAL CORNER:** The *Convergence to Equilibrium Theorem* implies that we can use power iteration to compute the unique stationary diistribution in the irreducible case. We revisit the *Robot Vaccum Example*. We initialize with the uniform distribution, then repeatedly multiply by $P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983b4a70",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mu = np.ones(n_robot)/n_robot\n",
    "print(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1067a764",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mu = mu @ P_robot\n",
    "print(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3de1b1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mu = mu @ P_robot\n",
    "print(mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d26aa2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We repeat, say, $10$ more times and compare to the truth `pi_robot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d29f67",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    mu = mu @ P_robot\n",
    "print(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d445b427",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(pi_robot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92d1fc6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We see that a small number of iterations sufficed to get an accurate answer. In general, the speed of convergence depends on the eigenvalues of $P$ that are strictly smaller than $1$ in absolute value. We will derive this type of result in a special case in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f470ba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We can also check the *Ergodic Theorem* through simulation. We generate a long sample path and compare the state visit frequencies to `pi_robot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659fc9a6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mu = np.ones(n_robot) / n_robot\n",
    "path_length = 10000\n",
    "visit_freq = np.zeros(n_robot) # initialization of number of visits\n",
    "\n",
    "path = mmids.SamplePath(mu, P_robot, path_length)\n",
    "for i in range(n_robot):\n",
    "    visit_freq[i] = np.count_nonzero(path == i+1)/(path_length+1)\n",
    "\n",
    "print(visit_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b145fda9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(pi_robot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fda888",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\lhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32d8d00",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep",
     "hide-cell"
    ]
   },
   "source": [
    "$\\newcommand{\\P}{\\mathbb{P}}$ $\\newcommand{\\E}{\\mathbb{E}}$ $\\newcommand{\\S}{\\mathcal{S}}$ $\\newcommand{\\indep}{\\perp\\!\\!\\!\\perp}$ $\\newcommand{\\bmu}{\\boldsymbol{\\mu}}$ $\\newcommand{\\bpi}{\\boldsymbol{\\pi}}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e550623",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "## Random walks on graphs and application to PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1ab7ba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**EXAMPLE:** **(Random Walk on the Petersen Graph, continued)** Let $G = (V,E)$ be the Petersen graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabddb99",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "G_petersen = nx.petersen_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f43be5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "nx.draw_networkx(G_petersen, pos=nx.circular_layout(G_petersen), labels={i: i+1 for i in range(10)}, \n",
    "                 node_size=600, node_color='black', font_size=16, font_color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee10a6ae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We have shown previously that the transition matrix is\n",
    "\n",
    "$$\n",
    "P = \\begin{pmatrix}\n",
    "0 & 1/3 & 0 & 0 & 1/3 & 1/3 & 0 & 0 & 0 & 0\\\\\n",
    "1/3 & 0 & 1/3 & 0 & 0 & 0 & 1/3 & 0 & 0 & 0\\\\\n",
    "0 & 1/3 & 0 & 1/3 & 0 & 0 & 0 & 1/3 & 0 & 0\\\\\n",
    "0 & 0 & 1/3 & 0 & 1/3 & 0 & 0 & 0 & 1/3 & 0\\\\\n",
    "1/3 & 0 & 0 & 1/3 & 0 & 0 & 0 & 0 & 0 & 1/3\\\\\n",
    "1/3 & 0 & 0 & 0 & 0 & 0 & 0 & 1/3 & 1/3 & 0\\\\\n",
    "0 & 1/3 & 0 & 0 & 0 & 0 & 0 & 0 & 1/3 & 1/3\\\\\n",
    "0 & 0 & 1/3 & 0 & 0 & 1/3 & 0 & 0 & 0 & 1/3\\\\\n",
    "0 & 0 & 0 & 1/3 & 0 & 1/3 & 1/3 & 0 & 0 & 0\\\\\n",
    "0 & 0 & 0 & 0 & 1/3 & 0 & 1/3 & 1/3 & 0 & 0\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e669ea",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\lhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48777433",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**EXAMPLE:** **(A Weighted Graph)** Here is another example. Consider the following adjacency matrix on $5$ vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6805ba1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "A_ex = np.array([\n",
    "[0, 8, 0, 1, 0],\n",
    "[8, 0, 6, 1, 0],\n",
    "[0, 6, 0, 0, 7],\n",
    "[1, 1, 0, 0, 10],\n",
    "[0, 0, 7, 10, 0]\n",
    "]\n",
    ")\n",
    "print(A_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b609bfb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "It is indeed a symmetric matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638e453b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(LA.norm(A_ex.T - A_ex))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44a79b2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We define a graph from its adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16074777",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n_ex = A_ex.shape[0] # number of vertices\n",
    "G_ex = nx.from_numpy_array(A_ex) # graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243fd81d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "To draw it, we first define edge labels by creating a dictionary that assigns to each edge (as a tuple) its weight. Here `G.edges.data('weight')` (see [`G.edges`](https://networkx.org/documentation/stable/reference/classes/generated/networkx.Graph.edges.html)) iterates through the edges `(u,v)` and includes their weight as the third entry of the tuple `(u,v,w)`. Then we use the function [`networkx.draw_networkx_edge_labels()`](https://networkx.org/documentation/stable/reference/generated/networkx.drawing.nx_pylab.draw_networkx_edge_labels.html#networkx.drawing.nx_pylab.draw_networkx_edge_labels) to add the weights as edge labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb50634",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "edge_labels = {}\n",
    "for (u,v,w) in G_ex.edges.data('weight'):\n",
    "    edge_labels[(u,v)] = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e256099a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pos=nx.circular_layout(G_ex)\n",
    "nx.draw_networkx(G_ex, pos, labels={i: i+1 for i in range(n_ex)}, node_size=600, \n",
    "                 node_color='black', font_size=16, font_color='white')\n",
    "edge_labels = nx.draw_networkx_edge_labels(G_ex, pos, edge_labels=edge_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48d1f2d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The transition matrix of the random walk on this graph can be computed using the lemma above. We first compute the degree matrix, then apply the formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e718f04",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "degrees_ex = A_ex @ np.ones(n_ex)\n",
    "inv_degrees_ex = 1/ degrees_ex\n",
    "Dinv_ex = np.diag(inv_degrees_ex)\n",
    "P_ex = Dinv_ex @ A_ex\n",
    "print(P_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e3ca75",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "This is indeed a stochastic matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdf14b4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(P_ex @ np.ones(n_ex))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5270bed",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\lhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af419b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**EXAMPLE:** **(A Weighted Graph, continued)** Going back to our weighted graph example, we use the previous theorem to compute the stationary distribution. Note that the graph is indeed connected so the stationary distribution is unique. We have already computed the degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f4c9c1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(degrees_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f029e4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We compute $\\sum_{i \\in V} \\delta(i)$ next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cb08e1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "total_degrees_ex = degrees_ex @ np.ones(n_ex)\n",
    "print(total_degrees_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decb8ac1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Finally, the stationary distribution is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd7230",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pi_ex = degrees_ex / total_degrees_ex\n",
    "print(pi_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1720668c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We check stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ce7165",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(LA.norm(P_ex.T @ pi_ex - pi_ex))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f55dab",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\lhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b2dc90",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**NUMERICAL CORNER:** Here is an implementation of the PageRank algorithm. We will need a function that takes as input an adjacency matrix $A$ and returns the corresponding transition matrix $P$. Some vertices have no outgoing links. To avoid dividing by $0$, we add a self-loop to *all vertices with out-degree $0$*. We [`numpy.fill_diagonal`](https://numpy.org/doc/stable/reference/generated/numpy.fill_diagonal.html) for this purpose.\n",
    "\n",
    "Also, because the adjacency matrix and the vector of out-degrees have different shapes, we turn `out_deg` into a column vector using [`numpy.newaxis`](https://numpy.org/doc/stable/reference/constants.html#numpy.newaxis) to ensure that the division is [done one column at a time](https://numpy.org/doc/stable/user/basics.broadcasting.html#broadcastable-arrays). (There are many ways of doing this, [but some are slower than others](https://stackoverflow.com/questions/18522216/multiplying-across-in-a-numpy-array).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852f4cc7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def transition_from_adjacency(A):\n",
    "    n = A.shape[0]\n",
    "    sinks = (A @ np.ones(n)) == 0.\n",
    "    P = A.copy()\n",
    "    np.fill_diagonal(P, sinks)\n",
    "    out_deg = P @ np.ones(n)\n",
    "    P = P / out_deg[:, np.newaxis]\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294d18de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The following function adds the damping factor. Here `mu` will be the uniform distribution. It gets added (after scaling by `1-alpha`) one row at a time to `P` (again after scaling by `alpha`). This time we do not need to reshape `mu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2932774e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def add_damping(P, alpha, mu):\n",
    "    Q = alpha * P + (1-alpha) * mu\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2472f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "When computing PageRank, we take the transpose of $Q$ to turn multiplication from the left into multiplication from the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ee24d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def pagerank(A, alpha=0.85, max_iter=100):\n",
    "    n = A.shape[0]\n",
    "    mu = np.ones(n)/n\n",
    "    P = transition_from_adjacency(A)\n",
    "    Q = add_damping(P, alpha, mu)\n",
    "    v = mu\n",
    "    for _ in range(max_iter):\n",
    "        v = Q.T @ v\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a2158d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Let's try a star with edges pointing out. Along the way, we check that our functions work how we expect them to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72364ce4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n = 8\n",
    "G_outstar = nx.DiGraph()\n",
    "for i in range(1,n):\n",
    "    G_outstar.add_edge(0,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed38a027",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "nx.draw_networkx(G_outstar, \n",
    "                 labels={i: i+1 for i in range(n)}, \n",
    "                 node_size=600, node_color='black', font_size=16, font_color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f17ae9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "A_outstar = nx.adjacency_matrix(G_outstar).toarray()\n",
    "print(A_outstar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d0bd16",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "P_outstar = transition_from_adjacency(A_outstar)\n",
    "print(P_outstar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5d9837",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.85\n",
    "mu = np.ones(n)/n\n",
    "Q_outstar = add_damping(P_outstar, alpha, mu)\n",
    "print(Q_outstar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f380d822",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "While it is tempting to guess that $1$ is the most central node of the network, no edge actually points to it. In this case, the center of the star has a low PageRank value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2249ffc5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pagerank(A_outstar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629319d2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We then try a star with edges pointing in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6c565b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n = 8\n",
    "G_instar = nx.DiGraph()\n",
    "G_instar.add_node(0)\n",
    "for i in range(1,n):\n",
    "    G_instar.add_edge(i,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5b36fa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "nx.draw_networkx(G_instar,  \n",
    "                 labels={i: i+1 for i in range(n)}, \n",
    "                 node_size=600, node_color='black', font_size=16, font_color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d7d8cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "A_instar = nx.adjacency_matrix(G_instar).toarray()\n",
    "print(A_instar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aa892c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "P_instar = transition_from_adjacency(A_instar)\n",
    "print(P_instar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b85f9c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Q_instar = add_damping(P_instar, alpha, mu)\n",
    "print(Q_instar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4fba51",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "In this case, the center of the star does indeed have a high PageRank value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55498d2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pagerank(A_instar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a661cdb7",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\unlhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7744282",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**NUMERICAL CORNER:** We revisit the star example in the undirected case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0c77af",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "n = 8\n",
    "G_star = nx.Graph()\n",
    "for i in range(1,n):\n",
    "    G_star.add_edge(0,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd354a2b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "nx.draw_networkx(G_star, \n",
    "                 labels={i: i+1 for i in range(n)}, \n",
    "                 node_size=600, node_color='black', font_size=16, font_color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fd7e5c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We first compute the PageRank vector without damping. Here the random walk is periodic (Why?) so power iteration may fail (Try it!). Instead, we use a small amount of damping and increase the number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b981088c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "A_star = nx.adjacency_matrix(G_star).toarray()\n",
    "print(A_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0470186a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "pagerank(A_star, max_iter=10000, alpha=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706c6a04",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The PageRank value for the center node is indeed roughly $7$ times larger than the other ones, as can be expected from the ratio of their degrees. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29b3791",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We try again with more damping. This time the ratio of PageRank values is not quite the same as the ratio of degrees, but the center node continues to have a higher value than the other nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492b4bad",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "pagerank(A_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ed17d8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\unlhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063b3336",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**Applying PageRank to MathWorld** We load the dataset again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d5df7c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df_edges = pd.read_csv('mathworld-adjacency.csv')\n",
    "df_edges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01357f94",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The second file contains the titles of the pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafda9dd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df_titles = pd.read_csv('mathworld-titles.csv')\n",
    "df_titles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7941c78e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We construct the graph by adding the edges one by one. We first convert `df_edges` into a Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d527bb3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "edgelist = df_edges[['from','to']].to_numpy()\n",
    "print(edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faa2c3c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n = 12362\n",
    "G_mw = nx.empty_graph(n, create_using=nx.DiGraph)\n",
    "for i in range(edgelist.shape[0]):\n",
    "    G_mw.add_edge(edgelist[i,0], edgelist[i,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee41a8f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "To apply PageRank, we construct the adjacency matric of the graph. We also define a vector of title pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe50726",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "A_mw = nx.adjacency_matrix(G_mw).toarray()\n",
    "titles_mw = df_titles['title'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9475bf6c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pr_mw = pagerank(A_mw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adb7482",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We use [`numpy.argsort`](https://numpy.org/doc/stable/reference/generated/numpy.argsort.html) to identify the pages with highest scores. We apply it to `-pr_mw` to sort from the highest to lowest value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416a8d1d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "top_pages = np.argsort(-pr_mw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5b3305",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The top 25 topics are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389f8059",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "titles_mw[top_pages[:25]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb29840",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We indeed get a list of central concepts in mathematics -- including several we have encountered previously such as `Normal Distribution`, `Tree`, `Vector` or `Derivative`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95dab37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**Personalized PageRank** There is a variant of PageRank, referred to as Personalized PageRank (PPR), which aims to tailor the outcome to specific interests. This is accomplished from a simple change to the algorithm. When teleporting, rather than jumping to a uniformly random page, we instead jump to an arbitrary distribution which is meant to capture some specific interests. In the context of the web for instance, this distribution might be uniform over someone's bookmarks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602678f3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We adapt `pagerank` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4d7bc2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def ppr(A, mu, alpha=0.85, max_iter=100):\n",
    "    n = A.shape[0]\n",
    "    P = transition_from_adjacency(A)\n",
    "    Q = add_damping(P, alpha, mu)\n",
    "    v = mu\n",
    "    for _ in range(max_iter):\n",
    "        v = Q.T @ v\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c959bbb6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "To test PPR, consider the distribution concentrated on a single topic `Normal Distribution`. This is topic number `1270`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8bf485",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.argwhere(titles_mw == 'Normal Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381514b7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mu = np.zeros(n)\n",
    "mu[1270] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3af5ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We now run PPR and list the top 25 pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e14f78",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ppr_mw = ppr(A_mw, mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b306da31",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "top_pers_pages = np.argsort(-ppr_mw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c754d95f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The top 25 topics are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40454179",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "titles_mw[top_pers_pages[:25]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbacaebb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "This indeed returns various statistical concepts, particularly related to the normal dsitribution. "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
