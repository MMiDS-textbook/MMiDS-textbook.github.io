<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MMiDS 4.3: Self-Assessment Quiz</title>
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@600&family=Open+Sans&display=swap"
        rel="stylesheet">
    <style>
        body {
            font-family: 'Arial', sans-serif;
            background-color: #f5f5f5;
            color: #333;
            margin: 0;
            padding: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
        }

        #quiz-container {
            background-color: #fff;
            border-radius: 10px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            padding: 30px;
            max-width: 800px;
            width: 100%;
            margin: 20px;
        }

        h1 {
            font-family: 'Montserrat', sans-serif;
            color: #673ab7;
            text-align: center;
            margin-bottom: 30px;
        }

        .question {
            background-color: #f5f0ff;
            border: 1px solid #d1c4e9;
            border-radius: 5px;
            padding: 20px;
            margin-bottom: 30px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }

        .question p {
            margin: 0 0 15px;
            font-weight: bold;
        }

        .options {
            list-style-type: none;
            padding: 0;
        }

        .options li {
            margin-bottom: 0px;
        }

        .options li label {
            display: block;
            padding: 12px;
            background-color: #f5f0ff;
            color: #333;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s;
        }

        .options li label:hover {
            background-color: #e0d6ff;
        }

        .feedback {
            margin-top: 15px;
            display: none;
            padding: 12px;
            border-radius: 5px;
        }

        .feedback.correct {
            background-color: #e0f0e5;
            color: #155724;
            display: block;
        }

        .feedback.incorrect {
            background-color: #f8e1e3;
            color: #721c24;
            display: block;
        }

        @media (max-width: 600px) {
            #quiz-container {
                padding: 20px;
            }

            h1 {
                font-size: 24px;
                margin-bottom: 20px;
            }

            .question {
                padding: 15px;
                margin-bottom: 20px;
            }
        }
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>
    <div id="quiz-container">
        <h1>MMiDS 4.3: Self-Assessment Quiz</h1>
        <div class="question">
            <p>Let \( \alpha_1, \dots, \alpha_n \) be data points in \( \mathbb{R}^m \). What is the objective of the best approximating subspace problem?</p>
            <ul class="options">
                <li><label><input type="radio" name="q0" value="0"> a) To find a linear subspace \( Z \) of \( \mathbb{R}^m \) that minimizes the sum of the distances between the \( \alpha_i \)'s and \( Z \).</label></li>
                <li><label><input type="radio" name="q0" value="1"> b) To find a linear subspace \( Z \) of \( \mathbb{R}^m \) that minimizes the sum of the squared distances between the \( \alpha_i \)'s and their orthogonal projections onto \( Z \).</label></li>
                <li><label><input type="radio" name="q0" value="2"> c) To find a linear subspace \( Z \) of \( \mathbb{R}^m \) that maximizes the sum of the squared norms of the orthogonal projections of the \( \alpha_i \)'s onto \( Z \).</label></li>
                <li><label><input type="radio" name="q0" value="3"> d) Both b and c.</label></li>
            </ul>
            <div class="feedback" id="feedback0"></div>
        </div>

        <div class="question">
            <p>Consider the data points \( \alpha_1 = (-2,2) \) and \( \alpha_2 = (3,-3) \). For \( k=1 \), what is the solution of the best approximating subspace problem?</p>
            <ul class="options">
                <li><label><input type="radio" name="q1" value="0"> a) \( Z = \{(x,y) \in \mathbb{R}^2 : y = x\} \)</label></li>
                <li><label><input type="radio" name="q1" value="1"> b) \( Z = \{(x,y) \in \mathbb{R}^2 : y = -x\} \)</label></li>
                <li><label><input type="radio" name="q1" value="2"> c) \( Z = \{(x,y) \in \mathbb{R}^2 : y = x+1\} \)</label></li>
                <li><label><input type="radio" name="q1" value="3"> d) \( Z = \{(x,y) \in \mathbb{R}^2 : y = x-1\} \)</label></li>
            </ul>
            <div class="feedback" id="feedback1"></div>
        </div>

        <div class="question">
            <p>Let \( A \in \mathbb{R}^{n \times m} \) with rows \( \alpha_i^T \), \( i=1,\dots,n \). A solution to the best approximating subspace problem is obtained by solving:</p>
            <ul class="options">
                <li><label><input type="radio" name="q2" value="0"> a) \( \max_{w_1,\dots,w_k} \sum_{j=1}^k \| Aw_j \|^2 \) over all orthonormal lists \( w_1,\dots,w_k \) of length \( k \).</label></li>
                <li><label><input type="radio" name="q2" value="1"> b) \( \min_{w_1,\dots,w_k} \sum_{j=1}^k \| Aw_j \|^2 \) over all orthonormal lists \( w_1,\dots,w_k \) of length \( k \).</label></li>
                <li><label><input type="radio" name="q2" value="2"> c) \( \max_{w_1,\dots,w_k} \sum_{j=1}^k \| Aw_j \| \) over all orthonormal lists \( w_1,\dots,w_k \) of length \( k \).</label></li>
                <li><label><input type="radio" name="q2" value="3"> d) \( \min_{w_1,\dots,w_k} \sum_{j=1}^k \| Aw_j \| \) over all orthonormal lists \( w_1,\dots,w_k \) of length \( k \).</label></li>
            </ul>
            <div class="feedback" id="feedback2"></div>
        </div>

        <div class="question">
            <p>What is the significance of the leading right singular vectors in the SVD?</p>
            <ul class="options">
                <li><label><input type="radio" name="q3" value="0"> a) They form an orthonormal basis for the column space of \( A \).</label></li>
                <li><label><input type="radio" name="q3" value="1"> b) They form an orthonormal basis for the row space of \( A \).</label></li>
                <li><label><input type="radio" name="q3" value="2"> c) They span the subspace that best approximates the data points.</label></li>
                <li><label><input type="radio" name="q3" value="3"> d) They maximize the sum of the Euclidean distances from the data points.</label></li>
            </ul>
            <div class="feedback" id="feedback3"></div>
        </div>

        <div class="question">
            <p>In the singular value decomposition \( A = \sum_{j=1}^r \sigma_j u_j v_j^T \), the vectors \( u_j \) are called:</p>
            <ul class="options">
                <li><label><input type="radio" name="q4" value="0"> a) Left singular vectors</label></li>
                <li><label><input type="radio" name="q4" value="1"> b) Right singular vectors</label></li>
                <li><label><input type="radio" name="q4" value="2"> c) Singular values</label></li>
                <li><label><input type="radio" name="q4" value="3"> d) None of the above</label></li>
            </ul>
            <div class="feedback" id="feedback4"></div>
        </div>

        <div class="question">
            <p>Which of the following is true about the SVD of a matrix \( A \)?</p>
            <ul class="options">
                <li><label><input type="radio" name="q5" value="0"> a) The SVD of \( A \) is unique.</label></li>
                <li><label><input type="radio" name="q5" value="1"> b) The left singular vectors of \( A \) are the eigenvectors of \( A^TA \).</label></li>
                <li><label><input type="radio" name="q5" value="2"> c) The right singular vectors of \( A \) are the eigenvectors of \( AA^T \).</label></li>
                <li><label><input type="radio" name="q5" value="3"> d) Both b and c.</label></li>
            </ul>
            <div class="feedback" id="feedback5"></div>
        </div>

        <div class="question">
            <p>What is the difference between a compact SVD and a full SVD?</p>
            <ul class="options">
                <li><label><input type="radio" name="q6" value="0"> a) A compact SVD only includes the non-zero singular values, while a full SVD includes all singular values, including zeros.</label></li>
                <li><label><input type="radio" name="q6" value="1"> b) A compact SVD has orthogonal matrices \( U \) and \( V \), while a full SVD has orthonormal matrices \( U \) and \( V \).</label></li>
                <li><label><input type="radio" name="q6" value="2"> c) A compact SVD is unique, while a full SVD is not.</label></li>
                <li><label><input type="radio" name="q6" value="3"> d) A compact SVD can be computed for any matrix, while a full SVD can only be computed for square matrices.</label></li>
            </ul>
            <div class="feedback" id="feedback6"></div>
        </div>

        <div class="question">
            <p>Let \( A = U \Sigma V^T \) be an SVD of \( A \). Which of the following is true?</p>
            <ul class="options">
                <li><label><input type="radio" name="q7" value="0"> a) \( A v_i = \sigma_i u_i \) for all \( i \).</label></li>
                <li><label><input type="radio" name="q7" value="1"> b) \( A^T u_i = \sigma_i v_i \) for all \( i \).</label></li>
                <li><label><input type="radio" name="q7" value="2"> c) \( \|Av_i\| = \sigma_i \) for all \( i \).</label></li>
                <li><label><input type="radio" name="q7" value="3"> d) All of the above.</label></li>
            </ul>
            <div class="feedback" id="feedback7"></div>
        </div>

        <div class="question">
            <p>Which of the following is NOT a property of the matrix \( A^TA \) in the context of the SVD?</p>
            <ul class="options">
                <li><label><input type="radio" name="q8" value="0"> a) \( A^T A \) is symmetric.</label></li>
                <li><label><input type="radio" name="q8" value="1"> b) \( A^T A \) is positive semidefinite.</label></li>
                <li><label><input type="radio" name="q8" value="2"> c) The eigenvectors of \( A^T A \) are the right singular vectors of \( A \).</label></li>
                <li><label><input type="radio" name="q8" value="3"> d) The eigenvalues of \( A^T A \) are the squares of the singular values of \( A \).</label></li>
            </ul>
            <div class="feedback" id="feedback8"></div>
        </div>

        <div class="question">
            <p>The columns of \( U \) in the compact SVD form an orthonormal basis for:</p>
            <ul class="options">
                <li><label><input type="radio" name="q9" value="0"> a) \( \mathrm{col}(A) \)</label></li>
                <li><label><input type="radio" name="q9" value="1"> b) \( \mathrm{row}(A) \)</label></li>
                <li><label><input type="radio" name="q9" value="2"> c) \( \mathrm{null}(A) \)</label></li>
                <li><label><input type="radio" name="q9" value="3"> d) \( \mathrm{null}(A^T) \)</label></li>
            </ul>
            <div class="feedback" id="feedback9"></div>
        </div>

        <div class="question">
            <p>Let \( A \in \mathbb{R}^{n \times m} \) have compact SVD \( A = U_1 \Sigma_1 V_1^T \). To obtain a full SVD, we complete \( U_1 \) to an orthonormal basis \( U = (U_1 \ U_2) \) of \( \mathbb{R}^n \) and \( V_1 \) to an orthonormal basis \( V = (V_1 \ V_2) \) of \( \mathbb{R}^m \). Then the columns of \( U_2 \) form an orthonormal basis of:</p>
            <ul class="options">
                <li><label><input type="radio" name="q10" value="0"> a) \( \mathrm{col}(A) \)</label></li>
                <li><label><input type="radio" name="q10" value="1"> b) \( \mathrm{row}(A) \)</label></li>
                <li><label><input type="radio" name="q10" value="2"> c) \( \mathrm{null}(A) \)</label></li>
                <li><label><input type="radio" name="q10" value="3"> d) \( \mathrm{null}(A^T) \)</label></li>
            </ul>
            <div class="feedback" id="feedback10"></div>
        </div>
    </div>

    <script>
         document.querySelectorAll('.options').forEach((optionsList, index) => {
            const correctOptions = [3, 1, 0, 2, 0, 3, 0, 3, 2, 0, 3];

            optionsList.addEventListener('change', (event) => {
                const selectedOption = parseInt(event.target.value);
                const feedbackDiv = document.getElementById('feedback' + index);
                let feedbackText = '';

                if (selectedOption === correctOptions[index]) {
                    feedbackText = "Excellent! " + getCorrectFeedback(index);
                    feedbackDiv.classList.add('correct');
                    feedbackDiv.classList.remove('incorrect');
                } else {
                    feedbackText = "Try again.";
                    feedbackDiv.classList.add('incorrect');
                    feedbackDiv.classList.remove('correct');
                }

                feedbackDiv.innerHTML = feedbackText;

                MathJax.typesetPromise([feedbackDiv]);
            });
        });

        function getCorrectFeedback(index) {
            switch (index) {
                case 0:
                    return "The text defines the best approximating subspace problem as minimizing the sum of squared distances between the data points and their projections onto the subspace, and it also states a lemma that this problem is equivalent to maximizing the sum of squared norms of the projections.";
                case 1:
                    return "By symmetry, the best approximating line must pass through the origin and bisect the angle between the two points. This is the line \\( y=-x \\).";
                case 2:
                    return "The text states this result in Lemma (Best Subspace in Matrix Form).";
                case 3:
                    return "The text indicates that the leading right singular vectors span the subspace that best approximates the data points.";
                case 4:
                    return "The text states: 'Here the \\( u_j \\)'s are the columns of \\( U \\) and are referred to as left singular vectors.'";
                case 5:
                    return "The SVD is not unique in general. The other two statements are true and are mentioned in the text.";
                case 6:
                    return "The text defines the compact and full SVDs and explains that the compact SVD only includes the non-zero singular values.";
                case 7:
                    return "This is a lemma stated in the text.";
                case 8:
                    return "The eigenvectors of \\( A^T A \\) are the right singular vectors of \\( A \\). The left singular vectors of \\( A \\) are the eigenvectors of \\( AA^T \\). The other statements are true.";
                case 9:
                    return "The text states in the SVD and Rank Lemma: 'the columns of \\( U \\) form an orthonormal basis of \\( \\mathrm{col}(A) \\).'";
                case 10:
                    return "The text states: 'Because \\( \\mathrm{col}(A)^\\perp = \\mathrm{null}(A^T) \\), the columns of \\( U_2 \\) form an orthonormal basis of \\( \\mathrm{null}(A^T) \\).'";
                default:
                    return "";
            }
        }
    </script>
</body>
</html>
