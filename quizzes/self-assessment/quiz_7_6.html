<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MMiDS 7.6: Self-Assessment Quiz</title>
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@600&family=Open+Sans&display=swap"
        rel="stylesheet">
    <style>
        body {
            font-family: 'Arial', sans-serif;
            background-color: #f5f5f5;
            color: #333;
            margin: 0;
            padding: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
        }

        #quiz-container {
            background-color: #fff;
            border-radius: 10px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            padding: 30px;
            max-width: 800px;
            width: 100%;
            margin: 20px;
        }

        h1 {
            font-family: 'Montserrat', sans-serif;
            color: #673ab7;
            text-align: center;
            margin-bottom: 30px;
        }

        .question {
            background-color: #f5f0ff;
            border: 1px solid #d1c4e9;
            border-radius: 5px;
            padding: 20px;
            margin-bottom: 30px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }

        .question p {
            margin: 0 0 15px;
            font-weight: bold;
        }

        .options {
            list-style-type: none;
            padding: 0;
        }

        .options li {
            margin-bottom: 0px;
        }

        .options li label {
            display: block;
            padding: 12px;
            background-color: #f5f0ff;
            color: #333;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s;
        }

        .options li label:hover {
            background-color: #e0d6ff;
        }

        .options li input[type="radio"] {
            accent-color: #673ab7;
        }

        .feedback {
            margin-top: 15px;
            display: none;
            padding: 12px;
            border-radius: 5px;
        }

        .feedback.correct {
            background-color: #e0f0e5;
            color: #155724;
            display: block;
        }

        .feedback.incorrect {
            background-color: #f8e1e3;
            color: #721c24;
            display: block;
        }

        img.graph-image {
            display: block;
            margin-left: auto;
            margin-right: auto;
            width: 50%;
            margin-bottom: 20px;
            margin-top: 20px;
        }

        @media (max-width: 600px) {
            #quiz-container {
                padding: 20px;
                margin: 20px 10px;
            }

            h1 {
                font-size: 24px;
                margin-bottom: 20px;
            }

            .question {
                padding: 15px;
                margin-bottom: 20px;
            }

            img.graph-image {
                width: 70%;
                margin-bottom: 15px;
                margin-top: 15px;
            }
        }
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>
    <div id="quiz-container">
        <h1>MMiDS 7.6: Self-Assessment Quiz</h1>

        <div class="question">
            <p>In the context of Markov Chain Monte Carlo (MCMC), what is the primary goal?</p>
            <ul class="options">
                <li><label><input type="radio" name="q0" value="0"> a) To find the maximum likelihood estimate of a
                        parameter.</label></li>
                <li><label><input type="radio" name="q0" value="1"> b) To generate samples from a complex target
                        distribution.</label></li>
                <li><label><input type="radio" name="q0" value="2"> c) To optimize a loss function using gradient
                        descent.</label></li>
                <li><label><input type="radio" name="q0" value="3"> d) To cluster data points based on
                        similarity.</label></li>
            </ul>
            <div class="feedback" id="feedback0"></div>
        </div>

        <div class="question">
            <p>Which of the following is NOT a requirement for the Metropolis-Hastings algorithm?</p>
            <ul class="options">
                <li><label><input type="radio" name="q1" value="0"> a) A target distribution \( \pi \) to sample
                        from.</label></li>
                <li><label><input type="radio" name="q1" value="1"> b) A proposal distribution \( Q \) that is easy to
                        simulate.</label></li>
                <li><label><input type="radio" name="q1" value="2"> c) A symmetric proposal distribution \( Q \), i.e.,
                        \( Q(x,y) = Q(y,x) \) for all \( x,y \in S \).</label></li>
                <li><label><input type="radio" name="q1" value="3"> d) An initial state \( x_0 \in S \).</label></li>
            </ul>
            <div class="feedback" id="feedback1"></div>
        </div>

        <div class="question">
            <p>In the Metropolis-Hastings algorithm, what is the role of the proposal chain \( Q \)?</p>
            <ul class="options">
                <li><label><input type="radio" name="q2" value="0"> a) It determines the stationary distribution of the
                        resulting Markov chain.</label></li>
                <li><label><input type="radio" name="q2" value="1"> b) It is used to compute the acceptance probability
                        for the proposed moves.</label></li>
                <li><label><input type="radio" name="q2" value="2"> c) It generates the candidate states for the next
                        move in the Markov chain.</label></li>
                <li><label><input type="radio" name="q2" value="3"> d) It ensures that the resulting Markov chain is
                        irreducible and aperiodic.</label></li>
            </ul>
            <div class="feedback" id="feedback2"></div>
        </div>

        <div class="question">
            <p>What is the purpose of the Hastings correction in the Metropolis-Hastings algorithm?</p>
            <ul class="options">
                <li><label><input type="radio" name="q3" value="0"> a) To ensure that the proposal chain is
                        symmetric.</label></li>
                <li><label><input type="radio" name="q3" value="1"> b) To make the resulting Markov chain irreducible
                        and aperiodic.</label></li>
                <li><label><input type="radio" name="q3" value="2"> c) To ensure that the resulting Markov chain has the
                        desired stationary distribution.</label></li>
                <li><label><input type="radio" name="q3" value="3"> d) To improve the mixing time of the resulting
                        Markov chain.</label></li>
            </ul>
            <div class="feedback" id="feedback3"></div>
        </div>

        <div class="question">
            <p>In the proof of the correctness of the Metropolis-Hastings algorithm, what is the key property that
                ensures the resulting Markov chain has the desired stationary distribution?</p>
            <ul class="options">
                <li><label><input type="radio" name="q4" value="0"> a) Irreducibility</label></li>
                <li><label><input type="radio" name="q4" value="1"> b) Aperiodicity</label></li>
                <li><label><input type="radio" name="q4" value="2"> c) Reversibility</label></li>
                <li><label><input type="radio" name="q4" value="3"> d) Ergodicity</label></li>
            </ul>
            <div class="feedback" id="feedback4"></div>
        </div>

        <div class="question">
            <p>What is the main advantage of Gibbs sampling compared to the general Metropolis-Hastings algorithm?</p>
            <ul class="options">
                <li><label><input type="radio" name="q5" value="0"> a) It always accepts the proposed moves.</label>
                </li>
                <li><label><input type="radio" name="q5" value="1"> b) It does not require a proposal
                        distribution.</label></li>
                <li><label><input type="radio" name="q5" value="2"> c) It exploits the conditional independence
                        structure of the target distribution.</label></li>
                <li><label><input type="radio" name="q5" value="3"> d) It guarantees a faster convergence to the
                        stationary distribution.</label></li>
            </ul>
            <div class="feedback" id="feedback5"></div>
        </div>

        <div class="question">
            <p>What is the role of the energy function \( E(v,h) \) in a Restricted Boltzmann Machine (RBM)?</p>
            <ul class="options">
                <li><label><input type="radio" name="q6" value="0"> a) It determines the acceptance probability in the
                        Metropolis-Hastings algorithm.</label></li>
                <li><label><input type="radio" name="q6" value="1"> b) It defines the joint probability distribution of
                        the visible and hidden units.</label></li>
                <li><label><input type="radio" name="q6" value="2"> c) It represents the cost function to be minimized
                        during training.</label></li>
                <li><label><input type="radio" name="q6" value="3"> d) It controls the learning rate of the RBM.</label>
                </li>
            </ul>
            <div class="feedback" id="feedback6"></div>
        </div>

        <div class="question">
            <p>Which function plays a crucial role in computing the conditional probabilities in an RBM?</p>
            <ul class="options">
                <li><label><input type="radio" name="q7" value="0"> a) The exponential function.</label></li>
                <li><label><input type="radio" name="q7" value="1"> b) The sigmoid function.</label></li>
                <li><label><input type="radio" name="q7" value="2"> c) The logarithmic function.</label></li>
                <li><label><input type="radio" name="q7" value="3"> d) The hyperbolic tangent function.</label></li>
            </ul>
            <div class="feedback" id="feedback7"></div>
        </div>

        <div class="question">
            <p>After training an RBM on handwritten digit images, what is the output of the Gibbs sampling process?</p>
            <ul class="options">
                <li><label><input type="radio" name="q8" value="0"> a) A set of parameters for the RBM.</label></li>
                <li><label><input type="radio" name="q8" value="1"> b) A probability distribution over all possible
                        images.</label></li>
                <li><label><input type="radio" name="q8" value="2"> c) A sequence of images that resemble handwritten
                        digits.</label></li>
                <li><label><input type="radio" name="q8" value="3"> d) A single image representing the average of all
                        training images.</label></li>
            </ul>
            <div class="feedback" id="feedback8"></div>
        </div>

        <div class="question">
            <p>What is the partition function \( Z \) used for in the RBM's joint probability distribution \( \pi(v, h)
                \)?</p>
            <ul class="options">
                <li><label><input type="radio" name="q9" value="0"> a) It normalizes the energy function.</label></li>
                <li><label><input type="radio" name="q9" value="1"> b) It scales the weights matrix \( W \).</label>
                </li>
                <li><label><input type="radio" name="q9" value="2"> c) It ensures that the probability distribution sums
                        to one.</label></li>
                <li><label><input type="radio" name="q9" value="3"> d) It adjusts the biases \( b \) and \( c
                        \).</label></li>
            </ul>
            <div class="feedback" id="feedback9"></div>
        </div>

    </div>

    <script>
        document.querySelectorAll('.options').forEach((optionsList, index) => {
            const correctOptions = [1, 2, 2, 2, 2, 2, 1, 1, 2, 2];

            optionsList.addEventListener('change', (event) => {
                const selectedOption = parseInt(event.target.value);
                const feedbackDiv = document.getElementById('feedback' + index);
                let feedbackText = '';

                if (selectedOption === correctOptions[index]) {
                    feedbackText = "Excellent! " + getCorrectFeedback(index);
                    feedbackDiv.classList.add('correct');
                    feedbackDiv.classList.remove('incorrect');
                } else {
                    feedbackText = "Try again.";
                    feedbackDiv.classList.add('incorrect');
                    feedbackDiv.classList.remove('correct');
                }

                feedbackDiv.innerHTML = feedbackText;

                MathJax.typesetPromise([feedbackDiv]);
            });
        });

        function getCorrectFeedback(index) {
            switch (index) {
                case 0:
                    return "The text states that 'The idea behind MCMC is simple. To generate samples from \\(\\pi\\), use a Markov chain for which it is the stationary distribution.'";
                case 1:
                    return "While a symmetric proposal distribution simplifies the acceptance probability calculation, it is not a strict requirement for the Metropolis-Hastings algorithm.";
                case 2:
                    return "The text describes the proposal chain as follows: 'We first define a proposal chain, that is, a transition matrix \\(Q\\) on the space \\(S\\). This chain does not need to have stationary distribution \\(\\pi\\). But it is typically a chain that is easy to simulate.'";
                case 3:
                    return "The text states that the Hastings correction is 'where the target distribution \\(\\pi\\) enters the picture, and the rejection probability is chosen to ensure that the new chain has the right stationary distribution, as we will see later.'";
                case 4:
                    return "The text proves the correctness of the Metropolis-Hastings algorithm by showing that the resulting Markov chain is irreducible and reversible with respect to the target distribution \\(\\pi\\).";
                case 5:
                    return "The text states that 'Gibbs sampling is a canonical way of addressing this issue that has many applications. It applies in cases where the states are vectors, typically with a large number of coordinates, and where the target distribution has the kind of conditional independence properties we have encountered previously in this chapter.'";
                case 6:
                    return "The text defines the joint distribution of \\(v\\) and \\(h\\) as \\(\\pi(v,h) = \\frac{1}{Z} \\exp(-E(v,h))\\).";
                case 7:
                    return "The text explicitly uses the sigmoid function \\(\\sigma(x) = \\frac{1}{1+e^{-x}}\\) in the derivation of the conditional probabilities.";
                case 8:
                    return "The text describes the goal of using the Gibbs sampler on an RBM as 'generating random images from a realistic distribution.'";
                case 9:
                    return "The text explains that \\(Z\\), the partition function, 'ensures that \\(\\pi\\) indeed sums to 1.'";
                default:
                    return "";
            }
        }

    </script>

</body>

</html>