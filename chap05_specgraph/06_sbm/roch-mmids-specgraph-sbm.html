
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>5.6. Erdős-Rényi random graph and stochastic blockmodel &#8212; MMiDS Textbook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-P5E8DW088F"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-P5E8DW088F');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-P5E8DW088F');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chap05_specgraph/06_sbm/roch-mmids-specgraph-sbm';</script>
    <link rel="canonical" href="https://mmids-textbook.github.io/chap05_specgraph/06_sbm/roch-mmids-specgraph-sbm.html" />
    <link rel="icon" href="https://mmids-textbook.github.io/favicon-32x32.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="5.7. Exercises" href="../exercises/roch-mmids-specgraph-exercises.html" />
    <link rel="prev" title="5.5. Application: graph partitioning via spectral clustering" href="../05_partitioning/roch-mmids-specgraph-partitioning.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/mmids-cover-small.jpg" class="logo__image only-light" alt="MMiDS Textbook - Home"/>
    <script>document.write(`<img src="../../_static/mmids-cover-small.jpg" class="logo__image only-dark" alt="MMiDS Textbook - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    <b>MATHEMATICAL METHODS in DATA SCIENCE (with Python)</b>
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../chap01_intro/00_intro/roch-mmids-intro-intro.html">1. Introduction: a first data science problem</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chap01_intro/01_motiv/roch-mmids-intro-motiv.html">1.1. Motivating example: identifying penguin species</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap01_intro/02_review/roch-mmids-intro-review.html">1.2. Background: quick refresher of matrix algebra, differential calculus, and elementary probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap01_intro/03_clustering/roch-mmids-intro-clustering.html">1.3. Clustering: an objective, an algorithm and a guarantee</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap01_intro/04_highdim/roch-mmids-intro-highdim.html">1.4. Some observations about high-dimensional data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap01_intro/exercises/roch-mmids-intro-exercises.html">1.5. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap01_intro/supp/roch-mmids-intro-supp.html">1.6. Online suppplementary material</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../chap02_ls/00_intro/roch-mmids-ls-intro.html">2. Least squares: geometric, algebraic, and numerical aspects</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/01_motiv/roch-mmids-ls-motiv.html">2.1. Motivating example: predicting sales</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/02_spaces/roch-mmids-ls-spaces.html">2.2. Background: review of vector spaces and matrix inverses</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/03_orthog/roch-mmids-ls-orthog.html">2.3. Geometry of least squares: the orthogonal projection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/04_qr/roch-mmids-ls-qr.html">2.4. QR decomposition and Householder transformations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/05_regression/roch-mmids-ls-regression.html">2.5. Application: regression analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/exercises/roch-mmids-ls-exercises.html">2.6. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/supp/roch-mmids-ls-supp.html">2.7. Online suppplementary material</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../chap03_opt/00_intro/roch-mmids-opt-intro.html">3. Optimization theory and algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/01_motiv/roch-mmids-opt-motiv.html">3.1. Motivating example:  analyzing customer satisfaction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/02_several/roch-mmids-opt-several.html">3.2. Background: review of differentiable functions of several variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/03_optimality/roch-mmids-opt-optimality.html">3.3. Optimality conditions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/04_convexity/roch-mmids-opt-convexity.html">3.4. Convexity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/05_gd/roch-mmids-opt-gd.html">3.5. Gradient descent and its convergence analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/06_logistic/roch-mmids-opt-logistic.html">3.6. Application: logistic regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/exercises/roch-mmids-opt-exercises.html">3.7. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/supp/roch-mmids-opt-supp.html">3.8. Online suppplementary material</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../chap04_svd/00_intro/roch-mmids-svd-intro.html">4. Singular value decomposition</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/01_motiv/roch-mmids-svd-motiv.html">4.1. Motivating example: visualizing viral evolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/02_spectral/roch-mmids-svd-spectral.html">4.2. Background: review of matrix rank  and spectral decomposition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/03_svd/roch-mmids-svd-svd.html">4.3. Approximating subspaces and the SVD</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/04_power/roch-mmids-svd-power.html">4.4. Power iteration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/05_pca/roch-mmids-svd-pca.html">4.5. Application: principal components analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/06_further/roch-mmids-svd-further.html">4.6. Further applications of the SVD: low-rank approximations and ridge regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/exercises/roch-mmids-svd-exercises.html">4.7. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/supp/roch-mmids-svd-supp.html">4.8. Online suppplementary material</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../00_intro/roch-mmids-specgraph-intro.html">5. Spectral graph theory</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../01_motiv/roch-mmids-specgraph-motiv.html">5.1. Motivating example: uncovering social groups</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02_graph/roch-mmids-specgraph-graph.html">5.2. Background: basic concepts in graph theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03_extremal/roch-mmids-specgraph-extremal.html">5.3. Variational characterization of eigenvalues</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04_laplacian/roch-mmids-specgraph-laplacian.html">5.4. Spectral properties of the Laplacian matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../05_partitioning/roch-mmids-specgraph-partitioning.html">5.5. Application: graph partitioning via spectral clustering</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">5.6. Erdős-Rényi random graph and stochastic blockmodel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/roch-mmids-specgraph-exercises.html">5.7. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../supp/roch-mmids-specgraph-supp.html">5.8. Online supplementary material</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../chap06_prob/00_intro/roch-mmids-prob-intro.html">6. Probabilistic models: from simple to complex</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chap06_prob/01_motiv/roch-mmids-prob-motiv.html">6.1. Motivating example: tracking location</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap06_prob/02_parametric/roch-mmids-prob-parametric.html">6.2. Background: introduction to parametric families and maximum likelihood estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap06_prob/03_joint/roch-mmids-prob-joint.html">6.3. Modeling more complex dependencies 1: using conditional independence</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap06_prob/04_em/roch-mmids-prob-em.html">6.4. Modeling more complex dependencies 2: marginalizing out an unobserved variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap06_prob/05_kalman/roch-mmids-prob-kalman.html">6.5. Application: linear-Gaussian models and Kalman filtering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap06_prob/exercises/roch-mmids-prob-exercises.html">6.6. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap06_prob/supp/roch-mmids-prob-supp.html">6.7. Online supplementary material</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../chap07_rwmc/00_intro/roch-mmids-rwmc-intro.html">7. Random walks on graphs and Markov chains</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/01_motiv/roch-mmids-rwmc-motiv.html">7.1. Motivating example: discovering mathematical topics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/02_mcdefs/roch-mmids-rwmc-mcdefs.html">7.2. Background: elements of finite Markov chains</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/03_stat/roch-mmids-rwmc-stat.html">7.3. Limit behavior 1: stationary distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/04_mclimit/roch-mmids-rwmc-mclimit.html">7.4. Limit behavior 2: convergence to equilibrium</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/05_pagerank/roch-mmids-rwmc-pagerank.html">7.5. Application: random walks on graphs and PageRank</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/06_gibbs/roch-mmids-rwmc-gibbs.html">7.6. Further applications: Gibbs sampling and generating images</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/exercises/roch-mmids-rwmc-exercises.html">7.7. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/supp/roch-mmids-rwmc-supp.html">7.8. Online supplementary material</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../chap08_nn/00_intro/roch-mmids-nn-intro.html">8. Neural networks, backpropagation and stochastic gradient descent</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chap08_nn/01_motiv/roch-mmids-nn-motiv.html">8.1. Motivating example:  classifying natural images</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap08_nn/02_chain/roch-mmids-nn-chain.html">8.2. Background: Jacobian, chain rule, and a brief introduction to automatic differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap08_nn/03_backprop/roch-mmids-nn-backprop.html">8.3. Building blocks of AI 1: backpropagation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap08_nn/04_sgd/roch-mmids-nn-sgd.html">8.4. Building blocks of AI 2: stochastic gradient descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap08_nn/05_nn/roch-mmids-nn-nn.html">8.5. Building blocks of AI 3: neural networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap08_nn/exercises/roch-mmids-nn-exercises.html">8.6. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap08_nn/supp/roch-mmids-nn-supp.html">8.7. Online supplementary material</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/MMiDS-textbook/MMiDS-textbook.github.io" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/issues/new?title=Issue%20on%20page%20%2Fchap05_specgraph/06_sbm/roch-mmids-specgraph-sbm.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/chap05_specgraph/06_sbm/roch-mmids-specgraph-sbm.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Erdős-Rényi random graph and stochastic blockmodel</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inhomogeneous-erdos-renyi-random-graph">5.6.1. Inhomogeneous Erdős-Rényi random graph</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-blockmodel">5.6.2. Stochastic blockmodel</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p><span class="math notranslate nohighlight">\(\newcommand{\bmu}{\boldsymbol{\mu}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bSigma}{\boldsymbol{\Sigma}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bfbeta}{\boldsymbol{\beta}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bflambda}{\boldsymbol{\lambda}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bgamma}{\boldsymbol{\gamma}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bsigma}{{\boldsymbol{\sigma}}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bpi}{\boldsymbol{\pi}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\btheta}{{\boldsymbol{\theta}}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bphi}{\boldsymbol{\phi}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\balpha}{\boldsymbol{\alpha}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\blambda}{\boldsymbol{\lambda}}\)</span>
<span class="math notranslate nohighlight">\(\renewcommand{\P}{\mathbb{P}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\E}{\mathbb{E}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\indep}{\perp\!\!\!\perp} \newcommand{\bx}{\mathbf{x}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bp}{\mathbf{p}}\)</span>
<span class="math notranslate nohighlight">\(\renewcommand{\bx}{\mathbf{x}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bX}{\mathbf{X}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\by}{\mathbf{y}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bY}{\mathbf{Y}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bz}{\mathbf{z}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bZ}{\mathbf{Z}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bw}{\mathbf{w}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bW}{\mathbf{W}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bv}{\mathbf{v}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bV}{\mathbf{V}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bfg}{\mathbf{g}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bfh}{\mathbf{h}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\horz}{\rule[.5ex]{2.5ex}{0.5pt}}\)</span>
<span class="math notranslate nohighlight">\(\renewcommand{\S}{\mathcal{S}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\X}{\mathcal{X}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\var}{\mathrm{Var}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\pa}{\mathrm{pa}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\Z}{\mathcal{Z}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bh}{\mathbf{h}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bb}{\mathbf{b}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bc}{\mathbf{c}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\cE}{\mathcal{E}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\cP}{\mathcal{P}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bbeta}{\boldsymbol{\beta}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bLambda}{\boldsymbol{\Lambda}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\cov}{\mathrm{Cov}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bfk}{\mathbf{k}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\idx}[1]{}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\xdi}{}\)</span></p>
<section id="erdos-renyi-random-graph-and-stochastic-blockmodel">
<h1><span class="section-number">5.6. </span>Erdős-Rényi random graph and stochastic blockmodel<a class="headerlink" href="#erdos-renyi-random-graph-and-stochastic-blockmodel" title="Link to this heading">#</a></h1>
<p>A natural way to test an algorithm is by running it on a simulated dataset whose “ground truth” is known. We encountered this idea for instance in clustering, where we used a mixture of Gaussians; there, the ground truth was the mixture component from which a data point was generated. What is an appropriate stochastic model in the context of network analysis?</p>
<p>In fact there are many models of random graphs, i.e., graphs whose edges are picked at random. Which one to use depends on the task at hand. For graph partitioning, one requires a graph with a “planted partition”. The stochastic blockmodel is a canonical example of such a model. We begin with a more general setting.</p>
<section id="inhomogeneous-erdos-renyi-random-graph">
<h2><span class="section-number">5.6.1. </span>Inhomogeneous Erdős-Rényi random graph<a class="headerlink" href="#inhomogeneous-erdos-renyi-random-graph" title="Link to this heading">#</a></h2>
<p>A simple approach to generating a random graph is to include each edge <em>independently</em>. More precisely, let <span class="math notranslate nohighlight">\(V = [n]\)</span> be a set of <span class="math notranslate nohighlight">\(n\)</span> vertices. Consider a symmetric matrix <span class="math notranslate nohighlight">\(M = (m_{i,j}) \in [0,1]^{n \times n}\)</span> with arbitrary entries in <span class="math notranslate nohighlight">\([0,1]\)</span>. The entry <span class="math notranslate nohighlight">\(m_{i,j} = m_{j,i}\)</span> is the probability that edge <span class="math notranslate nohighlight">\(\{i,j\}\)</span> is present (i.e., that <span class="math notranslate nohighlight">\(\{i,j\} \in E\)</span>), independently of all other edges. The outcome is a random graph <span class="math notranslate nohighlight">\(G = (V, E)\)</span> with random adjacency matrix <span class="math notranslate nohighlight">\(A = (A_{i,j}) \in \{0,1\}^{n \times n}\)</span>. This model is known as an inhomogeneous Erdős-Rényi (ER) random graph<span class="math notranslate nohighlight">\(\idx{inhomogeneous Erdős-Rényi random graph}\xdi\)</span>.</p>
<p>Observe that</p>
<div class="math notranslate nohighlight">
\[
\E[A_{i,j}]
= 1 \cdot m_{i,j} + 0 \cdot (1 - m_{i,j})
= m_{i,j}.
\]</div>
<p>Indeed each entry <span class="math notranslate nohighlight">\(A_{i,j}\)</span> is a Bernoulli random variable with success probability <span class="math notranslate nohighlight">\(m_{i,j}\)</span>. In other words, in matrix form, we have</p>
<div class="math notranslate nohighlight">
\[
\E[A]
= M,
\]</div>
<p>that is, <span class="math notranslate nohighlight">\(M\)</span> is the expected adjacency matrix. Note in particular that <span class="math notranslate nohighlight">\(M\)</span> is deterministic while <span class="math notranslate nohighlight">\(A\)</span> is random (which is why we use lowercase entries for <span class="math notranslate nohighlight">\(M\)</span> but uppercase entries for <span class="math notranslate nohighlight">\(A\)</span>).</p>
<p>An important special case is obtained when <span class="math notranslate nohighlight">\(m_{i,j} = m_{j,i} = p \in (0,1)\)</span> for all <span class="math notranslate nohighlight">\(i \neq j\)</span> and <span class="math notranslate nohighlight">\(m_{k,k} = 0\)</span> for all <span class="math notranslate nohighlight">\(k\)</span>. That is, each possible edge between two distinct vertices is present with the same probability <span class="math notranslate nohighlight">\(p\)</span>. This model is known simply as an Erdős-Rényi (ER) random graph<span class="math notranslate nohighlight">\(\idx{Erdős-Rényi random graph}\xdi\)</span>. Put differently,</p>
<div class="math notranslate nohighlight">
\[
\E[A] = M = p (J - I_{n \times n}), 
\]</div>
<p>where <span class="math notranslate nohighlight">\(J \in \mathbb{R}^{n \times n}\)</span> is the all-one matrix. In this calculation, we subtract the identity matrix to account for the fact that the diagonal is <span class="math notranslate nohighlight">\(0\)</span>.</p>
<p>The properties of this model are very well-studied. We give a couple of examples next.</p>
<p><strong>EXAMPLE:</strong> Let <span class="math notranslate nohighlight">\(G = (V, E)\)</span> be an ER graph with <span class="math notranslate nohighlight">\(n\)</span> vertices. The parameter <span class="math notranslate nohighlight">\(p\)</span> can be interpreted as an edge density. Indeed, let’s compute the expected number of edges <span class="math notranslate nohighlight">\(G\)</span>. By summing over all pairs and using linearity of expectation, we have</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\E[|E|]
&amp;= \E \left[\sum_{i &lt; j} \mathbf{1}_{\{i,j\} \in E}\right]\\
&amp;= \sum_{i &lt; j} \E \left[\mathbf{1}_{\{i,j\} \in E}\right]\\
&amp;= \binom{n}{2} p.
\end{align*}\]</div>
<p>Or, put differently, we have shown that the expected edge density <span class="math notranslate nohighlight">\(\E\left[|E|/\binom{n}{2}\right]\)</span> is <span class="math notranslate nohighlight">\(p\)</span>.</p>
<p>A similar calculation gives the expected number of triangles. Denote by <span class="math notranslate nohighlight">\(T_3\)</span> the number of triangles in <span class="math notranslate nohighlight">\(G\)</span>, that is, the number of triples <span class="math notranslate nohighlight">\(i, j , k\)</span> of distinct vertices such that <span class="math notranslate nohighlight">\(\{i,j\}, \{j,k\}, \{i,k\} \in E\)</span> (i.e., all edges between them are present). Then</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\E[|T_3|]
&amp;= \E \left[\sum_{i &lt; j &lt; k} \mathbf{1}_{\{i,j\}, \{j,k\}, \{i,k\} \in E}\right]\\
&amp;= \E \left[\sum_{i &lt; j &lt; k} \mathbf{1}_{\{i,j\} \in E}
\mathbf{1}_{\{j,k\} \in E} \mathbf{1}_{\{i,k\} \in E}\right]\\
&amp;= \sum_{i &lt; j &lt; k} \E \left[\mathbf{1}_{\{i,j\} \in E}\right]
\E \left[\mathbf{1}_{\{j,k\} \in E}\right] \E\left[\mathbf{1}_{\{i,k\} \in E}\right]\\
&amp;= \binom{n}{3} p^3.
\end{align*}\]</div>
<p>We used the independence of the edges on the third line. Or, put differently, we have shown that the expected triangle density <span class="math notranslate nohighlight">\(\E\left[|T_3|/\binom{n}{3}\right]\)</span> is <span class="math notranslate nohighlight">\(p^3\)</span>. <span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p>We implement the generation of an inhomogeneous ER graph using NetworkX. We first initialize a pseudorandom number generator <code class="docutils literal notranslate"><span class="pre">rng</span></code>. To determine whether an edge is present between <code class="docutils literal notranslate"><span class="pre">i</span></code> and <code class="docutils literal notranslate"><span class="pre">j</span></code>, we generate a uniform random variable <code class="docutils literal notranslate"><span class="pre">rng.random()</span></code> (see <a class="reference external" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.random.html"><code class="docutils literal notranslate"><span class="pre">numpy.random.Generator.random</span></code></a>) and add the edge with <code class="docutils literal notranslate"><span class="pre">G.add_edge(i,</span> <span class="pre">j)</span></code> if the random variable is <code class="docutils literal notranslate"><span class="pre">&lt;</span> <span class="pre">M[i,</span> <span class="pre">j]</span></code> – an event which indeed occurs with the desired probability (check it!).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">inhomogeneous_er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">M</span><span class="p">):</span>

    <span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
    <span class="n">G</span><span class="o">.</span><span class="n">add_nodes_from</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">M</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]:</span>
                <span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">G</span>
</pre></div>
</div>
</div>
</div>
<p><strong>NUMERICAL CORNER:</strong> Here is an example usage. We generate probabilities <span class="math notranslate nohighlight">\(m_{i,j}\)</span> uniformly at random between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">seed</span> <span class="o">=</span> <span class="mi">535</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">M</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">([</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">])</span>
<span class="n">M</span> <span class="o">=</span> <span class="p">(</span><span class="n">M</span> <span class="o">+</span> <span class="n">M</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="c1"># ensures symmetry of M (why?)</span>

<span class="n">G</span> <span class="o">=</span> <span class="n">inhomogeneous_er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We draw the resulting graph.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/9dbb087e250b03af00d198d9cdd1c4c4ebbf680e47dca105f6a12b350e3c5723.png" src="../../_images/9dbb087e250b03af00d198d9cdd1c4c4ebbf680e47dca105f6a12b350e3c5723.png" />
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p>The following subroutine generates an ER graph.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">p</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">inhomogeneous_er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To confirm our previous calculations, below is the implementation of a routine to estimate the edge density for an ER graph with a fixed parameter <span class="math notranslate nohighlight">\(p\)</span>. Recall that the edge density is defined as the number of edges present divided by the number of possible edges (i.e., the number of pairs of distinct vertices). The routine takes advantage of the <em>Law of Large Numbers</em> by generating a large number of sample graphs, computing their edge density, and then taking the mean.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">estimate_edge_density</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>

    <span class="n">total_edges</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_possible_edges</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
    
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
        <span class="n">G</span> <span class="o">=</span> <span class="n">er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
        <span class="n">total_edges</span> <span class="o">+=</span> <span class="n">G</span><span class="o">.</span><span class="n">number_of_edges</span><span class="p">()</span>
    
    <span class="n">average_edges</span> <span class="o">=</span> <span class="n">total_edges</span> <span class="o">/</span> <span class="n">num_samples</span>
    <span class="n">edge_density</span> <span class="o">=</span> <span class="n">average_edges</span> <span class="o">/</span> <span class="n">total_possible_edges</span>
    <span class="k">return</span> <span class="n">edge_density</span>
</pre></div>
</div>
</div>
</div>
<p><strong>NUMERICAL CORNER:</strong> On a small example, we indeed get that the edge density is roughly <span class="math notranslate nohighlight">\(p\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">estimated_density</span> <span class="o">=</span> <span class="n">estimate_edge_density</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Estimated edge density for an ER graph with n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2"> and p=</span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">estimated_density</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Estimated edge density for an ER graph with n=10 and p=0.3: 0.3004888888888889
</pre></div>
</div>
</div>
</div>
<p><strong>TRY IT!</strong> Modify the code above to estimate the density of triangles. (<a class="reference external" href="https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb">Open In Colab</a>) <span class="math notranslate nohighlight">\(\ddagger\)</span></p>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p>When <span class="math notranslate nohighlight">\(n\)</span>, the number of vertices, is large, random graphs tend to exhibit large-scale emergent behavior. One classical example involves the probability of being connected in an ER graph. To illustrate, below is code to estimate that probability over a range of edge densities <span class="math notranslate nohighlight">\(p\)</span> (with help from Claude and ChatGPT).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">estimate_connected_probability</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>

    <span class="n">connected_count</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
        <span class="n">G</span> <span class="o">=</span> <span class="n">er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">nx</span><span class="o">.</span><span class="n">is_connected</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
            <span class="n">connected_count</span> <span class="o">+=</span> <span class="mi">1</span>
    
    <span class="n">connected_probability</span> <span class="o">=</span> <span class="n">connected_count</span> <span class="o">/</span> <span class="n">num_samples</span>
    <span class="k">return</span> <span class="n">connected_probability</span>

<span class="k">def</span> <span class="nf">plot_connected_probability</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p_values</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>

    <span class="n">probabilities</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">p_values</span><span class="p">:</span>
        <span class="n">prob</span> <span class="o">=</span> <span class="n">estimate_connected_probability</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span>
        <span class="n">probabilities</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p_values</span><span class="p">,</span> <span class="n">probabilities</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$p$&#39;</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Estimated probability of being connected&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><strong>NUMERICAL CORNER:</strong> We run the code for <code class="docutils literal notranslate"><span class="pre">n</span></code> equal to <code class="docutils literal notranslate"><span class="pre">100</span></code>. What do you observe?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">p_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">250</span>
<span class="n">plot_connected_probability</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p_values</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/866c4b9e642bbaacd7f4296d4778cc8fbeb2b2060c4dfe8b8e9de264193fc20e.png" src="../../_images/866c4b9e642bbaacd7f4296d4778cc8fbeb2b2060c4dfe8b8e9de264193fc20e.png" />
</div>
</div>
<p>The probability of being connected starts out at <span class="math notranslate nohighlight">\(0\)</span> when <span class="math notranslate nohighlight">\(p\)</span> is small, which is not surprising since it implies that the graph has a relatively small number of edges. But then that probability increases – rapidly – to <span class="math notranslate nohighlight">\(1\)</span> as <span class="math notranslate nohighlight">\(p\)</span> crosses a threshold. This is referred to as the phase transition of the ER graph.</p>
<p>It can be shown rigorously that the transition occurs at roughly <span class="math notranslate nohighlight">\(p = \log n/n\)</span>. That is:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.04605170185988092
</pre></div>
</div>
</div>
</div>
<p>which is consistent with the plot.</p>
<p><strong>TRY IT!</strong> Taking a larger <code class="docutils literal notranslate"><span class="pre">n</span></code> would produce a sharper transition. Try it for yourself. Also try drawing one random sample for increasing values of <span class="math notranslate nohighlight">\(p\)</span> around the threshold. What do you observe? (<a class="reference external" href="https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb">Open In Colab</a>) <span class="math notranslate nohighlight">\(\ddagger\)</span></p>
<p><strong>TRY IT!</strong> Many other properties exhibit such sharp threshold behavior. Modify the code to to estimate the probability that a clique of size 4 exists in the graph. (<a class="reference external" href="https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb">Open In Colab</a>) <span class="math notranslate nohighlight">\(\ddagger\)</span></p>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
</section>
<section id="stochastic-blockmodel">
<h2><span class="section-number">5.6.2. </span>Stochastic blockmodel<a class="headerlink" href="#stochastic-blockmodel" title="Link to this heading">#</a></h2>
<p>We return to our original motivation. How can we create a random graph with a planted partition? The stochastic blockmodel (SBM) is such a model. Here we imagine that <span class="math notranslate nohighlight">\([n]\)</span> is partioned into two disjoint sets <span class="math notranslate nohighlight">\(C_1\)</span> and <span class="math notranslate nohighlight">\(C_2\)</span>, referred to as blocks. We set <span class="math notranslate nohighlight">\(z(i) = j\)</span> if vertex <span class="math notranslate nohighlight">\(i\)</span> is in block <span class="math notranslate nohighlight">\(C_j\)</span>. We also encode the block assignment with a matrix <span class="math notranslate nohighlight">\(Z \in \{0,1\}^{n \times 2}\)</span> where row <span class="math notranslate nohighlight">\(i\)</span> is <span class="math notranslate nohighlight">\(\mathbf{e}_j^T\)</span> if vertex <span class="math notranslate nohighlight">\(i\)</span> is assigned to block <span class="math notranslate nohighlight">\(C_j\)</span>.</p>
<p>Let <span class="math notranslate nohighlight">\(b_{i,j} \in [0,1]\)</span> be the probability that a vertex in block <span class="math notranslate nohighlight">\(C_i\)</span> and a vertex in block <span class="math notranslate nohighlight">\(C_j\)</span> are connected by an edge, independently of all other edges. We enforce <span class="math notranslate nohighlight">\(b_{1,2} = b_{2,1}\)</span>. We collect these probabilities in the following matrix</p>
<div class="math notranslate nohighlight">
\[\begin{split}
B = \begin{pmatrix}
b_{1,1} &amp; b_{1,2}\\
b_{2,1} &amp; b_{2,2}
\end{pmatrix}.
\end{split}\]</div>
<p>By our assumption, the matrix <span class="math notranslate nohighlight">\(B\)</span> is symmetric.</p>
<p>We typically take</p>
<div class="math notranslate nohighlight">
\[
\min\{b_{1,1}, b_{2,2}\} &gt; b_{1,2},
\]</div>
<p>that is, edges are more likely between vertices in the same block than between vertices in different blocks. That corresponds to the intuition that, in social networks or other types of networks, members of the same group (i.e., block) tend to interact more frequently with each other than with members of different groups. For instance, friends within the same social circle are more likely to be connected than with people outside their circle. That is related to the concept of homophily which describes the tendency of individuals to associate and bond with similar others.</p>
<p>This is a special case of the inhomogeneous ER graph model. What is the corresponding <span class="math notranslate nohighlight">\(M\)</span> matrix? Note that, for each pair of vertex <span class="math notranslate nohighlight">\(1 \leq i &lt; j \leq n\)</span>, edge <span class="math notranslate nohighlight">\(\{i,j\}\)</span> is present in <span class="math notranslate nohighlight">\(E\)</span> with probability</p>
<div class="math notranslate nohighlight">
\[
m_{i,j}
:= b_{z(i), z(j)}
= Z_{i,\cdot}^T B Z_{j,\cdot}
\]</div>
<p>where recall that <span class="math notranslate nohighlight">\(Z_{i,\cdot}\)</span> is row <span class="math notranslate nohighlight">\(i\)</span> of matrix <span class="math notranslate nohighlight">\(Z\)</span>.</p>
<p>In matrix form, this is saying that</p>
<div class="math notranslate nohighlight">
\[
M = Z^T B Z.
\]</div>
<p>So, given <span class="math notranslate nohighlight">\(B\)</span> and <span class="math notranslate nohighlight">\(Z\)</span>, we can generate an SBM as a special case of an inhomogeneous ER graph.</p>
<p>We implement the SBM model. We use blocks numbered <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sbm_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">block_assignments</span><span class="p">,</span> <span class="n">B</span><span class="p">):</span>

    <span class="n">num_blocks</span> <span class="o">=</span> <span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">num_blocks</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">Z</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">block_assignments</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">Z</span> <span class="o">@</span> <span class="n">B</span> <span class="o">@</span> <span class="n">Z</span><span class="o">.</span><span class="n">T</span>
    
    <span class="k">return</span> <span class="n">inhomogeneous_er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>NUMERICAL CORNER:</strong> Here is an example usage. We first pick a block assignment at random. Specifically, blocks are assigned randomly with <a class="reference external" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.choice.html#numpy.random.Generator.choice"><code class="docutils literal notranslate"><span class="pre">numpy.random.Generator.choice</span></code></a>. It produces two blocks by assigning each vertex with equal probability to either block, independently of all other choices.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">block_assignments</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>  <span class="c1"># randomly assign vertices to two blocks</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]])</span>

<span class="n">G</span> <span class="o">=</span> <span class="n">sbm_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">block_assignments</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We draw the graph with colored nodes based on block assignments. The “good” cut is clearly visible in this layout.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">spring_layout</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="n">block_assignments</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow&#39;</span><span class="p">,</span>
        <span class="n">node_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">font_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/3401f29c094a89b57b193bf4eb429dff7f9736babfdd16db237b5b77bb504eff.png" src="../../_images/3401f29c094a89b57b193bf4eb429dff7f9736babfdd16db237b5b77bb504eff.png" />
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p>We introduce a subroutine which assigns blocks at random as follows. Let <span class="math notranslate nohighlight">\(\beta_1, \beta_2 \in [0,1]\)</span> with <span class="math notranslate nohighlight">\(\beta_1 + \beta_2 = 1\)</span> be the probability that a vertex belongs respectively to block <span class="math notranslate nohighlight">\(1\)</span> and <span class="math notranslate nohighlight">\(2\)</span>. We collect these probabilities in the following vector</p>
<div class="math notranslate nohighlight">
\[
\bbeta = (\beta_1, \beta_2).
\]</div>
<p>We pick block <span class="math notranslate nohighlight">\(z(i) \in \{1,2\}\)</span> for each vertex <span class="math notranslate nohighlight">\(1 \leq i \leq n\)</span> according to the distribution <span class="math notranslate nohighlight">\(\bbeta\)</span>, independently of all other vertices <span class="math notranslate nohighlight">\(\neq i\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_block_assignments</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">beta</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">beta</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>NUMERICAL CORNER:</strong> Here is an example usage.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">beta</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.33</span><span class="p">,</span> <span class="mf">0.67</span><span class="p">]</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]])</span>

<span class="n">block_assignments</span> <span class="o">=</span> <span class="n">generate_block_assignments</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">sbm_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">block_assignments</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Observe that the blocks are more unbalanced this time.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">spring_layout</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="n">block_assignments</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">rainbow</span><span class="p">,</span>
        <span class="n">node_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">font_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">font_color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/56aedbc0a71e011ed9abd618d7d26d09407fa4210715558516940c3113ca161d.png" src="../../_images/56aedbc0a71e011ed9abd618d7d26d09407fa4210715558516940c3113ca161d.png" />
</div>
</div>
<p>To test our spectral partitioning algorithm, we run <code class="docutils literal notranslate"><span class="pre">spectral_cut2</span></code>, which indeed recovers the ground truth.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="p">(</span><span class="n">G</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">s</span><span class="p">,</span> <span class="n">sc</span> <span class="o">=</span> <span class="n">mmids</span><span class="o">.</span><span class="n">spectral_cut2</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">mmids</span><span class="o">.</span><span class="n">viz_cut</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/31f46fcc4a07fe19125fedabccbc210f90921696578d643703c3419486e4d530.png" src="../../_images/31f46fcc4a07fe19125fedabccbc210f90921696578d643703c3419486e4d530.png" />
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p>The following code computes the fraction of incorrectly assigned vertices. Note that it considers <em>two</em> assignments corresponding to swapping the labels <code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code> which cannot be inferred.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calculate_incorrect_fraction</span><span class="p">(</span><span class="n">block_assignments</span><span class="p">,</span> <span class="n">inferred_s</span><span class="p">,</span> <span class="n">inferred_sc</span><span class="p">):</span>
    
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">block_assignments</span><span class="p">)</span>
    
    <span class="n">inferred_assignments</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">inferred_s</span><span class="p">:</span>
        <span class="n">inferred_assignments</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">inferred_sc</span><span class="p">:</span>
        <span class="n">inferred_assignments</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    
    <span class="n">incorrect_assignments_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">block_assignments</span> <span class="o">!=</span> <span class="n">inferred_assignments</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>
    <span class="n">incorrect_assignments_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">block_assignments</span> <span class="o">==</span> <span class="n">inferred_assignments</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">incorrect_assignments_1</span><span class="p">,</span> <span class="n">incorrect_assignments_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>NUMERICAL CORNER:</strong> We confirm on our previous example that the ground truth was perfectly recovered.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fraction_incorrect</span> <span class="o">=</span> <span class="n">calculate_incorrect_fraction</span><span class="p">(</span><span class="n">block_assignments</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">sc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fraction of incorrectly assigned vertices: </span><span class="si">{</span><span class="n">fraction_incorrect</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fraction of incorrectly assigned vertices: 0.0
</pre></div>
</div>
</div>
</div>
<p>One expects that the ground truth is harder to recover if the probability of an edge between blocks is close to that within blocks, which makes the community structure more murky. To test this hypothesis, we modify our previous example by significantly increasing the inter-block probability.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">beta</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">]</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">]])</span>

<span class="n">block_assignments</span> <span class="o">=</span> <span class="n">generate_block_assignments</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">sbm_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">block_assignments</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We run <code class="docutils literal notranslate"><span class="pre">spectral_cut2</span></code>. It recovers the ground truth only partially this time.</p>
<div class="cell tag_colab-keep docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="p">(</span><span class="n">G</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">s</span><span class="p">,</span> <span class="n">sc</span> <span class="o">=</span> <span class="n">mmids</span><span class="o">.</span><span class="n">spectral_cut2</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">fraction_incorrect</span> <span class="o">=</span> <span class="n">calculate_incorrect_fraction</span><span class="p">(</span><span class="n">block_assignments</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">sc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fraction of incorrectly assigned vertices: </span><span class="si">{</span><span class="n">fraction_incorrect</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fraction of incorrectly assigned vertices: 0.22
</pre></div>
</div>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p><em><strong>Self-assessment quiz</strong></em> <em>(with help from Claude, Gemini, and ChatGPT)</em></p>
<p><strong>1</strong> In a stochastic blockmodel (SBM), what does <span class="math notranslate nohighlight">\(b_{i,j}\)</span> represent?</p>
<p>a) The probability that vertex <span class="math notranslate nohighlight">\(i\)</span> is assigned to block <span class="math notranslate nohighlight">\(j\)</span>.</p>
<p>b) The probability that there is an edge between any two vertices.</p>
<p>c) The probability that there is an edge between a vertex in block <span class="math notranslate nohighlight">\(C_i\)</span> and a vertex in block <span class="math notranslate nohighlight">\(C_j\)</span>.</p>
<p>d) The weight of the edge between vertex <span class="math notranslate nohighlight">\(i\)</span> and vertex <span class="math notranslate nohighlight">\(j\)</span>.</p>
<p><strong>2</strong> Consider the following graph generated using NetworkX in Python:</p>
<p><img alt="Graph" src="../../_images/quiz-5_6-graph1.png" /></p>
<p>Which of the following models could have produced this graph?</p>
<p>a) An Erdős-Rényi (ER) random graph.</p>
<p>b) A stochastic blockmodel (SBM) with two communities.</p>
<p>c) A symmetric stochastic blockmodel (SSBM) with two communities.</p>
<p>d) All of the above.</p>
<p><strong>3</strong> Consider an Erdős-Rényi (ER) random graph with <span class="math notranslate nohighlight">\(n\)</span> vertices and edge probability <span class="math notranslate nohighlight">\(p\)</span>. The expected number of edges in the graph is:</p>
<p>a) <span class="math notranslate nohighlight">\(n^2p\)</span></p>
<p>b) <span class="math notranslate nohighlight">\(\binom{n}{2}p\)</span></p>
<p>c) <span class="math notranslate nohighlight">\(np\)</span></p>
<p>d) <span class="math notranslate nohighlight">\(n(n-1)p\)</span></p>
<p><strong>4</strong> Consider the following Python code snippet:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">0.4</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_nodes_from</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">p</span><span class="p">:</span>
            <span class="n">G</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
</pre></div>
</div>
<p>Which of the following best describes the graph generated by this code?</p>
<p>a) An Erdős-Rényi (ER) random graph with <span class="math notranslate nohighlight">\(n=5\)</span> vertices and edge probability <span class="math notranslate nohighlight">\(p=0.4\)</span>.</p>
<p>b) A stochastic blockmodel (SBM) with <span class="math notranslate nohighlight">\(n=5\)</span> vertices and intra-block probability <span class="math notranslate nohighlight">\(p=0.4\)</span>.</p>
<p>c) A symmetric stochastic blockmodel (SSBM) with <span class="math notranslate nohighlight">\(n=5\)</span> vertices and inter-block probability <span class="math notranslate nohighlight">\(p=0.4\)</span>.</p>
<p>d) An inhomogeneous Erdős-Rényi (ER) random graph with <span class="math notranslate nohighlight">\(n=5\)</span> vertices and edge probabilities given by a matrix <span class="math notranslate nohighlight">\(M\)</span>.</p>
<p><strong>5</strong> In the stochastic blockmodel, what happens to the difficulty of recovering the community structure if the inter-block connection probability <span class="math notranslate nohighlight">\(b_{1,2}\)</span> is close to the intra-block connection probability <span class="math notranslate nohighlight">\(b_{1,1}\)</span>?</p>
<p>a) It becomes easier.</p>
<p>b) It remains unchanged.</p>
<p>c) It becomes harder.</p>
<p>d) None of the above.</p>
<p>Answer for 1: c. Justification: The text defines <span class="math notranslate nohighlight">\(b_{i,j}\)</span> as “the probability that a vertex in block <span class="math notranslate nohighlight">\(C_i\)</span> and a vertex in block <span class="math notranslate nohighlight">\(C_j\)</span> are connected by an edge.”</p>
<p>Answer for 2: d. Justification: The graph consists of two cliques (complete subgraphs) of size 3 each, one with vertices 0, 1, and 2 and another with vertices 3, 4, and 5. There are no edges between the two cliques. It has a positive probability of occurring under any ER, SBM, or SSBM random graph model where all edge probabilities are in <span class="math notranslate nohighlight">\((0,1)\)</span>.</p>
<p>Answer for 3: b. Justification: The text states: “Let’s compute the expected number of edges <span class="math notranslate nohighlight">\(G\)</span>. By summing over all pairs and using linearity of expectation, we have <span class="math notranslate nohighlight">\(\mathbb{E}[|E|] = \mathbb{E} [\sum_{i&lt;j} \mathbf{1}_{\{i,j\} \in E}] = \sum_{i&lt;j} \mathbb{E} [\mathbf{1}_{\{i,j\} \in E}] = \binom{n}{2}p\)</span>.”</p>
<p>Answer for 4: a. Justification: The code generates an ER random graph with <span class="math notranslate nohighlight">\(n=5\)</span> vertices, where each edge is included independently with probability <span class="math notranslate nohighlight">\(p=0.4\)</span>. This is evident from the nested loop structure and the condition <code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">rng.random()</span> <span class="pre">&lt;</span> <span class="pre">p</span></code> for adding edges.</p>
<p>Answer for 5: c. Justification: When the inter-block connection probability <span class="math notranslate nohighlight">\(b_{1,2}\)</span> is close to the intra-block connection probability <span class="math notranslate nohighlight">\(b_{1,1}\)</span>, the community structure becomes harder to recover because the distinction between the blocks is less clear.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chap05_specgraph/06_sbm"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../05_partitioning/roch-mmids-specgraph-partitioning.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">5.5. </span>Application: graph partitioning via spectral clustering</p>
      </div>
    </a>
    <a class="right-next"
       href="../exercises/roch-mmids-specgraph-exercises.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">5.7. </span>Exercises</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inhomogeneous-erdos-renyi-random-graph">5.6.1. Inhomogeneous Erdős-Rényi random graph</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-blockmodel">5.6.2. Stochastic blockmodel</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Sebastien Roch
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>