{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba8f38c6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-cell",
     "colab-keep"
    ]
   },
   "source": [
    "***\n",
    "\n",
    "*Course:* [Math 535](https://people.math.wisc.edu/~roch/mmids/) - Mathematical Methods in Data Science (MMiDS)  \n",
    "*Chapter:* 2-Least squares   \n",
    "*Author:* [Sebastien Roch](https://people.math.wisc.edu/~roch/), Department of Mathematics, University of Wisconsin-Madison  \n",
    "*Updated:* Jan 4, 2024   \n",
    "*Copyright:* &copy; 2024 Sebastien Roch\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f541ae",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# IF RUNNING ON GOOGLE COLAB, UNCOMMENT THE FOLLOWING CODE CELL\n",
    "# When prompted, upload: \n",
    "#     * mmids.py\n",
    "#     * advertising.csv \n",
    "# from your local file system\n",
    "# Files at: https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/tree/main/utils\n",
    "# Alternative instructions: https://colab.research.google.com/notebooks/io.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb4879b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-cell",
     "colab-uncomment"
    ]
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f00e44c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# PYTHON 3\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng(535)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import mmids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74afea33",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "## Motivating example: predicting sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89296689",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The following dataset is from [[ISLR]](http://faculty.marshall.usc.edu/gareth-james/ISL/). Quoting [ISLR, Section 2.1]:\n",
    "\n",
    "> Suppose that we are statistical consultants hired by a client to provide advice on how to improve sales of a particular product. The `Advertising` data set consists of the `sales` of that product in 200 different markets, along with advertising budgets for the product in each of those markets for three different media: `TV`, `radio`, and `newspaper`. [...] It is not possible for our client to directly increase sales of the product. On the other hand, they can control the advertising expenditure in each of the three media. Therefore, if we determine that there is an association between advertising and sales, then we can instruct our client to adjust advertising budgets, thereby indirectly increasing sales. In other words, our goal is to develop an accurate model that can be used to predict sales on the basis of the three media budgets.\n",
    "\n",
    "This a [regression](https://en.wikipedia.org/wiki/Regression_analysis) problem. That is, we want to estimate the relationship between an outcome variable and one or more predictors (or features). We load the data, show its first few lines and some statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ff4d1e",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('advertising.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b247c21",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312b2e45",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f911011",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We will focus for now on the TV budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3788f4d7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TV = df['TV'].to_numpy()\n",
    "sales = df['sales'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ba6083",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We make a scatterplot showing the realtion between those two quantities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2fb78e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.scatter(TV, sales)\n",
    "plt.xlabel('TV')\n",
    "plt.ylabel('sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85795d37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "There does seem to be a relationship between the two. Roughly a higher TV budget is linked to higher sales, although the correspondence is not perfect. To express the relationship more quantitatively, we seek a function $f$ such that\n",
    "\n",
    "$$\n",
    "y \\approx f(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "where $\\mathbf{x}$ denotes a sample TV budget and $y$ is the corresponding observed sales. We might posit for instance that there exists a true $f$ and that each observation is disrupted by some noise $\\varepsilon$\n",
    "\n",
    "$$\n",
    "y = f(\\mathbf{x}) + \\varepsilon.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09af9dd8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "A natural way to estimate such an $f$ from data is [$k$-nearest-neighbors ($k$-NN) regression](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm#k-NN_regression). Let the data be of the form $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^n$, where in our case $\\mathbf{x}_i$ is the TV budget of the $i$-th sample and $y_i$ is the corresponding sales. For each $\\mathbf{x}$ (not necessarily in the data), we do the following:\n",
    "\n",
    "- find the $k$ nearest $\\mathbf{x}_i$'s to $\\mathbf{x}$\n",
    "\n",
    "- take an average of the corresponding $y_i$'s. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20455cb1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We implement this method in Python. We use the function [`numpy.argsort`](https://numpy.org/doc/stable/reference/generated/numpy.argsort.html) to sort an array and the function [`numpy.absolute`](https://numpy.org/doc/stable/reference/generated/numpy.absolute.html) to compute the absolute deviation. Our quick implementation here assumes that the $\\mathbf{x}_i$'s are scalars, i.e., one-dimensional vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b033a1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def knnregression(x,y,k,xnew):\n",
    "    n = len(x)\n",
    "    closest = np.argsort([np.absolute(x[i]-xnew) for i in range(n)])\n",
    "    return np.mean(y[closest[0:k]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd224c90",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "For $k=3$ and a grid of $1000$ points, we get the following approximation $\\hat{f}$. Here the function [`numpy.linspace`](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html) creates an array of equally spaced points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fec3ad3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "xgrid = np.linspace(TV.min(), TV.max(), num=1000)\n",
    "yhat = [knnregression(TV,sales,k,xnew) for xnew in xgrid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b3d086",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.scatter(TV, sales, alpha=0.5)\n",
    "plt.xlabel('TV')\n",
    "plt.ylabel('sales')\n",
    "plt.plot(xgrid, yhat, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafade7c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "A higher $k$ gives something smoother."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58066d02",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "xgrid = np.linspace(TV.min(), TV.max(), num=1000)\n",
    "yhat = [knnregression(TV,sales,k,xnew) for xnew in xgrid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77c1d6f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.scatter(TV, sales, alpha=0.5)\n",
    "plt.xlabel('TV')\n",
    "plt.ylabel('sales')\n",
    "plt.plot(xgrid, yhat, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d876291",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "## Background: linear spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c8cb53",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**NUMERICAL CORNER:** The plane $P$ made of all points $(x,y,z) \\in \\mathbb{R}^3$ that satisfy $z = x+y$ is a linear subspace. Indeed, $0 = 0 + 0$ so $(0,0,0) \\in P$. And, for any $\\mathbf{u}_1 = (x_1, y_1, z_1)$ and $\\mathbf{u}_2 = (x_2, y_2, z_2)$ such that $z_1 = x_1 + y_1$ and $z_2 = x_2 + y_2$ and for any $\\alpha \\in \\mathbb{R}$, we have\n",
    "\n",
    "$$\n",
    "\\alpha z_1 + z_2 = \\alpha (x_1 + y_1) + (x_2 + y_2) = (\\alpha x_1 + x_2) + (\\alpha y_1 + y_2).\n",
    "$$\n",
    "\n",
    "That is, $\\alpha \\mathbf{u}_1 + \\mathbf{u}_2$ satisfies the condition defining $P$ and therefore is itself in $P$. Note also that $P$ passes through the origin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff3b2ed",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "In this example, the linear subspace $P$ can be described alternatively as the collection of every vector of the form $(x, y, x+y)$.\n",
    "\n",
    "We use [`plot_surface`](https://matplotlib.org/stable/api/_as_gen/mpl_toolkits.mplot3d.axes3d.Axes3D.html#mpl_toolkits.mplot3d.axes3d.Axes3D.plot_surface) to plot it over a grid of points created using [`numpy.meshgrid`](https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a1f2a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0,1,num=101)\n",
    "y = np.linspace(0,1,num=101)\n",
    "X, Y = np.meshgrid(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539297f1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe58d5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb59c698",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Z = X + Y\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88a7bf8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(X, Y, Z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e87a0c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\unlhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0061ea9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**NUMERICAL CORNER:** In Numpy, one can compute the rank of a matrix using the function [`numpy.linalg.matrix_rank`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.matrix_rank.html). We will see later in the course how to compute it using the singular value decomposition (which is how `LA.matrix_rank` does it).\n",
    "\n",
    "Let's try the example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e742ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "w1 = np.array([1., 0., 1.])\n",
    "w2 = np.array([0., 1., 1.])\n",
    "w3 = np.array([1., -1., 0.])\n",
    "A = np.stack((w1, w2, w3), axis=-1)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a78170b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We compute the rank of `A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208eedc7",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "LA.matrix_rank(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fe82ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We take only the first two columns of `A` this time to form `B`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d3030b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "B = np.stack((w1, w2),axis=-1)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c985975b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "LA.matrix_rank(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59ce30c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "In Numpy, `@` is used for matrix product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d5511d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "C = np.array([[1., 0., 1.],[0., 1., -1.]])\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3659c6ee",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LA.matrix_rank(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b1b9f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(B @ C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697b7bbb",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\unlhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300d3fee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "## Overdetermined linear systems and regression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27657769",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**NUMERICAL CORNER:** To solve a linear system in Numpy, use [`numpy.linalg.solve`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.solve.html). As an example, we consider the overdetermined system with\n",
    "\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "1 & 0\\\\\n",
    "0 & 1\\\\\n",
    "1 & 1\n",
    "\\end{pmatrix}\n",
    "\\quad\n",
    "\\text{and}\n",
    "\\quad\n",
    "\\mathbf{b} = \\begin{pmatrix}\n",
    "0\\\\\n",
    "0\\\\\n",
    "2\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "We use [`numpy.ndarray.T`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.T.html) for the transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2f50a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "w1 = np.array([1., 0., 1.])\n",
    "w2 = np.array([0., 1., 1.])\n",
    "A = np.stack((w1, w2),axis=-1)\n",
    "b = np.array([0., 0., 2.])\n",
    "x = LA.solve(A.T @ A, A.T @ b)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba508ff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We can also use [`numpy.linalg.lstsq`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.lstsq.html) directly on the overdetermined system to compute the least-square solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f7eb7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = LA.lstsq(A, b, rcond=None)[0]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a95e9d",
   "metadata": {
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\unlhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014a9974",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**NUMERICAL CORNER:** We implement back substitution in Python. In our naive implementation, we assume that the diagonal entries are not zero, which will suffice for our purposes. Here we use [`numpy.dot`](https://numpy.org/doc/stable/reference/generated/numpy.dot.html) to compute inner products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f81776",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def backsubs(R,b):\n",
    "    m = b.shape[0]\n",
    "    x = np.zeros(m)\n",
    "    for i in reversed(range(m)):\n",
    "        x[i] = (b[i] - np.dot(R[i,i+1:m],x[i+1:m]))/R[i,i]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7409adfa",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Forward substitution is implemented similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3615e5",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def forwardsubs(L,b):\n",
    "    m = b.shape[0]\n",
    "    x = np.zeros(m)\n",
    "    for i in range(m):\n",
    "        x[i] = (b[i] - np.dot(L[i,0:i],x[0:i]))/L[i,i]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e149b3",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\unlhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f9704b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**NUMERICAL CORNER:** We implement the algorithm above. In our naive implementation, we assume that $B$ is positive definite, and therefore that all steps are well-defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c924651",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def cholesky(B):\n",
    "    n = B.shape[0] \n",
    "    L = np.zeros((n, n))\n",
    "    for j in range(n):\n",
    "        L[j,0:j] = forwardsubs(L[0:j,0:j],B[j,0:j])\n",
    "        L[j,j] = np.sqrt(B[j,j] - LA.norm(L[j,0:j])**2)\n",
    "    return L "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788aed08",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Here is a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0038a8a5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "B = np.array([[2., 1.],[1., 2.]])\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502a1fc3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "L = cholesky(B)\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c279d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We can check that it produces the right factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac10df8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(L @ L.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a73a56f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\unlhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9216883c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**NUMERICAL CORNER:** We implement this algorithm below. In our naive implementation, we assume that $A$ has full column rank, and therefore that all steps are well-defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3cf5a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def ls_by_chol(A, b):\n",
    "    L = cholesky(A.T @ A)\n",
    "    z = forwardsubs(L, A.T @ b)\n",
    "    return backsubs(L.T, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619c0241",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\unlhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664a995a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**NUMERICAL CORNER:** We test our least-squares method on simulated data. This has the advantage that we know the truth.\n",
    "\n",
    "Suppose the truth is a linear function of one variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e6d3dc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n, b0, b1 = 100, -1, 1\n",
    "x = np.linspace(0,10,num=n)\n",
    "y = b0 + b1*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a42b698",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.scatter(x,y,alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec484c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "A perfect straight line is little too easy. So let's add some noise. That is, to each $y_i$ we add an independent random variable $\\varepsilon_i$ with a standard Normal distribution (mean $0$, variance $1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d2ff5b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y += rng.normal(0,1,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def71ed",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.scatter(x,y,alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11fbe4e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We form the matrix $A$ and use our least-squares code to solve for $\\boldsymbol{\\hat\\beta}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb77811",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "A = np.stack((np.ones(n),x),axis=-1)\n",
    "coeff = ls_by_chol(A,y)\n",
    "print(coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17142dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.scatter(x,y,alpha=0.5)\n",
    "plt.plot(x,coeff[0]+coeff[1]*x,'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a379766",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\unlhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12514b97",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**NUMERICAL CORNER:** Suppose the truth is in fact a degree-two polynomial of one variable with Gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538033b6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n, b0, b1, b2 = 100, 0, 0, 1\n",
    "x = np.linspace(0,10,num=n)\n",
    "y = b0 + b1 * x + b2 * x**2 + 10*rng.normal(0,1,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951942e3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.scatter(x,y,alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5308a766",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We form the matrix $A$ and use our least-squares code to solve for $\\boldsymbol{\\hat\\beta}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a109cb4a",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "A = np.stack((np.ones(n), x, x**2), axis=-1)\n",
    "coeff = ls_by_chol(A,y)\n",
    "print(coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7271c91",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.scatter(x,y,alpha=0.5)\n",
    "plt.plot(x, coeff[0] + coeff[1] * x + coeff[2] * x**2, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d162b8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\unlhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a9b234",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "## QR decomposition and Householder transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974faf73",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**NUMERICAL CORNER:** We implement the Gram-Schmidt algorithm in Python. For reasons that will become clear in a future section, we output both the $\\mathbf{q}_j$'s and $r_{ij}$'s, each in matrix form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d94c1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def gramschmidt(A):\n",
    "    (n,m) = A.shape\n",
    "    Q = np.zeros((n,m))\n",
    "    R = np.zeros((m,m))\n",
    "    for j in range(m):\n",
    "        v = np.copy(A[:,j])\n",
    "        for i in range(j):\n",
    "            R[i,j] = np.dot(Q[:,i], A[:,j])\n",
    "            v -= R[i,j]*Q[:,i]\n",
    "        R[j,j] = LA.norm(v)\n",
    "        Q[:,j] = v/R[j,j]\n",
    "    return Q, R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f1e135",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Let's try a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df819943",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "w1 = np.array([1., 0., 1.])\n",
    "w2 = np.array([0., 1., 1.])\n",
    "A = np.stack((w1, w2),axis=-1)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65e1fa9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Q, R = gramschmidt(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f003add4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792fb2ce",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d684a4",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\unlhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2537365c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**NUMERICAL CORNER:** We implement the QR approach to least squares and return to our previous linear regression example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969e9bee",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def ls_by_qr(A, b):\n",
    "    Q, R = gramschmidt(A)\n",
    "    return mmids.backsubs(R, Q.T @ b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279673e8",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "n, b0, b1 = 100, -1, 1\n",
    "x = np.linspace(0,10,num=n)\n",
    "y = b0 + b1*x + rng.normal(0,1,n)\n",
    "A = np.stack((np.ones(n),x),axis=-1)\n",
    "coeff = ls_by_qr(A,y)\n",
    "print(coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ea658f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.scatter(x,y,alpha=0.5)\n",
    "plt.plot(x,coeff[0]+coeff[1]*x,'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09539829",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\unlhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e789027",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**NUMERICAL CORNER:** We implement the procedure above in Python. We will need the following function. For $\\alpha \\in \\mathbb{R}$, let the sign of $\\alpha$ be\n",
    "\n",
    "$$\n",
    "\\mathrm{sign}(\\alpha)\n",
    "= \n",
    "\\begin{cases}\n",
    "1 & \\text{if $\\alpha > 0$}\\\\\n",
    "0 & \\text{if $\\alpha = 0$}\\\\\n",
    "-1 & \\text{if $\\alpha < 0$}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "For example, in Python, using the function [`numpy.sign`](https://numpy.org/doc/stable/reference/generated/numpy.sign.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6465cfc3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.sign(-10), np.sign(20), np.sign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe92bd1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The following function constructs the upper triangular matrix $R$ by iteratively modifying the relevant block of $A$. On the other hand, computing the matrix $Q$ actually requires extra computational work that is often not needed. We saw that, in the context of the least-squares problem, we really only need to compute $Q^T \\mathbf{b}$ for some input vector $\\mathbf{b}$. This can be done at the same time that $R$ is constructed, as follows. The key point to note is that $Q^T \\mathbf{b} = H_m \\cdots H_1 \\mathbf{b}$.\n",
    "\n",
    "See [here](https://numpy.org/doc/stable/reference/generated/numpy.copy.html) for an explanation of `numpy.copy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f552427e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def householder(A, b):\n",
    "    n, m = A.shape\n",
    "    R = np.copy(A)\n",
    "    Qtb = np.copy(b)\n",
    "    for k in range(m):\n",
    "    \n",
    "        # computing z\n",
    "        y = R[k:n,k]\n",
    "        e1 = np.zeros(n-k)\n",
    "        e1[0] = 1\n",
    "        z = np.sign(y[0]) * LA.norm(y) * e1 + y\n",
    "        z = z / LA.norm(z)\n",
    "        \n",
    "        # updating R\n",
    "        R[k:n,k:m] = R[k:n,k:m] - 2 * np.outer(z, z) @ R[k:n,k:m]\n",
    "        \n",
    "        # updating Qtb\n",
    "        Qtb[k:n] = Qtb[k:n] - 2 * np.outer(z, z) @ Qtb[k:n]\n",
    "    \n",
    "    return R[0:m,0:m], Qtb[0:m]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2dd127",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "In `householder`, we use both reflections defined above. We will not prove this here, but the particular choice made has good numerical properties. Quoting [TB, Lecture 10]:\n",
    "\n",
    "> Mathematically, either choice of sign is satisfactory. However, this is a case where numerical stability -- insensitivity to rounding errors -- dictates that one choice should be taken rather than the other. For numerical stability, it is desirable to reflect $\\mathbf{x}$ to the vector $z \\|\\mathbf{x}\\| \\mathbf{e}_1$ that is not too close to $\\mathbf{x}$ itself. [...] Suppose that [in the figure above] the angle between $H^+$ and the $\\mathbf{e}_1$ axis is very small. Then the vector $\\mathbf{v} = \\|\\mathbf{x}\\| \\mathbf{e}_1 - \\mathbf{x}$ is much smaller than $\\mathbf{x}$ or $\\|\\mathbf{x}\\| \\mathbf{e}_1$. Thus the calculation of $\\mathbf{v}$ represents a subtraction of nearby quantities and will tend to suffer from cancellation errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9bb76f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We return to our regression example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2600f8b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n, b0, b1, b2 = 100, 0, 0, 1\n",
    "x = np.linspace(0,10,num=n)\n",
    "y = b0 + b1*x + b2 * x**2 + 10*rng.normal(0,1,n)\n",
    "A = np.stack((np.ones(n), x, x**2), axis=-1)\n",
    "R, Qtb = householder(A, y)\n",
    "coeff = mmids.backsubs(R, Qtb)\n",
    "print(coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df24d59c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.scatter(x,y,alpha=0.5)\n",
    "plt.plot(x, coeff[0] + coeff[1]*x + coeff[2] * x**2, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa84dd88",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "One advantage of the Householder approach is that it produces a matrix $Q$ with very good orthogonality, i.e., $Q^T Q \\approx I$. We give a quick example below comparing Gram-Schmidt and Householder. (The choice of matrix $A$ will become clearer when we discuss the singular value decomposition later in the chapter.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c96d745",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n = 50\n",
    "U, W = LA.qr(rng.normal(0,1,(n,n)))\n",
    "V, W = LA.qr(rng.normal(0,1,(n,n)))\n",
    "S = np.diag((1/2) ** np.arange(1,n+1))\n",
    "A = U @ S @ V.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333136f2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Qgs, Rgs = gramschmidt(A)\n",
    "print(LA.norm(A - Qgs @ Rgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4991ea28",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(LA.norm(Qgs.T @ Qgs - np.identity(n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc6bdd0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "As you can see above, the $Q$ and $R$ factors produced by Gram-Schmidt do have the property that $QR \\approx A$. However, $Q$ is far from orthogonal. (Recall that `LA.norm` computes the Frobenius norm introduced previously.)\n",
    "\n",
    "On the other hand, Householder reflections perform much better in that respect as we show next. Here we use the implementation of Householder transformations in [`numpy.linalg.qr`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.qr.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b85368",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Qhh, Rhh = LA.qr(A)\n",
    "print(LA.norm(A - Qhh @ Rhh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d104a2db",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(LA.norm(Qhh.T @ Qhh - np.identity(n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e7b0e7",
   "metadata": {
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\unlhd$"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
