{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ac1e1d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-cell",
     "colab-keep"
    ]
   },
   "source": [
    "***\n",
    "\n",
    "*Course:* [Math 535](https://people.math.wisc.edu/~roch/mmids/) - Mathematical Methods in Data Science (MMiDS)  \n",
    "*Chapter:* 8-Deep neural networks, automatic differentiation, and stochastic gradient descent: building blocks of AI   \n",
    "*Author:* [Sebastien Roch](https://people.math.wisc.edu/~roch/), Department of Mathematics, University of Wisconsin-Madison  \n",
    "*Updated:* May 26, 2024   \n",
    "*Copyright:* &copy; 2024 Sebastien Roch\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e07d5f6",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# You will need the files:\n",
    "#     * mmids.py\n",
    "#     * advertising.csv \n",
    "#     * SAHeart.csv \n",
    "# from https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/tree/main/utils\n",
    "#\n",
    "# IF RUNNING ON GOOGLE COLAB (RECOMMENDED):\n",
    "# \"Upload to session storage\" from the Files tab on the left\n",
    "# Alternative instructions: https://colab.research.google.com/notebooks/io.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2292ba",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# PYTHON 3\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch\n",
    "import mmids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609b0073",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "## Motivating example:  classifying natural images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a504f1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "In this chapter, we return to the classification problem. This time we consider more complex datasets involving natural images. We have seen an example previously, the MNIST dataset. We use a related dataset known as Fashion-MNIST developed by the [Zalando Research](https://engineering.zalando.com/tags/zalando-research.html). Quoting from their [GitHub repository](https://github.com/zalandoresearch/fashion-mnist):\n",
    "\n",
    "> Fashion-MNIST is a dataset of Zalando's article images -- consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d6f6cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**Figure:** Fashion-MNIST sample images ([Source](https://github.com/zalandoresearch/fashion-mnist))\n",
    "\n",
    "![Fashion-MNIST sample images](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)\n",
    "\n",
    "$\\bowtie$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ff8e8e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We first load the data and convert it to an appropriate matrix representation. The data can be accessed with [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ec62d7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd45de4d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Download and load the MNIST dataset\n",
    "fashion_mnist = datasets.FashionMNIST(root='./data', \n",
    "                                      train=True, \n",
    "                                      download=True, \n",
    "                                      transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37134dc9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "For example, the first image and its label are the following. The [`squeeze()`](https://pytorch.org/docs/stable/generated/torch.Tensor.squeeze.html) below removes the color dimension in the image, which is grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba95bcf0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "img, label = fashion_mnist[0]\n",
    "plt.figure()\n",
    "plt.imshow(img.squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd8ef6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6208bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping of label numbers to class names\n",
    "class_names = [\n",
    "    \"T-shirt/top\", \n",
    "    \"Trouser\", \n",
    "    \"Pullover\", \n",
    "    \"Dress\", \n",
    "    \"Coat\", \n",
    "    \"Sandal\", \n",
    "    \"Shirt\", \n",
    "    \"Sneaker\", \n",
    "    \"Bag\", \n",
    "    \"Ankle boot\"\n",
    "]\n",
    "\n",
    "# Function to get the class name from a label\n",
    "def get_class_name(label):\n",
    "    return class_names[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2ab6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The label {label} corresponds to the class name '{get_class_name(label)}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c9b1c9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Here is a second example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aec63b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "img, label = fashion_mnist[1]\n",
    "plt.figure()\n",
    "plt.imshow(img.squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab66429",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "outputs": [],
   "source": [
    "get_class_name(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df7d4a2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The purpose of this chapter is to develop some of the mathematical tools used to solve this kind of classification problem:\n",
    "\n",
    "- deep neural networks\n",
    "- automatic differentiation\n",
    "- stochastic gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1716c1e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "## Background: Jacobian and Chain Rule; an introduction to automatic differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1029faee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "### Brief introduction to automatic differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e87acb6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We illustrate the use of [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation) to compute gradients. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ad72e6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Quoting [Wikipedia](https://en.wikipedia.org/wiki/Automatic_differentiation):\n",
    "\n",
    "> In mathematics and computer algebra, automatic differentiation (AD), also called algorithmic differentiation or computational differentiation, is a set of techniques to numerically evaluate the derivative of a function specified by a computer program. AD exploits the fact that every computer program, no matter how complicated, executes a sequence of elementary arithmetic operations (addition, subtraction, multiplication, division, etc.) and elementary functions (exp, log, sin, cos, etc.). By applying the chain rule repeatedly to these operations, derivatives of arbitrary order can be computed automatically, accurately to working precision, and using at most a small constant factor more arithmetic operations than the original program. Automatic differentiation is distinct from symbolic differentiation and numerical differentiation (the method of finite differences). Symbolic differentiation can lead to inefficient code and faces the difficulty of converting a computer program into a single expression, while numerical differentiation can introduce round-off errors in the discretization process and cancellation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc048840",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**Automatic differentiation in PyTorch** We will use [PyTorch](https://pytorch.org/tutorials/). It uses [tensors](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html), which in many ways behave similarly to Numpy arrays. See [here](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html) for a quick introduction. Here is an example. We first initialize the tensors. Here each tensor corresponds to a single real variable. With the option [`requires_grad=True`](https://pytorch.org/docs/stable/generated/torch.Tensor.requires_grad.html#torch.Tensor.requires_grad), we indicate that these are variables with respect to which a gradient will be taken later. We initialize the tensors at the values where the derivatives will be computed. If derivatives need to be computed at different values, we need to repeat this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c268e8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "x1 = torch.tensor(1.0, requires_grad=True)\n",
    "x2 = torch.tensor(2.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9835e9ff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The function [`.backward()`](https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html) computes the gradient using backpropagation, to which we will return later. The partial derivatives are accessed with [`.grad`](https://pytorch.org/docs/stable/generated/torch.Tensor.grad.html). We first define the function. Note that we use\n",
    "[`torch.exp`](https://pytorch.org/docs/stable/generated/torch.exp.html), the PyTorch implementation of the (element-wise) exponential function. Moreover, as in NumPy, PyTorch allows the use of `**` for [taking a power](https://pytorch.org/docs/stable/generated/torch.pow.html). [Here](https://pytorch.org/docs/stable/name_inference.html) is a list of operations on tensors in PyTorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7439a1e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Define function\n",
    "f = 3 * (x1 ** 2) + x2 + torch.exp(x1 * x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0e4eea",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Perform automatic differentiation\n",
    "f.backward()  # Compute gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be32ada",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Print gradients\n",
    "print(x1.grad)  # df/dx\n",
    "print(x2.grad)  # df/dy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd41f102",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The input parameters can also be vectors, which allows to consider functions of large numbers of variables. Here we use [`torch.sum`](https://pytorch.org/docs/stable/generated/torch.sum.html#torch.sum) for taking a sum of the arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5ca203",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# New variables for the second example\n",
    "z = torch.tensor([1., 2., 3.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38cafd4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Perform automatic differentiation\n",
    "g = torch.sum(z ** 2)\n",
    "g.backward()  # Compute gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b13bc2b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Print gradient\n",
    "print(z.grad)  # gradient is (2 z_1, 2 z_2, 2 z_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f58c04",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Here is another typical example in a data science context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b124cbc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Variables for the third example\n",
    "X = torch.randn(3, 2)  # Random dataset (features)\n",
    "y = torch.tensor([[1., 0., 1.]])  # Dataset (labels)\n",
    "theta = torch.ones(2, 1, requires_grad=True)  # Parameter assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676875f5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Perform automatic differentiation\n",
    "predict = X @ theta  # Classifier with parameter vector theta\n",
    "loss = torch.sum((predict - y)**2)  # Loss function\n",
    "loss.backward()  # Compute gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f158cd8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Print gradient\n",
    "print(theta.grad)  # gradient of loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9585b28",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**Implementing gradient descent in PyTorch** Rather than explicitly specifying the gradient function, we could use PyTorch to compute it automatically. This is done next. Note that the descent update is done within [`with torch.no_grad()`](https://pytorch.org/docs/stable/generated/torch.no_grad.html), which ensures that the update operation itself is not tracked for gradient computation. Here the input `x0` as well as the output `xk.numpy(force=True)` are Numpy arrays. The function [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) converts a PyTorch tensor to a Numpy array (see the documentation for an explanation of the `force=True` option). Also, quoting ChatGPT:\n",
    "\n",
    "> In the given code, `.item()` is used to extract the scalar value from a tensor. In PyTorch, when you perform operations on tensors, you get back tensors as results, even if the result is a single scalar value. `.item()` is used to extract this scalar value from the tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446e5063",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def gd_with_ad(f, x0, alpha=1e-3, niters=int(1e6)):\n",
    "    xk = torch.tensor(x0, \n",
    "                      requires_grad=True, \n",
    "                      dtype=torch.float)\n",
    "    \n",
    "    for _ in range(niters):\n",
    "        # Compute the function value and its gradient\n",
    "        value = f(xk)\n",
    "        value.backward()\n",
    "\n",
    "        # Perform a gradient descent step\n",
    "        # Temporarily set all requires_grad flags to False\n",
    "        with torch.no_grad():  \n",
    "            xk -= alpha * xk.grad\n",
    "\n",
    "        # Zero the gradients for the next iteration\n",
    "        xk.grad.zero_()\n",
    "\n",
    "    return xk.numpy(force=True), f(xk).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe21f770",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We revisit a previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5764ef17",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3f2b00",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "xgrid = np.linspace(-2,2,100)\n",
    "plt.plot(xgrid, f(xgrid), label='f')\n",
    "plt.ylim((-10,10))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f731f186",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "gd_with_ad(f, 2, niters=int(1e4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc7332",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gd_with_ad(f, -2, niters=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583abea9",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "$\\unlhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf58dc9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f60b10",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([1.,0.,-1.], requires_grad=True)\n",
    "y = torch.tensor([0.,1.])\n",
    "W0 = torch.tensor([[0.,1.,-1.],[2.,0.,1.]])\n",
    "W1 = torch.tensor([[-1.,0.],[2.,-1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b7f67",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "z0 = x\n",
    "z1 = W0 @ z0\n",
    "z2 = W1 @ z1\n",
    "f = 0.5 * (torch.linalg.vector_norm(y-z2) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa9fd7e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "print('z0 =',z0)\n",
    "print('z1 =',z1)\n",
    "print('z2 =',z2)\n",
    "print('f =',f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089608ad",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    F0 = W0\n",
    "    F1 = W1 @ F0\n",
    "    grad_f = (z2 - y).T @ F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80db7ad0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "print('F0 =', F0)\n",
    "print('F1 =', F1)\n",
    "print('grad_f =', grad_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cdb356",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5ff8cb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "print('x.grad =', x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcced9e9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    G2 = (z2 - y).T\n",
    "    G1 = G2 @ W1\n",
    "    grad_f = G1 @ W0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3956936d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "print('G2 =', G2)\n",
    "print('G1 =', G1)\n",
    "print('grad_f =', grad_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d2979e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([1.,0.,-1.])\n",
    "y = torch.tensor([0.,1.])\n",
    "W0 = torch.tensor([[0.,1.,-1.],[2.,0.,1.]], requires_grad=True)\n",
    "W1 = torch.tensor([[-1.,0.],[2.,-1.]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a58737",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "z0 = x\n",
    "z1 = W0 @ z0\n",
    "z2 = W1 @ z1\n",
    "f = 0.5 * (torch.linalg.vector_norm(y-z2) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e832c1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "print('z0 =',z0)\n",
    "print('z1 =',z1)\n",
    "print('z2 =',z2)\n",
    "print('f =',f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966a0adf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2d6d36",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "print('W0.grad =', W0.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a83ea11",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "print('W1.grad =', W1.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6c483e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    grad_W0 = torch.kron((z2 - y).T @ W1, z0.T)\n",
    "    grad_W1 = torch.kron((z2 - y).T, z1.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24a33bf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "print('grad_W0 =', grad_W0)\n",
    "print('grad_W1 =', grad_W1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0a6001",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "## Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd67ee0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(z): \n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def pred_fn(x, A): \n",
    "    return sigmoid(A @ x)\n",
    "\n",
    "def loss_fn(x, A, b): \n",
    "    return np.mean(-b*np.log(pred_fn(x, A)) - (1 - b)*np.log(1 - pred_fn(x, A)))\n",
    "\n",
    "def grad_fn(x, A, b):\n",
    "    return -A.T @ (b - pred_fn(x, A))/len(b)\n",
    "\n",
    "def desc_update_for_logreg(grad_fn, A, b, curr_x, beta):\n",
    "    gradient = grad_fn(curr_x, A, b)\n",
    "    return curr_x - beta*gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c948b202",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "seed = 535\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "def sgd_for_logreg(loss_fn, grad_fn, A, b, \n",
    "                   init_x, beta=1e-3, niters=int(1e5), batch=40):\n",
    "    \n",
    "    # initialization\n",
    "    curr_x = init_x\n",
    "    \n",
    "    # until the maximum number of iterations\n",
    "    nsamples = len(b)\n",
    "    for _ in range(niters):\n",
    "        I = rng.integers(nsamples, size=batch)\n",
    "        curr_x = desc_update_for_logreg(\n",
    "            grad_fn, A[I,:], b[I], curr_x, beta)\n",
    "    \n",
    "    return curr_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6294ec2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We analyze a dataset from [[ESL](https://web.stanford.edu/~hastie/ElemStatLearn/)], which can be downloaded [here](https://web.stanford.edu/~hastie/ElemStatLearn/data.html). Quoting [[ESL](https://web.stanford.edu/~hastie/ElemStatLearn/), Section 4.4.2] \n",
    "\n",
    "> The data [...] are a subset of the Coronary Risk-Factor Study (CORIS) baseline survey, carried out in three rural areas of the Western Cape, South Africa (Rousseauw et al., 1983). The aim of the study was to establish the intensity of ischemic heart disease risk factors in that high-incidence region. The data represent white males between 15 and 64, and the response variable is the presence or absence of myocardial infarction (MI) at the time of the survey (the overall prevalence of MI was 5.1% in this region). There are 160 cases in our data set, and a sample of 302 controls. These data are described in more detail in Hastie and Tibshirani (1987).\n",
    "\n",
    "We load the data, which we slightly reformatted and look at a summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a59ac4b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('SAHeart.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32212a5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Our goal to predict `chd`, which stands for coronary heart disease, based on the other variables (which are briefly described [here](https://web.stanford.edu/~hastie/ElemStatLearn/datasets/SAheart.info.txt)). We use logistic regression again. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd1fd36",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We first construct the data matrices. We only use three of the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3422d4aa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "feature = data[['tobacco', 'ldl', 'age']].to_numpy()\n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a60d772",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "label = data['chd'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0176b1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "A = np.concatenate((np.ones((len(label),1)),feature),axis=1)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26001c23",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "b = label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5cd89f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We try mini-batch SGD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f5b42e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "init_x = np.zeros(A.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23921d7a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "best_x = sgd_for_logreg(loss_fn, grad_fn, A, b, \n",
    "                        init_x, beta=1e-3, niters=int(1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04a78db",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(best_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb42083d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The outcome is harder to vizualize. To get a sense of how accurate the result is, we compare our predictions to the true labels. By prediction, let us say that we mean that we predict label $1$ whenever $\\sigma(\\boldsymbol{\\alpha}^T \\mathbf{x}) > 1/2$. We try this on the training set. (A better approach would be to split the data into training and testing sets, but we will not do this here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f6a03",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def logis_acc(x, A, b):\n",
    "    return np.sum((pred_fn(x, A) > 0.5) == b)/len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26637915",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "logis_acc(best_x, A, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d831b0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**The `Advertising` dataset and the least-squares solution** We return to the `Advertising` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e23004",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('advertising.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698a5334",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "n = len(data.index)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b6e1b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We first compute the solution using the least-squares approach we detailed previously. We use [`numpy.column_stack`](https://numpy.org/doc/stable/reference/generated/numpy.column_stack.html#numpy.column_stack) to add a column of ones to the feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577a8085",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "TV = data['TV'].to_numpy()\n",
    "radio = data['radio'].to_numpy()\n",
    "newspaper = data['newspaper'].to_numpy()\n",
    "sales = data['sales'].to_numpy()\n",
    "features = np.stack((TV, radio, newspaper), axis=-1)\n",
    "A = np.column_stack((np.ones(n), features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ac1977",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "coeff = mmids.ls_by_qr(A, sales)\n",
    "print(coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182c1139",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.mean((A @ coeff - sales)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b2319e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**Solving the problem using PyTorch** We will be using PyTorch to implement the previous method. We first convert the data into PyTorch tensors. We then use [`torch.utils.data.TensorDataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset) to create the dataset. Finally, [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) provides the utilities to load the data in batches for training. We take mini-batches of size `BATCH_SIZE = 64` and we apply a random permutation of the samples on every pass (with the option `shuffle=True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f647ee",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb5896d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "features_tensor = torch.tensor(features, \n",
    "                               dtype=torch.float32)\n",
    "sales_tensor = torch.tensor(sales, \n",
    "                            dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3abcfc2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataset and dataloader for training\n",
    "BATCH_SIZE = 64\n",
    "train_dataset = TensorDataset(features_tensor, sales_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c1494f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Now we construct our model. It is simply an affine map from $\\mathbb{R}^3$ to $\\mathbb{R}$. Note that there is no need to pre-process the inputs by adding $1$s. A constant term (or \"bias variable\") is automatically added by PyTorch (unless one chooses the option [`bias=False`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a5cf3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Define the model using nn.Sequential\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3, 1)  # 3 input features, 1 output value\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988856c7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Finally, we are ready to run an optimization method of our choice on the loss function, which are specified next. There are many [optimizers](https://pytorch.org/docs/stable/optim.html#algorithms) available. (See this [post](https://hackernoon.com/demystifying-different-variants-of-gradient-descent-optimization-algorithm-19ae9ba2e9bc) for a brief explanation of many common optimizers.) Here we use SGD as the optimizer. And the loss function is the MSE. A quick tutorial is [here](https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html).\n",
    "\n",
    "Choosing the right number of passes (i.e. epochs) through the data requires some experimenting. Here $10^4$ suffices. But in the interest of time, we will run it only for $100$ epochs. As you will see from the results, this is not quite enough. On each pass, we compute the output of the current model, use `backward()` to obtain the gradient, and then perform a descent update with `step()`. We also have to reset the gradients first (otherwise they add up by default). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523abdd4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model: define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc973646",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb2c021",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The final parameters and loss are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37708d3",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Get and print the model weights and bias\n",
    "weights = model[0].weight.detach().numpy()\n",
    "bias = model[0].bias.detach().numpy()\n",
    "print(\"Weights:\", weights)\n",
    "print(\"Bias:\", bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd91353",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    for inputs, targets in train_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Mean Squared Error on Training Set: {total_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a27d58b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**MNIST dataset** We will use the [MNIST](https://en.wikipedia.org/wiki/MNIST_database) dataset introduced earlier in the chapter. This example is inspired by [these](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html) [tutorials](https://www.tensorflow.org/tutorials/keras/classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1022db4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**Figure:** MNIST sample images ([Source](https://commons.wikimedia.org/wiki/File:MnistExamples.png))\n",
    "\n",
    "![MNIST sample images](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)\n",
    "\n",
    "$\\bowtie$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1081e4fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We first load the data. As before, the training dataset is a tensor -- think matrix with $3$ indices. One index runs through the $60,000$ training images, while the other two indices run through the horizontal and vertical pixel axes of each image. Here each image is $28 \\times 28$. The training labels are between $0$ and $9$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6f2f8f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Load and normalize the MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', \n",
    "                               train=True, \n",
    "                               download=True, \n",
    "                               transform=transforms.ToTensor())\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', \n",
    "                              train=False, \n",
    "                              download=True, \n",
    "                              transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3fbcf5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ccdd79",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**Implementation** We implement multinomial logistic regression to learn a classifier for the MNIST data. We first check for the availability of GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbb0f9c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                      else (\"mps\" if torch.backends.mps.is_available() \n",
    "                            else \"cpu\"))\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1444b06",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "In PyTorch, composition of functions can be achieved with [`torch.nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html). Our model is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e76b15",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Define the model using nn.Sequential and move it to the device (GPU if available)\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28 * 28, 10)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56460dc5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The [`torch.nn.Flatten`](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html) layer turns each input image into a vector of size $784$ (where $784 = 28^2$ is the number of pixels in each image). The final output is $10$-dimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200cdcf9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Here we use the [`torch.optim.Adam`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) optimizer (you can try SGD, but it is slow). The loss function is the [cross-entropy](https://en.wikipedia.org/wiki/Cross_entropy), as implemented by [`torch.nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html), which first takes the softmax and expects the labels to be class names rather than their one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02b8684",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model: define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8c4a29",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "In the interest of time, we train for 3 epochs only. An epoch is one training iteration where all samples are iterated once (in a randomly shuffled order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ec9d15",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(dataloader, model, loss_fn, optimizer, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Training loop\n",
    "def training_loop(train_loader, model, loss_fn, optimizer, device, epochs=3):\n",
    "    for epoch in range(epochs):\n",
    "        train(train_loader, model, loss_fn, optimizer, device)\n",
    "        \n",
    "        if (epoch+1) % 1 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515a29d3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "training_loop(train_loader, model, loss_fn, optimizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a699a245",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Because of the issue of [overfitting](https://en.wikipedia.org/wiki/Overfitting), we use the *test* images to assess the performance of the final classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af09b13",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def test(dataloader, model, loss_fn, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(dim=1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    accuracy = correct / size\n",
    "    print(f\"Test error: {(100*accuracy):>0.1f}% accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a94166c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test(test_loader, model, loss_fn, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f88d06",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "To make a prediction, we take a [`torch.nn.functional.softmax`](https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html) of the output of our model. Recall that it is implicitly included in `torch.nn.CrossEntropyLoss`, but is not actually part of `model`. (Note that the softmax itself has no parameter.) \n",
    "\n",
    "As an illustration, we do this for each test image. We use [`torch.cat`](https://pytorch.org/docs/stable/generated/torch.cat.html) to concatenate a sequence of tensors into a single tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf55a7e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_softmax(dataloader, model, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            probabilities = F.softmax(pred, dim=1)\n",
    "            predictions.append(probabilities.cpu())  # Move predictions to CPU\n",
    "\n",
    "    return torch.cat(predictions, dim=0)\n",
    "\n",
    "predictions = predict_softmax(test_loader, model, device).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b4bcc6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The result for the first test image is shown below. To make a prediction, we choose the label with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429e4f02",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812c81d9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "predictions[0].argmax(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873d962a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The truth is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb842750",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(test_loader))\n",
    "images = images.squeeze().numpy()\n",
    "labels = labels.numpy()\n",
    "labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391b9095",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Above, `next(iter(test_loader))` loads the first batch of test images. (See [here](https://docs.python.org/3/tutorial/classes.html#iterators) for background on iterators in Python.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad280b4",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The following code, adapted from [here](https://www.tensorflow.org/tutorials/keras/classification), provides a neat vizualization of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbf19fb",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "class_names = ['0', '1', '2', '3', '4',\n",
    "               '5', '6', '7', '8', '9']\n",
    "\n",
    "def plot_image(predictions_array, true_label, img):\n",
    "    \n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(f\"{class_names[predicted_label]} {100*np.max(predictions_array):2.0f}% ({class_names[true_label]})\", \n",
    "               color=color)\n",
    "\n",
    "def plot_value_array(predictions_array, true_label):\n",
    "    \n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    " \n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a187b6e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Here's the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992f4cc8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualization code for individual image\n",
    "i = 0\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(predictions[i], labels[i], images[i])  \n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(predictions[i], labels[i]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7667db3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "This one is a little less clear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028565da",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualization code for individual and multiple images\n",
    "i = 11\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(predictions[i], labels[i], images[i])  \n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(predictions[i], labels[i]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e2c0c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "This one is wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b597908",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualization code for individual and multiple images\n",
    "i = 8\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(predictions[i], labels[i], images[i])  \n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(predictions[i], labels[i]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ba4cca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "## Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbb1de0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**NUMERICAL CORNER:** We return to the concrete example from the previous section. We re-write the gradient as\n",
    "\n",
    "\\begin{align*}\n",
    "\\nabla f(\\mathbf{w})^T\n",
    "&= \\begin{pmatrix}\n",
    "[(\\mathbf{z}_2 - \\mathbf{y})^T\n",
    "\\mathcal{W}_{1} \\mathrm{diag}(\\mathbf{z}_1 \\odot (\\mathbf{1} - \\mathbf{z}_1))] \\otimes \\mathbf{z}_0^T &\n",
    "(\\mathbf{z}_2 - \\mathbf{y})^T\n",
    "\\otimes \\mathbf{z}_1^T\n",
    "\\end{pmatrix}.\n",
    "\\end{align*}\n",
    "\n",
    "We will use [`torch.nn.functional.sigmoid`](https://pytorch.org/docs/stable/generated/torch.nn.functional.sigmoid.html) and\n",
    "[`torch.nn.functional.softmax`](https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html) for the sigmoid and softmax functions respectively. We also use [`torch.dot`](https://pytorch.org/docs/stable/generated/torch.dot.html) for the inner product (i.e., dot product) of two vectors (as tensors) and [`torch.diag`](https://pytorch.org/docs/stable/generated/torch.diag.html) for the creation of a diagonal matrix with specified entries on its diagonal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdfb406",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f17bb95",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([1.,0.,-1.])\n",
    "y = torch.tensor([0.,1.])\n",
    "W0 = torch.tensor([[0.,1.,-1.],[2.,0.,1.]], requires_grad=True)\n",
    "W1 = torch.tensor([[-1.,0.],[2.,-1.]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b513a2a6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "z0 = x\n",
    "z1 = F.sigmoid(W0 @ z0)\n",
    "z2 = F.softmax(W1 @ z1)\n",
    "f = -torch.dot(torch.log(z2), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6df472",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "print('z0 =',z0)\n",
    "print('z1 =',z1)\n",
    "print('z2 =',z2)\n",
    "print('f =',f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c7b907",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We compute the gradient $\\nabla f(\\mathbf{w})$ using AD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d381970",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7269ccd8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "print('W0.grad =', W0.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606113d0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "print('W1.grad =', W1.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ad4df9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We use our formulas to confirm that they match these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7231e3fb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    grad_W0 = torch.kron((z2 - y).T @ W1 @ torch.diag(z1 * (1-z1)), z0.T)\n",
    "    grad_W1 = torch.kron((z2 - y).T, z1.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e663e19",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "print('grad_W0 =', grad_W0)\n",
    "print('grad_W1 =', grad_W1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b89ce3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The results match with the AD output. $\\unlhd$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de05d754",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**Implementation** We implement the training of a neural network in PyTorch. We use the MNIST dataset again. We first load it again. We also check for the availability of GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8325a7ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fd3a66",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='./data', \n",
    "                               train=True, \n",
    "                               download=True, \n",
    "                               transform=transforms.ToTensor())\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', \n",
    "                              train=False, \n",
    "                              download=True, \n",
    "                              transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ab31ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297bd648",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                      else (\"mps\" if torch.backends.mps.is_available() \n",
    "                            else \"cpu\"))\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db15ca9c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We construct a three-layer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95493382",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Flatten(),                      # Flatten the input\n",
    "    nn.Linear(28 * 28, 32),            # First Linear layer with 32 nodes\n",
    "    nn.Sigmoid(),                      # Sigmoid activation function\n",
    "    nn.Linear(32, 10)                  # Second Linear layer with 10 nodes (output layer)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4004b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "As we did for multinomial logistic regression, we use the Adam optimizer and the cross-entropy loss (which in PyTorch includes the softmax function and expects labels to be class names rather than one-hot encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aacc68",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63132cf3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Again, we train for 3 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c74105",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "mmids.training_loop(train_loader, model, loss_fn, optimizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635f6870",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "On the test data, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5a9dc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mmids.test(test_loader, model, loss_fn, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d46851",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "This is a significantly more accurate model than what we obtained using multinomial logistic regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d504e7f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "One can do even better using a neural network tailored for images, known as [convolutional neural networks](https://cs231n.github.io/convolutional-networks/). From [Wikipedia](https://en.wikipedia.org/wiki/Convolutional_neural_network):\n",
    "\n",
    "> In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery. They are also known as shift invariant or space invariant artificial neural networks (SIANN), based on their shared-weights architecture and translation invariance characteristics.\n",
    "\n",
    "More background can be found in this excellent [module](http://cs231n.github.io/convolutional-networks/) from Stanford's [CS231n](http://cs231n.github.io/). Our CNN will be a composition of [convolutional layers](http://cs231n.github.io/convolutional-networks/#conv) and [pooling layers](http://cs231n.github.io/convolutional-networks/#pool)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3144ac",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "**LEARNING BY CHATTING:** Ask your favorite AI chatbot to explain what are convolutional and pooling layers. $\\ddagger$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd693b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The new model is the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be590332",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    # First convolution, operating upon a 28x28 image\n",
    "    nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    # Second convolution, operating upon a 14x14 image\n",
    "    nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    # Third convolution, operating upon a 7x7 image\n",
    "    nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    # Flatten the tensor\n",
    "    nn.Flatten(),\n",
    "\n",
    "    # Fully connected layer\n",
    "    nn.Linear(32 * 3 * 3, 10),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abadcfd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "We train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87075e64",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02977e56",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mmids.training_loop(train_loader, model, loss_fn, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796c503e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mmids.test(test_loader, model, loss_fn, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c853db8f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The accuracy has indeed improved markedly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45287ad6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "Finally, we try the Fashion-MNIST dataset. We use the same CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f966e797",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.FashionMNIST(root='./data', \n",
    "                                      train=True, \n",
    "                                      download=True, \n",
    "                                      transform=transforms.ToTensor())\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(root='./data', \n",
    "                                     train=False, \n",
    "                                     download=True, \n",
    "                                     transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093ba081",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e80988",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd0cbfd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mmids.training_loop(train_loader, model, loss_fn, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d7b429",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mmids.test(test_loader, model, loss_fn, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b468ae7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "colab-keep"
    ]
   },
   "source": [
    "The accuracy is not as high, as this is a more difficult dataset."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
