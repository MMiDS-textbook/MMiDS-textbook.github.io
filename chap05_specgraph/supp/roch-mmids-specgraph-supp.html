
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>5.8. Online supplementary material &#8212; MMiDS Textbook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-P5E8DW088F"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-P5E8DW088F');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-P5E8DW088F');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chap05_specgraph/supp/roch-mmids-specgraph-supp';</script>
    <link rel="canonical" href="https://mmids-textbook.github.io/chap05_specgraph/supp/roch-mmids-specgraph-supp.html" />
    <link rel="icon" href="https://mmids-textbook.github.io/favicon-32x32.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="6. Probabilistic models: from simple to complex" href="../../chap06_prob/00_intro/roch-mmids-prob-intro.html" />
    <link rel="prev" title="5.7. Exercises" href="../exercises/roch-mmids-specgraph-exercises.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/mmids-cover-small.jpg" class="logo__image only-light" alt="MMiDS Textbook - Home"/>
    <script>document.write(`<img src="../../_static/mmids-cover-small.jpg" class="logo__image only-dark" alt="MMiDS Textbook - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    <b>MATHEMATICAL METHODS in DATA SCIENCE (with Python)</b>
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../chap01_intro/00_intro/roch-mmids-intro-intro.html">1. Introduction: a first data science problem</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chap01_intro/01_motiv/roch-mmids-intro-motiv.html">1.1. Motivating example: identifying penguin species</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap01_intro/02_review/roch-mmids-intro-review.html">1.2. Background: quick refresher of matrix algebra, differential calculus, and elementary probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap01_intro/03_clustering/roch-mmids-intro-clustering.html">1.3. Clustering: an objective, an algorithm and a guarantee</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap01_intro/04_highdim/roch-mmids-intro-highdim.html">1.4. Some observations about high-dimensional data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap01_intro/exercises/roch-mmids-intro-exercises.html">1.5. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap01_intro/supp/roch-mmids-intro-supp.html">1.6. Online suppplementary material</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../chap02_ls/00_intro/roch-mmids-ls-intro.html">2. Least squares: geometric, algebraic, and numerical aspects</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/01_motiv/roch-mmids-ls-motiv.html">2.1. Motivating example: predicting sales</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/02_spaces/roch-mmids-ls-spaces.html">2.2. Background: review of vector spaces and matrix inverses</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/03_orthog/roch-mmids-ls-orthog.html">2.3. Geometry of least squares: the orthogonal projection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/04_qr/roch-mmids-ls-qr.html">2.4. QR decomposition and Householder transformations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/05_regression/roch-mmids-ls-regression.html">2.5. Application: regression analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/exercises/roch-mmids-ls-exercises.html">2.6. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/supp/roch-mmids-ls-supp.html">2.7. Online suppplementary material</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../chap03_opt/00_intro/roch-mmids-opt-intro.html">3. Optimization theory and algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/01_motiv/roch-mmids-opt-motiv.html">3.1. Motivating example:  analyzing customer satisfaction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/02_several/roch-mmids-opt-several.html">3.2. Background: review of differentiable functions of several variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/03_optimality/roch-mmids-opt-optimality.html">3.3. Optimality conditions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/04_convexity/roch-mmids-opt-convexity.html">3.4. Convexity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/05_gd/roch-mmids-opt-gd.html">3.5. Gradient descent and its convergence analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/06_logistic/roch-mmids-opt-logistic.html">3.6. Application: logistic regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/exercises/roch-mmids-opt-exercises.html">3.7. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/supp/roch-mmids-opt-supp.html">3.8. Online suppplementary material</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../chap04_svd/00_intro/roch-mmids-svd-intro.html">4. Singular value decomposition</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/01_motiv/roch-mmids-svd-motiv.html">4.1. Motivating example: visualizing viral evolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/02_spectral/roch-mmids-svd-spectral.html">4.2. Background: review of matrix rank  and spectral decomposition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/03_svd/roch-mmids-svd-svd.html">4.3. Approximating subspaces and the SVD</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/04_power/roch-mmids-svd-power.html">4.4. Power iteration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/05_pca/roch-mmids-svd-pca.html">4.5. Application: principal components analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/06_further/roch-mmids-svd-further.html">4.6. Further applications of the SVD: low-rank approximations and ridge regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/exercises/roch-mmids-svd-exercises.html">4.7. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/supp/roch-mmids-svd-supp.html">4.8. Online suppplementary material</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../00_intro/roch-mmids-specgraph-intro.html">5. Spectral graph theory</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../01_motiv/roch-mmids-specgraph-motiv.html">5.1. Motivating example: uncovering social groups</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02_graph/roch-mmids-specgraph-graph.html">5.2. Background: basic concepts in graph theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03_extremal/roch-mmids-specgraph-extremal.html">5.3. Variational characterization of eigenvalues</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04_laplacian/roch-mmids-specgraph-laplacian.html">5.4. Spectral properties of the Laplacian matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../05_partitioning/roch-mmids-specgraph-partitioning.html">5.5. Application: graph partitioning via spectral clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06_sbm/roch-mmids-specgraph-sbm.html">5.6. Erdős-Rényi random graph and stochastic blockmodel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/roch-mmids-specgraph-exercises.html">5.7. Exercises</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">5.8. Online supplementary material</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../chap06_prob/00_intro/roch-mmids-prob-intro.html">6. Probabilistic models: from simple to complex</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chap06_prob/01_motiv/roch-mmids-prob-motiv.html">6.1. Motivating example: tracking location</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap06_prob/02_parametric/roch-mmids-prob-parametric.html">6.2. Background: introduction to parametric families and maximum likelihood estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap06_prob/03_joint/roch-mmids-prob-joint.html">6.3. Modeling more complex dependencies 1: using conditional independence</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap06_prob/04_em/roch-mmids-prob-em.html">6.4. Modeling more complex dependencies 2: marginalizing out an unobserved variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap06_prob/05_kalman/roch-mmids-prob-kalman.html">6.5. Application: linear-Gaussian models and Kalman filtering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap06_prob/exercises/roch-mmids-prob-exercises.html">6.6. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap06_prob/supp/roch-mmids-prob-supp.html">6.7. Online supplementary material</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../chap07_rwmc/00_intro/roch-mmids-rwmc-intro.html">7. Random walks on graphs and Markov chains</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/01_motiv/roch-mmids-rwmc-motiv.html">7.1. Motivating example: discovering mathematical topics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/02_mcdefs/roch-mmids-rwmc-mcdefs.html">7.2. Background: elements of finite Markov chains</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/03_stat/roch-mmids-rwmc-stat.html">7.3. Limit behavior 1: stationary distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/04_mclimit/roch-mmids-rwmc-mclimit.html">7.4. Limit behavior 2: convergence to equilibrium</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/05_pagerank/roch-mmids-rwmc-pagerank.html">7.5. Application: random walks on graphs and PageRank</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/06_gibbs/roch-mmids-rwmc-gibbs.html">7.6. Further applications: Gibbs sampling and generating images</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/exercises/roch-mmids-rwmc-exercises.html">7.7. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/supp/roch-mmids-rwmc-supp.html">7.8. Online supplementary material</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../chap08_nn/00_intro/roch-mmids-nn-intro.html">8. Neural networks, backpropagation and stochastic gradient descent</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chap08_nn/01_motiv/roch-mmids-nn-motiv.html">8.1. Motivating example:  classifying natural images</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap08_nn/02_chain/roch-mmids-nn-chain.html">8.2. Background: Jacobian, chain rule, and a brief introduction to automatic differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap08_nn/03_backprop/roch-mmids-nn-backprop.html">8.3. Building blocks of AI 1: backpropagation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap08_nn/04_sgd/roch-mmids-nn-sgd.html">8.4. Building blocks of AI 2: stochastic gradient descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap08_nn/05_nn/roch-mmids-nn-nn.html">8.5. Building blocks of AI 3: neural networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap08_nn/exercises/roch-mmids-nn-exercises.html">8.6. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap08_nn/supp/roch-mmids-nn-supp.html">8.7. Online supplementary material</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/MMiDS-textbook/MMiDS-textbook.github.io" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/issues/new?title=Issue%20on%20page%20%2Fchap05_specgraph/supp/roch-mmids-specgraph-supp.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/chap05_specgraph/supp/roch-mmids-specgraph-supp.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Online supplementary material</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quizzes-solutions-code-etc">5.8.1. Quizzes, solutions, code, etc.</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#just-the-code">5.8.1.1. Just the code</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#self-assessment-quizzes">5.8.1.2. Self-assessment quizzes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#auto-quizzes">5.8.1.3. Auto-quizzes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#solutions-to-odd-numbered-warm-up-exercises">5.8.1.4. Solutions to odd-numbered warm-up exercises</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-outcomes">5.8.1.5. Learning outcomes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-sections">5.8.2. Additional sections</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#spectral-properties-of-sbm">5.8.2.1. Spectral properties of SBM</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#weyls-inequality">5.8.2.2. Weyl’s inequality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#weighted-case">5.8.2.3. Weighted case</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#image-segmentation">5.8.2.4. Image segmentation</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p><span class="math notranslate nohighlight">\(\newcommand{\bSigma}{\boldsymbol{\Sigma}}\)</span> <span class="math notranslate nohighlight">\(\newcommand{\bmu}{\boldsymbol{\mu}}\)</span></p>
<section id="online-supplementary-material">
<h1><span class="section-number">5.8. </span>Online supplementary material<a class="headerlink" href="#online-supplementary-material" title="Link to this heading">#</a></h1>
<section id="quizzes-solutions-code-etc">
<h2><span class="section-number">5.8.1. </span>Quizzes, solutions, code, etc.<a class="headerlink" href="#quizzes-solutions-code-etc" title="Link to this heading">#</a></h2>
<section id="just-the-code">
<h3><span class="section-number">5.8.1.1. </span>Just the code<a class="headerlink" href="#just-the-code" title="Link to this heading">#</a></h3>
<p>An interactive Jupyter notebook featuring the code in this chapter can be accessed below (Google Colab recommended). You are encouraged to tinker with it. Some suggested computational exercises are scattered throughout. The notebook is also available as a slideshow.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb">Notebook</a> (<a class="reference external" href="https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_specgraph_notebook.ipynb">Open In Colab</a>)</p></li>
<li><p><a class="reference external" href="https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/just_the_code/roch_mmids_chap_specgraph_notebook_slides.slides.html">Slideshow</a></p></li>
</ul>
</section>
<section id="self-assessment-quizzes">
<h3><span class="section-number">5.8.1.2. </span>Self-assessment quizzes<a class="headerlink" href="#self-assessment-quizzes" title="Link to this heading">#</a></h3>
<p>A more extensive web version of the self-assessment quizzes is available by following the links below.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_2.html">Section 5.2</a></p></li>
<li><p><a class="reference external" href="https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_3.html">Section 5.3</a></p></li>
<li><p><a class="reference external" href="https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_4.html">Section 5.4</a></p></li>
<li><p><a class="reference external" href="https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_5.html">Section 5.5</a></p></li>
<li><p><a class="reference external" href="https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_5_6.html">Section 5.6</a></p></li>
</ul>
</section>
<section id="auto-quizzes">
<h3><span class="section-number">5.8.1.3. </span>Auto-quizzes<a class="headerlink" href="#auto-quizzes" title="Link to this heading">#</a></h3>
<p>Automatically generated quizzes for this chapter can be accessed here (Google Colab recommended).</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-specgraph-autoquiz.ipynb">Auto-quizzes</a>
(<a class="reference external" href="https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-specgraph-autoquiz.ipynb">Open In Colab</a>)</p></li>
</ul>
</section>
<section id="solutions-to-odd-numbered-warm-up-exercises">
<h3><span class="section-number">5.8.1.4. </span>Solutions to odd-numbered warm-up exercises<a class="headerlink" href="#solutions-to-odd-numbered-warm-up-exercises" title="Link to this heading">#</a></h3>
<p><em>(with help from Claude, Gemini, and ChatGPT)</em></p>
<p><strong>E5.2.1</strong> <span class="math notranslate nohighlight">\(V = \{1, 2, 3, 4\}\)</span>, <span class="math notranslate nohighlight">\(E = \{\{1, 2\}, \{1, 3\}, \{2, 4\}, \{3, 4\}\}\)</span>. This follows directly from the definition of a graph as a pair <span class="math notranslate nohighlight">\(G = (V, E)\)</span>.</p>
<p><strong>E5.2.3</strong> One possible path is <span class="math notranslate nohighlight">\(1 \sim 2 \sim 4\)</span>. Its length is 2, since it consists of two edges.</p>
<p><strong>E5.2.5</strong> <span class="math notranslate nohighlight">\(\delta^-(2) = 1\)</span>, <span class="math notranslate nohighlight">\(\delta^+(2) = 2\)</span>. The in-degree of a vertex <span class="math notranslate nohighlight">\(v\)</span> is the number of edges with destination <span class="math notranslate nohighlight">\(v\)</span>, and the out-degree is the number of edges with source <span class="math notranslate nohighlight">\(v\)</span>.</p>
<p><strong>E5.2.7</strong> The graph <span class="math notranslate nohighlight">\(G\)</span> is not connected. There is no path between vertex 1 and vertex 4, indicating that the graph is not connected.</p>
<p><strong>E5.2.9</strong> The number of connected components is 1. There is a path between every pair of vertices, so the graph is connected, having only one connected component.</p>
<p><strong>E5.2.11</strong></p>
<div class="math notranslate nohighlight">
\[\begin{split}
B = \begin{pmatrix} 1 &amp; 1 &amp; 0 &amp; 0 \\ 1 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 1 &amp; 0 &amp; 1 \\ 0 &amp; 0 &amp; 1 &amp; 1 \end{pmatrix}.
\end{split}\]</div>
<p>The entry <span class="math notranslate nohighlight">\(B_{ij}\)</span> is 1 if vertex <span class="math notranslate nohighlight">\(i\)</span> is incident to edge <span class="math notranslate nohighlight">\(j\)</span>, and 0 otherwise.</p>
<p><strong>E5.2.13</strong></p>
<div class="math notranslate nohighlight">
\[\begin{split}
B = \begin{pmatrix} -1 &amp; 0 &amp; 1 &amp; 0 \\ 1 &amp; -1 &amp; 0 &amp; -1 \\ 0 &amp; 1 &amp; -1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{pmatrix}.
\end{split}\]</div>
<p>The entry <span class="math notranslate nohighlight">\(B_{ij}\)</span> is 1 if edge <span class="math notranslate nohighlight">\(j\)</span> leaves vertex <span class="math notranslate nohighlight">\(i\)</span>, -1 if edge <span class="math notranslate nohighlight">\(j\)</span> enters vertex <span class="math notranslate nohighlight">\(i\)</span>, and 0 otherwise.</p>
<p><strong>E5.2.15</strong> The Petersen graph is 3-regular, as stated in the text.</p>
<p><strong>E5.3.1</strong> We can find the eigenvectors of <span class="math notranslate nohighlight">\(A\)</span> and normalize them to get an orthonormal basis. The characteristic polynomial of <span class="math notranslate nohighlight">\(A\)</span> is <span class="math notranslate nohighlight">\((5-\lambda)^2 - 9 = \lambda^2 - 10\lambda + 16 = (\lambda - 2)(\lambda - 8)\)</span>, so the eigenvalues are 2 and 8. For <span class="math notranslate nohighlight">\(\lambda = 2\)</span>, an eigenvector is <span class="math notranslate nohighlight">\(\begin{pmatrix} -1 \\ 1 \end{pmatrix}\)</span>, and for <span class="math notranslate nohighlight">\(\lambda = 8\)</span>, an eigenvector is <span class="math notranslate nohighlight">\(\begin{pmatrix} 1 \\ 1 \end{pmatrix}\)</span>. Normalizing these vectors, we get the matrix</p>
<div class="math notranslate nohighlight">
\[\begin{split}
W = \begin{pmatrix} -1/\sqrt{2} &amp; 1/\sqrt{2} \\ 1/\sqrt{2} &amp; 1/\sqrt{2} \end{pmatrix}.
\end{split}\]</div>
<p><strong>E5.3.3</strong> <span class="math notranslate nohighlight">\(R_A(u) = \frac{\langle u, Au \rangle}{\langle u, u \rangle} = \langle u, Au \rangle = \begin{pmatrix} \frac{\sqrt{3}}{2} &amp; \frac{1}{2} \end{pmatrix} \begin{pmatrix} 3 &amp; 1 \\ 1 &amp; 2 \end{pmatrix} \begin{pmatrix} \frac{\sqrt{3}}{2} \\ \frac{1}{2} \end{pmatrix} = \frac{7}{2}\)</span>.</p>
<p><strong>E5.3.5</strong> To find the eigenvalues, we solve the characteristic equation:
<span class="math notranslate nohighlight">\(\det(A - \lambda I) = \begin{vmatrix} 2-\lambda &amp; -1 \\ -1 &amp; 2-\lambda \end{vmatrix} = (2-\lambda)^2 - 1 = \lambda^2 - 4\lambda + 3 = (\lambda - 1)(\lambda - 3) = 0\)</span>.
So the eigenvalues are <span class="math notranslate nohighlight">\(\lambda_1 = 3\)</span> and <span class="math notranslate nohighlight">\(\lambda_2 = 1\)</span>. To find the eigenvectors, we solve <span class="math notranslate nohighlight">\((A - \lambda_i I)v_i = 0\)</span> for each eigenvalue:
For <span class="math notranslate nohighlight">\(\lambda_1 = 3\)</span>: <span class="math notranslate nohighlight">\(\begin{pmatrix} -1 &amp; -1 \\ -1 &amp; -1 \end{pmatrix}v_1 = 0\)</span>, which gives <span class="math notranslate nohighlight">\(v_1 = c\begin{pmatrix} 1 \\ -1 \end{pmatrix}\)</span>. Normalizing, we get <span class="math notranslate nohighlight">\(v_1 = \frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ -1 \end{pmatrix}\)</span>.
For <span class="math notranslate nohighlight">\(\lambda_2 = 1\)</span>: <span class="math notranslate nohighlight">\(\begin{pmatrix} 1 &amp; -1 \\ -1 &amp; 1 \end{pmatrix}v_2 = 0\)</span>, which gives <span class="math notranslate nohighlight">\(v_2 = c\begin{pmatrix} 1 \\ 1 \end{pmatrix}\)</span>. Normalizing, we get <span class="math notranslate nohighlight">\(v_2 = \frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ 1 \end{pmatrix}\)</span>.
To verify the variational characterization for <span class="math notranslate nohighlight">\(\lambda_1\)</span>:
<span class="math notranslate nohighlight">\(R_A(v_1) = \frac{\langle v_1, Av_1 \rangle}{\langle v_1, v_1 \rangle} = \frac{1}{2}\begin{pmatrix} 1 &amp; 1 \end{pmatrix}\begin{pmatrix} 2 &amp; -1 \\ -1 &amp; 2 \end{pmatrix}\begin{pmatrix} 1 \\ 1 \end{pmatrix} = \frac{1}{2}(2 - 1 - 1 + 2) = 3 = \lambda_1\)</span>.
For any unit vector <span class="math notranslate nohighlight">\(u = \begin{pmatrix} \cos\theta \\ \sin\theta \end{pmatrix}\)</span>, we have:
<span class="math notranslate nohighlight">\(R_A(u) = \begin{pmatrix} \cos\theta &amp; \sin\theta \end{pmatrix}\begin{pmatrix} 2 &amp; -1 \\ -1 &amp; 2 \end{pmatrix}\begin{pmatrix} \cos\theta \\ \sin\theta \end{pmatrix} = 2\cos^2\theta + 2\sin^2\theta - 2\cos\theta\sin\theta = 2 - 2\cos\theta\sin\theta \leq 2 + 2|\cos\theta\sin\theta| \leq 3\)</span>,
with equality when <span class="math notranslate nohighlight">\(\theta = \frac{\pi}{4}\)</span>, which corresponds to <span class="math notranslate nohighlight">\(u = v_1\)</span>. Thus, <span class="math notranslate nohighlight">\(\lambda_1 = \max_{u \neq 0} R_A(u)\)</span>.</p>
<p><strong>E5.3.7</strong> First, we find the eigenvalues corresponding to the given eigenvectors: <span class="math notranslate nohighlight">\(Av_1 = \begin{pmatrix} 1 &amp; 2 &amp; 0 \\ 2 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 3 \end{pmatrix} \frac{1}{\sqrt{2}} \begin{pmatrix} 1 \\ 1 \\ 0 \end{pmatrix} = \frac{1}{\sqrt{2}} \begin{pmatrix} 3 \\ 3 \\ 0 \end{pmatrix} = 3v_1\)</span>, so <span class="math notranslate nohighlight">\(\lambda_1 = 3\)</span>. <span class="math notranslate nohighlight">\(Av_2 = \begin{pmatrix} 1 &amp; 2 &amp; 0 \\ 2 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 3 \end{pmatrix} \frac{1}{\sqrt{2}} \begin{pmatrix} -1 \\ 1 \\ 0 \end{pmatrix} = \frac{1}{\sqrt{2}} \begin{pmatrix} -1 \\ 1 \\ 0 \end{pmatrix} = v_2\)</span>, so <span class="math notranslate nohighlight">\(\lambda_2 = 1\)</span>. <span class="math notranslate nohighlight">\(Av_3 = \begin{pmatrix} 1 &amp; 2 &amp; 0 \\ 2 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 3 \end{pmatrix} \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 3 \end{pmatrix} = 3v_3\)</span>, so <span class="math notranslate nohighlight">\(\lambda_3 = 3\)</span>.</p>
<p>So the eigenvalues are <span class="math notranslate nohighlight">\(\lambda_1 = 3\)</span>, <span class="math notranslate nohighlight">\(\lambda_2 = 1\)</span>, and <span class="math notranslate nohighlight">\(\lambda_3 = 3\)</span>. Note that <span class="math notranslate nohighlight">\(\lambda_2\)</span> is the second smallest eigenvalue.</p>
<p>Now, let’s verify the variational characterization for <span class="math notranslate nohighlight">\(\lambda_2\)</span>. Any vector <span class="math notranslate nohighlight">\(u \in V_2\)</span> can be written as <span class="math notranslate nohighlight">\(u = c_1 v_1 + c_2 v_2\)</span> for some scalars <span class="math notranslate nohighlight">\(c_1\)</span> and <span class="math notranslate nohighlight">\(c_2\)</span>. Then:</p>
<p><span class="math notranslate nohighlight">\(\langle u, u \rangle = \langle c_1 v_1 + c_2 v_2, c_1 v_1 + c_2 v_2 \rangle = c_1^2 \langle v_1, v_1 \rangle + 2c_1c_2 \langle v_1, v_2 \rangle + c_2^2 \langle v_2, v_2 \rangle = c_1^2 + c_2^2\)</span>, since <span class="math notranslate nohighlight">\(v_1\)</span> and <span class="math notranslate nohighlight">\(v_2\)</span> are orthonormal.</p>
<p><span class="math notranslate nohighlight">\(\langle u, Au \rangle = \langle c_1 v_1 + c_2 v_2, A(c_1 v_1 + c_2 v_2) \rangle = \langle c_1 v_1 + c_2 v_2, 3c_1 v_1 + c_2 v_2 \rangle = 3c_1^2 + c_2^2\)</span>, since <span class="math notranslate nohighlight">\(Av_1 = 3v_1\)</span> and <span class="math notranslate nohighlight">\(Av_2 = v_2\)</span>.</p>
<p>Therefore, <span class="math notranslate nohighlight">\(R_A(u) = \frac{\langle u, Au \rangle}{\langle u, u \rangle} = \frac{3c_1^2 + c_2^2}{c_1^2 + c_2^2} \geq 1\)</span> for all <span class="math notranslate nohighlight">\(u \neq 0\)</span> in <span class="math notranslate nohighlight">\(V_2\)</span>, with equality when <span class="math notranslate nohighlight">\(c_1 = 0\)</span>. Thus: <span class="math notranslate nohighlight">\(\lambda_2 = \min_{0 \neq u \in V_2} R_A(u) = 1 = R_A(v_2)\)</span>.</p>
<p>So indeed, the second smallest eigenvalue <span class="math notranslate nohighlight">\(\lambda_2\)</span> satisfies the variational characterization <span class="math notranslate nohighlight">\(\lambda_2 = \min_{0 \neq u \in V_2} R_A(u)\)</span>.</p>
<p><strong>E5.4.1</strong> The degree matrix <span class="math notranslate nohighlight">\(D\)</span> is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
D = \begin{pmatrix}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 3 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 2 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 2
\end{pmatrix}.
\end{split}\]</div>
<p>The Laplacian matrix <span class="math notranslate nohighlight">\(L\)</span> is <span class="math notranslate nohighlight">\(L = D - A\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
L = \begin{pmatrix}
1 &amp; -1 &amp; 0 &amp; 0 \\
-1 &amp; 3 &amp; -1 &amp; -1 \\
0 &amp; -1 &amp; 2 &amp; -1 \\
0 &amp; -1 &amp; -1 &amp; 2
\end{pmatrix}.
\end{split}\]</div>
<p><strong>E5.4.3</strong></p>
<div class="math notranslate nohighlight">
\[\begin{split}
Ly_1 = \begin{pmatrix}
2 &amp; -1 &amp; 0 &amp; -1 &amp; 0\\
-1 &amp; 2 &amp; -1 &amp; 0 &amp; 0\\
0 &amp; -1 &amp; 3 &amp; -1 &amp; -1\\
-1 &amp; 0 &amp; -1 &amp; 2 &amp; 0\\
0 &amp; 0 &amp; -1 &amp; 0 &amp; 1
\end{pmatrix} \cdot \frac{1}{\sqrt{5}}\begin{pmatrix}
1\\
1\\
1\\
1\\
1
\end{pmatrix} = \frac{1}{\sqrt{5}}\begin{pmatrix}
0\\
0\\
0\\
0\\
0
\end{pmatrix} = 0 \cdot y_1.
\end{split}\]</div>
<p><strong>E5.4.5</strong> Let’s verify that <span class="math notranslate nohighlight">\(y_1\)</span> and <span class="math notranslate nohighlight">\(y_2\)</span> are eigenvectors of <span class="math notranslate nohighlight">\(L\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
Ly_1 = \begin{pmatrix}
1 &amp; -1 &amp; 0 &amp; 0\\
-1 &amp; 2 &amp; -1 &amp; 0\\
0 &amp; -1 &amp; 2 &amp; -1\\
0 &amp; 0 &amp; -1 &amp; 1
\end{pmatrix} \cdot \frac{1}{2}\begin{pmatrix}
1\\
1\\
1\\
1
\end{pmatrix} = \frac{1}{2}\begin{pmatrix}
0\\
0\\
0\\
0
\end{pmatrix} = 0 \cdot y_1,
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
Ly_2 = \begin{pmatrix}
1 &amp; -1 &amp; 0 &amp; 0\\
-1 &amp; 2 &amp; -1 &amp; 0\\
0 &amp; -1 &amp; 2 &amp; -1\\
0 &amp; 0 &amp; -1 &amp; 1
\end{pmatrix} \cdot \frac{1}{2}\begin{pmatrix}
1\\
\frac{1}{\sqrt{2}}\\
-\frac{1}{\sqrt{2}}\\
-1
\end{pmatrix} = (2 - \sqrt{2}) \cdot
\frac{1}{2}\begin{pmatrix}
1\\
\frac{1}{\sqrt{2}}\\
-\frac{1}{\sqrt{2}}\\
-1
\end{pmatrix} = (2 - \sqrt{2}) \cdot y_2.
\end{split}\]</div>
<p>So, <span class="math notranslate nohighlight">\(y_1\)</span> is an eigenvector with eigenvalue <span class="math notranslate nohighlight">\(\mu_1 = 0\)</span>, and <span class="math notranslate nohighlight">\(y_2\)</span> is an eigenvector with eigenvalue <span class="math notranslate nohighlight">\(\mu_2 = 2 - \sqrt{2}\)</span>.</p>
<p><strong>E5.4.7</strong> The maximum degree of <span class="math notranslate nohighlight">\(K_4\)</span> is <span class="math notranslate nohighlight">\(\bar{\delta} = 3\)</span>. Using the bounds <span class="math notranslate nohighlight">\(\bar{\delta} + 1 \leq \mu_n \leq 2\bar{\delta}\)</span>, we have:</p>
<div class="math notranslate nohighlight">
\[
4 = \bar{\delta} + 1 \leq \mu_4 \leq 2\bar{\delta} = 6.
\]</div>
<p><strong>E5.4.9</strong> The diagonal entry <span class="math notranslate nohighlight">\(L_{ii}\)</span> is the degree of vertex <span class="math notranslate nohighlight">\(i\)</span>, and the off-diagonal entry <span class="math notranslate nohighlight">\(L_{ij}\)</span> (for <span class="math notranslate nohighlight">\(i \neq j\)</span>) is <span class="math notranslate nohighlight">\(-1\)</span> if vertices <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> are adjacent, and 0 otherwise. Thus, the sum of the entries in row <span class="math notranslate nohighlight">\(i\)</span> is</p>
<div class="math notranslate nohighlight">
\[
\deg(i) - \sum_{j: \{i,j\} \in E} 1 = 0.
\]</div>
<p><strong>E5.4.11</strong> For any vector <span class="math notranslate nohighlight">\(x \in \mathbb{R}^n\)</span>, we have</p>
<div class="math notranslate nohighlight">
\[
x^T L_G x = \sum_{\{i,j\} \in E} (x_i - x_j)^2 \ge 0.
\]</div>
<p>Since this holds for all <span class="math notranslate nohighlight">\(x\)</span>, <span class="math notranslate nohighlight">\(L_G\)</span> is positive semidefinite.</p>
<p><strong>E5.4.13</strong> In a complete graph, each vertex has degree <span class="math notranslate nohighlight">\(n-1\)</span>. Thus, the Laplacian matrix is <span class="math notranslate nohighlight">\(L_G = nI - J\)</span>, where <span class="math notranslate nohighlight">\(I\)</span> is the identity matrix and <span class="math notranslate nohighlight">\(J\)</span> is the all-ones matrix. The eigenvalues of <span class="math notranslate nohighlight">\(J\)</span> are <span class="math notranslate nohighlight">\(n\)</span> (with multiplicity 1) and, because <span class="math notranslate nohighlight">\(J\)</span> has rank one, 0 (with multiplicity <span class="math notranslate nohighlight">\(n-1\)</span>). Therefore, the eigenvalues of <span class="math notranslate nohighlight">\(L_G\)</span> are 0 (with multiplicity 1) and <span class="math notranslate nohighlight">\(n\)</span> (with multiplicity <span class="math notranslate nohighlight">\(n-1\)</span>).</p>
<p><strong>E5.5.1</strong> <span class="math notranslate nohighlight">\(|E(S, S^c)| = 2\)</span> (the edges between <span class="math notranslate nohighlight">\(S\)</span> and <span class="math notranslate nohighlight">\(S^c\)</span> are <span class="math notranslate nohighlight">\(\{1, 2\}\)</span> and <span class="math notranslate nohighlight">\(\{2, 3\}\)</span>), and <span class="math notranslate nohighlight">\(\min\{|S|, |S^c|\} = 1\)</span>. Therefore, <span class="math notranslate nohighlight">\(\phi(S) = \frac{|E(S, S^c)|}{\min\{|S|, |S^c|\}} = 2\)</span>.</p>
<p><strong>E5.5.3</strong> In a connected graph with <span class="math notranslate nohighlight">\(n\)</span> vertices, the numerator of the cut ratio is at least 1, and the denominator is at most <span class="math notranslate nohighlight">\(n/2\)</span>, which is achieved by cutting the graph into two equal parts. Therefore, the smallest possible value of the isoperimetric number is <span class="math notranslate nohighlight">\(\frac{1}{n/2} = \frac{2}{n}\)</span>. For <span class="math notranslate nohighlight">\(n = 6\)</span>, this is <span class="math notranslate nohighlight">\(\frac{1}{3}\)</span>.</p>
<p><strong>E5.5.5</strong> The Cheeger Inequality also states that <span class="math notranslate nohighlight">\(\frac{\phi_G^2}{2\bar{\delta}} \leq \mu_2\)</span>. Therefore, <span class="math notranslate nohighlight">\(\phi_G \leq \sqrt{2\bar{\delta}\mu_2} = \sqrt{2 \cdot 4 \cdot 0.5} = 2\)</span>.</p>
<p><strong>E5.5.7</strong> Let <span class="math notranslate nohighlight">\(\mathbf{v}_1 = (1, 1, 1, 1)/2\)</span>, <span class="math notranslate nohighlight">\(\mathbf{v}_2 = (-1, -1, 1, 1)/2\)</span>, <span class="math notranslate nohighlight">\(\mathbf{v}_3 = (1, -1, -1, 1)/2\)</span>, and <span class="math notranslate nohighlight">\(\mathbf{v}_4 = (1, -1, 1, -1)/2\)</span>. These vectors form an orthonormal list. We can verify that these are eigenvectors of <span class="math notranslate nohighlight">\(L\)</span> and find their corresponding eigenvalues:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
L\mathbf{v}_1 = \begin{pmatrix}
2 &amp; -1 &amp; 0 &amp; -1 \\
-1 &amp; 2 &amp; -1 &amp; 0 \\
0 &amp; -1 &amp; 2 &amp; -1 \\
-1 &amp; 0 &amp; -1 &amp; 2
\end{pmatrix} \frac{1}{2}\begin{pmatrix}
1 \\ 1 \\ 1 \\ 1
\end{pmatrix} = \begin{pmatrix}
0 \\ 0 \\ 0 \\ 0
\end{pmatrix} = 0 \cdot \mathbf{v}_1,
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
L\mathbf{v}_2 = \begin{pmatrix}
2 &amp; -1 &amp; 0 &amp; -1 \\
-1 &amp; 2 &amp; -1 &amp; 0 \\
0 &amp; -1 &amp; 2 &amp; -1 \\
-1 &amp; 0 &amp; -1 &amp; 2
\end{pmatrix} \frac{1}{2}\begin{pmatrix}
-1 \\ -1 \\ 1 \\ 1
\end{pmatrix} = \frac{1}{2}\begin{pmatrix}
-2 \\ -2 \\ 2 \\ 2
\end{pmatrix} = 2 \cdot \mathbf{v}_2,
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
L\mathbf{v}_3 = \begin{pmatrix}
2 &amp; -1 &amp; 0 &amp; -1 \\
-1 &amp; 2 &amp; -1 &amp; 0 \\
0 &amp; -1 &amp; 2 &amp; -1 \\
-1 &amp; 0 &amp; -1 &amp; 2
\end{pmatrix} \frac{1}{2}\begin{pmatrix}
1 \\ -1 \\ -1 \\ 1
\end{pmatrix} = \frac{1}{2}\begin{pmatrix}
2 \\ -2 \\ -2 \\ 2
\end{pmatrix} = 2 \cdot \mathbf{v}_3,
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
L\mathbf{v}_4 = \begin{pmatrix}
2 &amp; -1 &amp; 0 &amp; -1 \\
-1 &amp; 2 &amp; -1 &amp; 0 \\
0 &amp; -1 &amp; 2 &amp; -1 \\
-1 &amp; 0 &amp; -1 &amp; 2
\end{pmatrix} \frac{1}{2}\begin{pmatrix}
1 \\ -1 \\ 1 \\ -1
\end{pmatrix} = \frac{1}{2}\begin{pmatrix}
4 \\ -4 \\ 4 \\ -4
\end{pmatrix} = 4 \cdot \mathbf{v}_4.
\end{split}\]</div>
<p>Therefore, the corresponding eigenvalues are <span class="math notranslate nohighlight">\(\mu_1 = 0\)</span>, <span class="math notranslate nohighlight">\(\mu_2 = 2\)</span>, <span class="math notranslate nohighlight">\(\mu_3 = 2\)</span>, and <span class="math notranslate nohighlight">\(\mu_4 = 4\)</span>.</p>
<p><strong>E5.5.9</strong> Using the Fiedler vector <span class="math notranslate nohighlight">\(\mathbf{v}_2 = (-1, -1, 1, 1)/2\)</span>, an order is <span class="math notranslate nohighlight">\(\pi(1) = 1\)</span>, <span class="math notranslate nohighlight">\(\pi(2) = 2\)</span>, <span class="math notranslate nohighlight">\(\pi(3) = 3\)</span>, <span class="math notranslate nohighlight">\(\pi(4) = 4\)</span>.</p>
<p><strong>E5.5.11</strong> To find the isoperimetric number, we need to consider all possible cuts and find the minimum cut ratio.</p>
<p>Let’s consider all possible cuts:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(S = \{1\}\)</span>, <span class="math notranslate nohighlight">\(|E(S, S^c)| = 2\)</span>, <span class="math notranslate nohighlight">\(\min\{|S|, |S^c|\} = 1\)</span>, so <span class="math notranslate nohighlight">\(\phi(S) = 2\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(S = \{1, 2\}\)</span>, <span class="math notranslate nohighlight">\(|E(S, S^c)| = 2\)</span>, <span class="math notranslate nohighlight">\(\min\{|S|, |S^c|\} = 2\)</span>, so <span class="math notranslate nohighlight">\(\phi(S) = 1\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(S = \{1, 2, 3\}\)</span>, <span class="math notranslate nohighlight">\(|E(S, S^c)| = 2\)</span>, <span class="math notranslate nohighlight">\(\min\{|S|, |S^c|\} = 1\)</span>, so <span class="math notranslate nohighlight">\(\phi(S) = 2\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(S = \{1, 2, 3, 4\}\)</span>, <span class="math notranslate nohighlight">\(|E(S, S^c)| = 2\)</span>, <span class="math notranslate nohighlight">\(\min\{|S|, |S^c|\} = 0\)</span>, so <span class="math notranslate nohighlight">\(\phi(S)\)</span> is undefined.</p></li>
<li><p>etc.</p></li>
</ul>
<p>The minimum cut ratio is <span class="math notranslate nohighlight">\(1\)</span>, achieved by the cut <span class="math notranslate nohighlight">\(S = \{1, 2\}\)</span>. Therefore, the isoperimetric number of the graph is <span class="math notranslate nohighlight">\(\phi_G = 1\)</span>.</p>
<p>Comparing this to the results from E5.5.8 and E5.5.10:</p>
<ul class="simple">
<li><p>In E5.5.8, we found that the Fiedler vector is either <span class="math notranslate nohighlight">\((-1, -1, 1, 1)/2\)</span>, which suggests a cut separating vertices <span class="math notranslate nohighlight">\(\{1, 2\}\)</span> from <span class="math notranslate nohighlight">\(\{3, 4\}\)</span>.</p></li>
<li><p>In E5.5.10, using the ordering based on the Fiedler vector, we found that the cut with the smallest ratio is <span class="math notranslate nohighlight">\(S_2 = \{1, 2\}\)</span>, with a cut ratio of <span class="math notranslate nohighlight">\(1\)</span>.</p></li>
</ul>
<p>Both the Fiedler vector and the spectral clustering algorithm based on it correctly identify the cut that achieves the isoperimetric number (Cheeger constant) of the graph.</p>
<p>Now, let’s compare the isoperimetric number to the bounds given by Cheeger’s inequality. From E5.5.7, we know that the second smallest eigenvalue of the Laplacian matrix is <span class="math notranslate nohighlight">\(\mu_2 = 2\)</span>. The maximum degree of the graph is <span class="math notranslate nohighlight">\(\bar{\delta} = 2\)</span>. Cheeger’s inequality states that:</p>
<div class="math notranslate nohighlight">
\[\frac{\phi_G^2}{2\bar{\delta}} \leq \mu_2 \leq 2\phi_G\]</div>
<p>Plugging in the values, we get:</p>
<div class="math notranslate nohighlight">
\[\frac{(\frac{1}{2})^2}{2 \cdot 2} \leq 2 \leq 2 \cdot 1\]</div>
<p>which simplifies to:</p>
<div class="math notranslate nohighlight">
\[\frac{1}{16} \leq 2 \leq 2\]</div>
<p>We can see that the isoperimetric number <span class="math notranslate nohighlight">\(\phi_G = 1\)</span> satisfies the bounds given by Cheeger’s inequality.</p>
<p><strong>E5.5.13</strong></p>
<div class="math notranslate nohighlight">
\[\begin{split}
D = \begin{pmatrix}
2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 3 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 3 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
\end{pmatrix}
\end{split}\]</div>
<p>The degree matrix <span class="math notranslate nohighlight">\(D\)</span> is a diagonal matrix where each entry <span class="math notranslate nohighlight">\(D_{ii}\)</span> is the degree of vertex <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p><strong>E5.5.15</strong></p>
<div class="math notranslate nohighlight">
\[
\text{Cutset} = \{\{1, 3\}, \{2, 3\}, \{2, 4\}\}, \quad |E(S, S^c)| = 3
\]</div>
<div class="math notranslate nohighlight">
\[
\phi(S) = \frac{|E(S, S^c)|}{\min(|S|, |S^c|)} = \frac{3}{2} = 1.5
\]</div>
<p>The cutset consists of edges between <span class="math notranslate nohighlight">\(S\)</span> and <span class="math notranslate nohighlight">\(S^c\)</span>. The cut ratio <span class="math notranslate nohighlight">\(\phi(S)\)</span> is the</p>
<p>size of the cutset divided by the size of the smaller subset.</p>
<p><strong>E5.5.17</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="n">edges</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)]</span>
<span class="n">G</span><span class="o">.</span><span class="n">add_edges_from</span><span class="p">(</span><span class="n">edges</span><span class="p">)</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">spring_layout</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>

<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">with_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="s1">&#39;lightblue&#39;</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">font_size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_edges</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">edgelist</span><span class="o">=</span><span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)],</span> <span class="n">edge_color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>This code creates and displays the graph with the cut edges highlighted in red.</p>
<p><strong>E5.6.1</strong> The expected number of edges is <span class="math notranslate nohighlight">\(\mathbb{E}[|E|] = \binom{n}{2}p = \binom{6}{2} \cdot 0.4 = 15 \cdot 0.4 = 6\)</span>.</p>
<p><strong>E5.6.3</strong> The expected number of triangles is <span class="math notranslate nohighlight">\(\mathbb{E}[|T_3|] = \binom{n}{3}p^3 = \binom{10}{3} \cdot 0.3^3 = 120 \cdot 0.027 = 3.24\)</span>. The expected triangle density is <span class="math notranslate nohighlight">\(\mathbb{E}[|T_3|/\binom{n}{3}] = p^3 = 0.3^3 = 0.027\)</span>.</p>
<p><strong>E5.6.5</strong> The block assignment matrix <span class="math notranslate nohighlight">\(Z\)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
Z = \begin{pmatrix}
1 &amp; 0 \\
1 &amp; 0 \\
1 &amp; 0 \\
1 &amp; 0 \\
0 &amp; 1 \\
0 &amp; 1 \\
0 &amp; 1 \\
0 &amp; 1
\end{pmatrix}.
\end{split}\]</div>
<p><strong>E5.6.7</strong> The degree of a vertex in <span class="math notranslate nohighlight">\(G(4, 0.5)\)</span> follows a binomial distribution <span class="math notranslate nohighlight">\(\mathrm{Bin}(3, 0.5)\)</span>. The probabilities are:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbb{P}(d = 0) = (0.5)^3 = 0.125\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbb{P}(d = 1) = 3 \cdot (0.5)^3 = 0.375\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbb{P}(d = 2) = 3 \cdot (0.5)^3 = 0.375\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbb{P}(d = 3) = (0.5)^3 = 0.125\)</span></p></li>
</ul>
<p><strong>E5.6.9</strong> The variance is <span class="math notranslate nohighlight">\(\mathrm{Var}[|E|] = \binom{3}{2} \cdot p \cdot (1 - p) = 3 \cdot 0.5 \cdot 0.5 = 0.75\)</span>.</p>
<p><strong>E5.6.11</strong> Since vertex 2 is in block <span class="math notranslate nohighlight">\(C_1\)</span> and vertex 4 is in block <span class="math notranslate nohighlight">\(C_2\)</span>, the probability of an edge between them is <span class="math notranslate nohighlight">\(b_{1,2} = 1/4\)</span>.</p>
<p><strong>E5.6.13</strong> The expected degree of each vertex is <span class="math notranslate nohighlight">\((p+q)n/2 = (1)(8)/2 = 4\)</span>.</p>
<p><strong>E5.6.15</strong> Let <span class="math notranslate nohighlight">\(A_{i,j}\)</span> be the indicator random variable for the presence of edge <span class="math notranslate nohighlight">\(\{i,j\}\)</span>. Then the number of edges is <span class="math notranslate nohighlight">\(X = \sum_{i&lt;j} A_{i,j}\)</span>. Since the edges are independent,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\mathrm{Var}[X] &amp;= \mathrm{Var}\left[\sum_{i&lt;j} A_{i,j}\right] \\
&amp;= \sum_{i&lt;j} \mathrm{Var}[A_{i,j}] \\
&amp;= \sum_{i&lt;j} m_{i,j}(1-m_{i,j}) \\
&amp;= \frac{1}{2}\left(1-\frac{1}{2}\right) + \frac{1}{4}\left(1-\frac{1}{4}\right) + \frac{1}{2}\left(1-\frac{1}{2}\right) \\
&amp;= \frac{11}{16}.
\end{align*}\]</div>
</section>
<section id="learning-outcomes">
<h3><span class="section-number">5.8.1.5. </span>Learning outcomes<a class="headerlink" href="#learning-outcomes" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Define undirected and directed graphs, and identify their key components such as vertices, edges, paths, and cycles.</p></li>
<li><p>Recognize special types of graphs, including cliques, trees, forests, and directed acyclic graphs (DAGs).</p></li>
<li><p>Determine the connectivity of a graph and identify its connected components.</p></li>
<li><p>Construct the adjacency matrix, incidence matrix, and Laplacian matrix representations of a graph.</p></li>
<li><p>Prove key properties of the Laplacian matrix, such as symmetry and positive semidefiniteness.</p></li>
<li><p>Extend the concepts of graphs and their matrix representations to weighted graphs.</p></li>
<li><p>Implement graph representations and algorithms using the NetworkX package in Python.</p></li>
<li><p>Apply graph theory concepts to model and analyze real-world networks and relationships.</p></li>
<li><p>Outline the proof of the Spectral Theorem using a sequence of orthogonal transformations to diagonalize a matrix.</p></li>
<li><p>Define the Rayleigh quotient and explain its relationship to eigenvectors and eigenvalues.</p></li>
<li><p>Prove the variational characterizations of the largest, smallest, and second smallest eigenvalues of a symmetric matrix using the Rayleigh quotient.</p></li>
<li><p>State the Courant-Fischer Theorem and interpret its local and global formulas for the eigenvalues of a symmetric matrix.</p></li>
<li><p>Apply the Courant-Fischer Theorem to characterize the third smallest eigenvalue of a symmetric matrix.</p></li>
<li><p>State the key properties of the Laplacian matrix, including symmetry, positive semidefiniteness, and the constant eigenvector associated with the zero eigenvalue.</p></li>
<li><p>Prove the relationship between graph connectivity and the second smallest eigenvalue (algebraic connectivity) of the Laplacian matrix.</p></li>
<li><p>Derive bounds on the largest eigenvalue of the Laplacian matrix using the maximum degree of the graph.</p></li>
<li><p>Formulate the variational characterization of the second smallest eigenvalue of the Laplacian matrix as a constrained optimization problem.</p></li>
<li><p>Explain how the eigenvectors of the Laplacian matrix can be used for graph drawing and revealing the underlying geometry of the graph, using the variational characterization.</p></li>
<li><p>Compute the Laplacian matrix and its eigenvalues and eigenvectors for simple graphs, and interpret the results in terms of graph connectivity and geometry.</p></li>
<li><p>Compute the cut ratio and the isoperimetric number (Cheeger constant) for a given graph cut.</p></li>
<li><p>State the Cheeger Inequality and explain its significance in relating the isoperimetric number to the second smallest Laplacian eigenvalue.</p></li>
<li><p>Describe the main steps of the graph-cutting algorithm based on the Fiedler vector.</p></li>
<li><p>Analyze the performance guarantees of the Fiedler vector-based graph-cutting algorithm and compare them to the optimal cut.</p></li>
<li><p>Apply spectral clustering techniques to identify communities within a graph, and evaluate the quality of the resulting partitions.</p></li>
<li><p>Formulate the minimum bisection problem as a discrete optimization problem and relax it into a continuous optimization problem related to the Laplacian matrix.</p></li>
<li><p>Define the inhomogeneous Erdős-Rényi (ER) random graph model and explain how it generalizes the standard ER model.</p></li>
<li><p>Generate inhomogeneous ER graphs and analyze their properties, such as edge density and the probability of connectivity, using Python and NetworkX.</p></li>
<li><p>Calculate the expected number of edges and triangles in an ER random graph.</p></li>
<li><p>Describe the stochastic blockmodel (SBM) and its role in creating random graphs with planted partitions, and explain how it relates to the concept of homophily.</p></li>
<li><p>Construct SBMs with specified block assignments and edge probabilities, and visualize the resulting graphs using Python and NetworkX.</p></li>
<li><p>Compute the expected adjacency matrix of an SBM given the block assignment matrix and connection probabilities.</p></li>
<li><p>Apply spectral clustering algorithms to SBMs and evaluate their performance in recovering the ground truth community structure.</p></li>
<li><p>Analyze the simplified symmetric stochastic blockmodel (SSBM) and derive the spectral decomposition of its expected adjacency matrix.</p></li>
<li><p>Explain the relationship between the eigenvectors of the expected Laplacian matrix and the community structure in the SSBM.</p></li>
<li><p>Investigate the behavior of the eigenvalues of the Laplacian matrix for large random graphs and discuss the connection to random matrix theory.</p></li>
</ul>
<p><span class="math notranslate nohighlight">\(\aleph\)</span></p>
</section>
</section>
<section id="additional-sections">
<h2><span class="section-number">5.8.2. </span>Additional sections<a class="headerlink" href="#additional-sections" title="Link to this heading">#</a></h2>
<section id="spectral-properties-of-sbm">
<h3><span class="section-number">5.8.2.1. </span>Spectral properties of SBM<a class="headerlink" href="#spectral-properties-of-sbm" title="Link to this heading">#</a></h3>
<p>The SBM provides an alternative explanation for the efficacy of spectral clustering.</p>
<p>We use a toy version of the model. Specifically, we assume that:</p>
<ul class="simple">
<li><p>The number of vertices <span class="math notranslate nohighlight">\(n\)</span> is even.</p></li>
<li><p>Vertices <span class="math notranslate nohighlight">\(1,\ldots,n/2\)</span> are in block <span class="math notranslate nohighlight">\(C_1\)</span> while vertices <span class="math notranslate nohighlight">\(n/2+1,\ldots,n\)</span> are in block <span class="math notranslate nohighlight">\(C_2\)</span>.</p></li>
<li><p>The intra-block connection probability is <span class="math notranslate nohighlight">\(b_{1,1} = b_{2,2} = p\)</span> and the inter-block connection probability is <span class="math notranslate nohighlight">\(b_{1,2} = b_{2,1} = q &lt; p\)</span>, with <span class="math notranslate nohighlight">\(p, q \in (0,1)\)</span>.</p></li>
<li><p>We allow self-loops, whose probability are the intra-block connection probability.</p></li>
</ul>
<p>In that case, the matrix <span class="math notranslate nohighlight">\(M\)</span> is the block matrix</p>
<div class="math notranslate nohighlight">
\[\begin{split}
M = \begin{pmatrix}
p J &amp; q J\\
qJ &amp; pJ
\end{pmatrix},
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(J \in \mathbb{R}^{n/2 \times n/2}\)</span> is the all-one matrix. We refer to this model as the symmetric stochastic blockmodel (SSBM).</p>
<p>The matrix <span class="math notranslate nohighlight">\(M\)</span> is symmetric. Hence it has a spectral decomposition. It is straightforward to compute. Let <span class="math notranslate nohighlight">\(\mathbf{1}_m\)</span> be the all-one vector of size <span class="math notranslate nohighlight">\(m\)</span>.</p>
<p><strong>LEMMA</strong> <strong>(Spectral Decomposition of SSBM)</strong> Consider the matrix <span class="math notranslate nohighlight">\(M\)</span> above. Let</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{q}_1 
= \frac{1}{\sqrt{n}} \mathbf{1}_n
\quad
\text{and}
\quad
\mathbf{q}_2
= \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{n/2} \\ - \mathbf{1}_{n/2} \end{pmatrix}. 
\end{split}\]</div>
<p>Let <span class="math notranslate nohighlight">\(\mathbf{q}_3,\ldots,\mathbf{q}_n\)</span> be an orthonormal basis of <span class="math notranslate nohighlight">\((\mathrm{span}\{\mathbf{q}_1, \mathbf{q}_2\})^\perp\)</span>. Denote by <span class="math notranslate nohighlight">\(Q\)</span> the matrix whose columns are <span class="math notranslate nohighlight">\(\mathbf{q}_1,\ldots,\mathbf{q}_n\)</span>. Let</p>
<div class="math notranslate nohighlight">
\[
\lambda_1 
= \frac{p + q}{2} n 
\quad
\text{and}
\quad
\lambda_2
= \frac{p - q}{2} n. 
\]</div>
<p>Let <span class="math notranslate nohighlight">\(\lambda_3,\ldots,\lambda_n = 0\)</span>. Denote by <span class="math notranslate nohighlight">\(\Lambda\)</span> the diagonal matrix with diagonal entries <span class="math notranslate nohighlight">\(\lambda_1,\ldots,\lambda_n\)</span>.</p>
<p>Then a spectral decomposition of <span class="math notranslate nohighlight">\(M\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
M = Q \Lambda Q^T.
\]</div>
<p>In particular, <span class="math notranslate nohighlight">\(\mathbf{q}_i\)</span> is an eigenvector of <span class="math notranslate nohighlight">\(M\)</span> with eigenvalue <span class="math notranslate nohighlight">\(\lambda_i\)</span>. <span class="math notranslate nohighlight">\(\flat\)</span></p>
<p><em>Proof:</em> We start with <span class="math notranslate nohighlight">\(\mathbf{q}_1\)</span> and note that by the formula for the multiplication of block matrices and the definition of <span class="math notranslate nohighlight">\(J\)</span></p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
     M \mathbf{q}_1 &amp;= \begin{pmatrix}
     p J &amp; q J\\
     q J &amp; p J
     \end{pmatrix} \frac{1}{\sqrt{n}} \mathbf{1}_n \\
     &amp;= \begin{pmatrix}
     p J &amp; q J\\
     q J &amp; p J
     \end{pmatrix} \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}} \\ \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\
     &amp;= \frac{1}{\sqrt{n}} \begin{pmatrix}
     p J \mathbf{1}_{\frac{n}{2}} + q J \mathbf{1}_{\frac{n}{2}}\\
     q J \mathbf{1}_{\frac{n}{2}} + p J \mathbf{1}_{\frac{n}{2}}
     \end{pmatrix} \\
     &amp;= \frac{1}{\sqrt{n}} \begin{pmatrix}
     (p + q) J \mathbf{1}_{\frac{n}{2}}\\
     (p + q) J \mathbf{1}_{\frac{n}{2}}
     \end{pmatrix} \\
     &amp;= \frac{1}{\sqrt{n}} \begin{pmatrix}
     (p + q) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}\\
     (p + q) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}
     \end{pmatrix} \\
     &amp;= \frac{p + q}{2} \sqrt{n} \begin{pmatrix}
     \mathbf{1}_{\frac{n}{2}}\\
     \mathbf{1}_{\frac{n}{2}}
     \end{pmatrix} \\
     &amp;= \lambda_1 \mathbf{q}_1.
\end{align*}\]</div>
<p>Similarly</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
     M \mathbf{q}_2 &amp;= \begin{pmatrix}
     p J &amp; q J\\
     q J &amp; p J
     \end{pmatrix} \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{\frac{n}{2}} \\ - \mathbf{1}_{\frac{n}{2}} \end{pmatrix} \\
     &amp;= \frac{1}{\sqrt{n}} \begin{pmatrix}
     p J \mathbf{1}_{\frac{n}{2}} - q J \mathbf{1}_{\frac{n}{2}}\\
     q J \mathbf{1}_{\frac{n}{2}} - p J \mathbf{1}_{\frac{n}{2}}
     \end{pmatrix} \\
     &amp;= \frac{1}{\sqrt{n}} \begin{pmatrix}
     (p - q) J \mathbf{1}_{\frac{n}{2}}\\
     (q - p) J \mathbf{1}_{\frac{n}{2}}
     \end{pmatrix} \\
     &amp;= \frac{1}{\sqrt{n}} \begin{pmatrix}
     (p - q) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}\\
     (q - p) \frac{n}{2} \mathbf{1}_{\frac{n}{2}}
     \end{pmatrix} \\
     &amp;= \frac{p - q}{2} \sqrt{n} \begin{pmatrix}
     \mathbf{1}_{\frac{n}{2}}\\
     - \mathbf{1}_{\frac{n}{2}}
     \end{pmatrix} \\
     &amp;= \lambda_2 \mathbf{q}_2.
\end{align*}\]</div>
<p>Matrix <span class="math notranslate nohighlight">\(M\)</span> has rank 2 since it only has two distinct columns (assuming <span class="math notranslate nohighlight">\(p \neq q\)</span>). By the <em>Spectral Theorem</em>, there is an orthonormal basis of eigenvectors. We have shown that <span class="math notranslate nohighlight">\(\mathbf{q}_1\)</span> and <span class="math notranslate nohighlight">\(\mathbf{q}_2\)</span> are eigenvectors with nonzero eigenvalues (again using that <span class="math notranslate nohighlight">\(p \neq q\)</span>). So the remaining eigenvectors must form a basis of the orthogonal complement of <span class="math notranslate nohighlight">\(\mathrm{span}\{\mathbf{q}_1, \mathbf{q}_2\}\)</span> and they must have eigenvalue <span class="math notranslate nohighlight">\(0\)</span> since they lie in the null space. In particular,</p>
<div class="math notranslate nohighlight">
\[
\lambda_3 = \lambda_4 = \ldots = \lambda_n = 0.
\]</div>
<p>That proves the claim. <span class="math notranslate nohighlight">\(\square\)</span></p>
<p>Why is this relevant to graph cutting? We first compute the expected Laplacian matrix. For this we need to expected degree of each vertex. This is obtained as follows</p>
<div class="math notranslate nohighlight">
\[
\E[\delta(1)]
= \E\left[\sum_{j=1}^n \mathbf{1}_{\{i,j\} \in E}\right]
= \sum_{j=1}^n \E[\mathbf{1}_{\{i,j\} \in E}]
= \sum_{j=1}^{n/2} p + \sum_{j=n/2}^n q
= (p + q) \frac{n}{2},
\]</div>
<p>where we counted the self-loop (if present) once. The same holds for the other vertices. So</p>
<div class="math notranslate nohighlight">
\[
\overline{L} := \E[L]
= \E[D] - \E[A]
= (p + q) \frac{n}{2} I_{n \times n} - M.
\]</div>
<p>For any eigenvector <span class="math notranslate nohighlight">\(\mathbf{q}_i\)</span> of <span class="math notranslate nohighlight">\(M\)</span>, we note that</p>
<div class="math notranslate nohighlight">
\[
\overline{L} \,\mathbf{q}_i
= (p + q) \frac{n}{2} I_{n \times n} \mathbf{q}_i - M \mathbf{q}_i
= \left\{(p + q) \frac{n}{2} - \lambda_i \right\}\mathbf{q}_i,
\]</div>
<p>that is, <span class="math notranslate nohighlight">\(\mathbf{q}_i\)</span> is also an eigenvector of <span class="math notranslate nohighlight">\(\overline{L}\)</span>. Its eigenvalues are therefore</p>
<div class="math notranslate nohighlight">
\[
(p + q) \frac{n}{2} - \frac{p + q}{2} n = 0,
\quad
(p + q) \frac{n}{2} - \frac{p - q}{2} n = q n,
\quad
(p + q) \frac{n}{2}.
\]</div>
<p>When <span class="math notranslate nohighlight">\(p &gt; q\)</span>, <span class="math notranslate nohighlight">\(q n\)</span> is the second smallest eigenvalue of <span class="math notranslate nohighlight">\(\overline{L}\)</span> with corresponding eigenvector</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{q}_2
= \frac{1}{\sqrt{n}} \begin{pmatrix} \mathbf{1}_{n/2} \\ - \mathbf{1}_{n/2} \end{pmatrix}. 
\end{split}\]</div>
<p>The key observation:</p>
<blockquote>
<div><p>The eigenvector corresponding to the second smallest eigenvalue of <span class="math notranslate nohighlight">\(\overline{L}\)</span> perfectly encodes the community structure by assigning <span class="math notranslate nohighlight">\(1/\sqrt{n}\)</span> to the vertices in block <span class="math notranslate nohighlight">\(C_1\)</span> and <span class="math notranslate nohighlight">\(-1/\sqrt{n}\)</span> to the vertices in block <span class="math notranslate nohighlight">\(C_2\)</span>!</p>
</div></blockquote>
<p>Now, in reality, we do not get to observe <span class="math notranslate nohighlight">\(\overline{L}\)</span>. Instead we compute the actual Laplacian <span class="math notranslate nohighlight">\(L\)</span>, a random matrix whose expectation if <span class="math notranslate nohighlight">\(\overline{L}\)</span>. But it turns out that, for large <span class="math notranslate nohighlight">\(n\)</span>, the eigenvectors of <span class="math notranslate nohighlight">\(L\)</span> corresponding to its two smallest eigenvalues are close to <span class="math notranslate nohighlight">\(\mathbf{q}_1\)</span> and <span class="math notranslate nohighlight">\(\mathbf{q}_2\)</span>. Hence we can recover the community structure approximately from <span class="math notranslate nohighlight">\(L\)</span>. This is far from obvious since <span class="math notranslate nohighlight">\(L\)</span> and <span class="math notranslate nohighlight">\(\overline{L}\)</span> are very different matrices.</p>
<p>A formal proof of this claim is beyond this course. But we illustrate it numerically next.</p>
<p><strong>NUMERICAL CORNER:</strong> We first construct the block assignment and matrix <span class="math notranslate nohighlight">\(M\)</span> in the case of SSBM.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">build_ssbm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">):</span>

    <span class="n">block_assignments</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">block_assignments</span><span class="p">[</span><span class="n">n</span><span class="o">//</span><span class="mi">2</span><span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span>
    
    <span class="n">J</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="o">//</span><span class="mi">2</span><span class="p">))</span>
    
    <span class="n">M_top</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">p</span> <span class="o">*</span> <span class="n">J</span><span class="p">,</span> <span class="n">q</span> <span class="o">*</span> <span class="n">J</span><span class="p">))</span>
    <span class="n">M_bottom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">q</span> <span class="o">*</span> <span class="n">J</span><span class="p">,</span> <span class="n">p</span> <span class="o">*</span> <span class="n">J</span><span class="p">))</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">M_top</span><span class="p">,</span> <span class="n">M_bottom</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">block_assignments</span><span class="p">,</span> <span class="n">M</span>
</pre></div>
</div>
</div>
</div>
<p>Here is an example.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">q</span> <span class="o">=</span> <span class="mf">0.2</span>

<span class="n">block_assignments</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">build_ssbm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Block Assignments:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">block_assignments</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Matrix M:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Block Assignments:
 [0 0 0 0 0 1 1 1 1 1]
Matrix M:
 [[0.8 0.8 0.8 0.8 0.8 0.2 0.2 0.2 0.2 0.2]
 [0.8 0.8 0.8 0.8 0.8 0.2 0.2 0.2 0.2 0.2]
 [0.8 0.8 0.8 0.8 0.8 0.2 0.2 0.2 0.2 0.2]
 [0.8 0.8 0.8 0.8 0.8 0.2 0.2 0.2 0.2 0.2]
 [0.8 0.8 0.8 0.8 0.8 0.2 0.2 0.2 0.2 0.2]
 [0.2 0.2 0.2 0.2 0.2 0.8 0.8 0.8 0.8 0.8]
 [0.2 0.2 0.2 0.2 0.2 0.8 0.8 0.8 0.8 0.8]
 [0.2 0.2 0.2 0.2 0.2 0.8 0.8 0.8 0.8 0.8]
 [0.2 0.2 0.2 0.2 0.2 0.8 0.8 0.8 0.8 0.8]
 [0.2 0.2 0.2 0.2 0.2 0.8 0.8 0.8 0.8 0.8]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">seed</span> <span class="o">=</span> <span class="mi">535</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">mmids</span><span class="o">.</span><span class="n">inhomogeneous_er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The eigenvectors and eigenvalues of the Laplacian in this case are:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">L</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">laplacian_matrix</span><span class="p">(</span><span class="n">G</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">eigenvalues</span><span class="p">,</span> <span class="n">eigenvectors</span> <span class="o">=</span> <span class="n">LA</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Laplacian Matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">L</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Laplacian Matrix:
 [[ 5  0 -1 -1 -1  0  0 -1 -1  0]
 [ 0  4  0 -1 -1  0  0  0 -1 -1]
 [-1  0  5 -1  0 -1 -1  0 -1  0]
 [-1 -1 -1  5 -1  0  0  0  0 -1]
 [-1 -1  0 -1  3  0  0  0  0  0]
 [ 0  0 -1  0  0  4 -1 -1 -1  0]
 [ 0  0 -1  0  0 -1  5 -1 -1 -1]
 [-1  0  0  0  0 -1 -1  5 -1 -1]
 [-1 -1 -1  0  0 -1 -1 -1  6  0]
 [ 0 -1  0 -1  0  0 -1 -1  0  4]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Eigenvalues:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">eigenvalues</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Eigenvalues:
 [-1.03227341e-15  1.83189278e+00  3.17040405e+00  4.36335953e+00
  4.47745803e+00  5.00000000e+00  5.62350706e+00  6.78008860e+00
  7.17298485e+00  7.58030511e+00]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The first two eigenvectors:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">eigenvectors</span><span class="p">[:,:</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The first two eigenvectors:
 [[ 0.31622777  0.09163939]
 [ 0.31622777  0.3432291 ]
 [ 0.31622777 -0.17409747]
 [ 0.31622777  0.28393334]
 [ 0.31622777  0.61535604]
 [ 0.31622777 -0.42850888]
 [ 0.31622777 -0.32008722]
 [ 0.31622777 -0.25633242]
 [ 0.31622777 -0.17853607]
 [ 0.31622777  0.02340419]]
</pre></div>
</div>
</div>
</div>
<p>The first eigenvalue is roughly <span class="math notranslate nohighlight">\(0\)</span> as expected with an eigenvector which is proportional to the all-one vector. The second eigenvalue is somewhat close to the expected <span class="math notranslate nohighlight">\(q n = 0.2 \cdot 10 = 2\)</span> with an eigenvector that has different signs on the two blocks. This is consistent with our prediction.</p>
<p>The eigenvalues exhibit an interesting behavior that is common for random matrices. This is easier to see for larger <span class="math notranslate nohighlight">\(n\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">q</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">block_assignments</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">build_ssbm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">mmids</span><span class="o">.</span><span class="n">inhomogeneous_er_random_graph</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
<span class="n">L</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">laplacian_matrix</span><span class="p">(</span><span class="n">G</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">eigenvalues</span><span class="p">,</span> <span class="n">eigenvectors</span> <span class="o">=</span> <span class="n">LA</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">eigenvalues</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;lightblue&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Eigenvalue&#39;</span><span class="p">),</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/25d8bb7f3e707bd66fedc2b11e9c66f1461636483ad41ef93e48b12d0bb2985e.png" src="../../_images/25d8bb7f3e707bd66fedc2b11e9c66f1461636483ad41ef93e48b12d0bb2985e.png" />
</div>
</div>
<p>The first two eigenvalues are close to <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(0.2 \cdot 100 = 20\)</span> as expected. The rest of the eigenvalues are centered around <span class="math notranslate nohighlight">\( (0.2 + 0.8) 100 /2 = 50\)</span>, but they are quite spread out, with a density resembling a half-circle. This is related to <a class="reference external" href="https://en.wikipedia.org/wiki/Wigner_semicircle_distribution">Wigner’s semicircular law</a> which plays a key role in random matrix theory.</p>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
</section>
<section id="weyls-inequality">
<h3><span class="section-number">5.8.2.2. </span>Weyl’s inequality<a class="headerlink" href="#weyls-inequality" title="Link to this heading">#</a></h3>
<p>We prove an inequality on the sensitivity of eigenvalues which is useful in certain applications.</p>
<p>For a symmetric matrix <span class="math notranslate nohighlight">\(C \in  \mathbb{R}^{d \times d}\)</span>, we let <span class="math notranslate nohighlight">\(\lambda_j(C)\)</span>, <span class="math notranslate nohighlight">\(j=1, \ldots, d\)</span>, be the eigenvalues of <span class="math notranslate nohighlight">\(C\)</span> in non-increasing order with corresponding orthonormal eigenvectors <span class="math notranslate nohighlight">\(\mathbf{v}_j\)</span>, <span class="math notranslate nohighlight">\(j=1, \ldots, d\)</span>. The following lemma is one version of what is known as <em>Weyl’s Inequality</em>.</p>
<p><strong>LEMMA</strong> <strong>(Weyl)</strong> Let <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{d \times d}\)</span> and <span class="math notranslate nohighlight">\(B \in \mathbb{R}^{d \times d}\)</span> be symmetric matrices. Then, for all <span class="math notranslate nohighlight">\(j=1, \ldots, d\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\max_{j \in [d]} \left|\lambda_j(B) - \lambda_j(A)\right|
\leq \|B- A\|_2
\]</div>
<p>where <span class="math notranslate nohighlight">\(\|C\|_2\)</span> is the induced <span class="math notranslate nohighlight">\(2\)</span>-norm of <span class="math notranslate nohighlight">\(C\)</span>. <span class="math notranslate nohighlight">\(\flat\)</span></p>
<p><em>Proof idea:</em> We use the extremal characterization of the eigenvalues together with a dimension argument.</p>
<p><em>Proof:</em> For a symmetric matrix <span class="math notranslate nohighlight">\(C \in  \mathbb{R}^{d \times d}\)</span>, define the subspaces</p>
<div class="math notranslate nohighlight">
\[
\mathcal{V}_k(C) = \mathrm{span}(\mathbf{v}_1, \ldots,  \mathbf{v}_k)
\quad\text{and}\quad
\mathcal{W}_{d-k+1}(C) = \mathrm{span}(\mathbf{v}_k, \ldots,  \mathbf{v}_d)
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{v}_1,\ldots,\mathbf{v}_d\)</span> form an orthonormal basis of eigenvectors of <span class="math notranslate nohighlight">\(C\)</span>. Let <span class="math notranslate nohighlight">\(H = B - A\)</span>. We prove only the upper bound. The other direction follows from interchanging the roles of <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>. Because</p>
<div class="math notranslate nohighlight">
\[
\mathrm{dim}(\mathcal{V}_j(B)) 
+ \mathrm{dim}(\mathcal{W}_{d-j+1}(A))
= j + (d-j+1)
= d+1
\]</div>
<p>it it can be shown (Try it!) that</p>
<div class="math notranslate nohighlight">
\[
\mathrm{dim}\left(\mathcal{V}_j(B) \cap \mathcal{W}_{d-j+1}(A)\right)
\geq d+1 - d = 1.
\]</div>
<p>Hence the <span class="math notranslate nohighlight">\(\mathcal{V}_j(B) \cap \mathcal{W}_{d-j+1}(A)\)</span> is non-empty. Let <span class="math notranslate nohighlight">\(\mathbf{v}\)</span> be a unit vector in that intersection.</p>
<p>By <em>Courant-Fischer</em>,</p>
<div class="math notranslate nohighlight">
\[
\lambda_j(B)
\leq \langle \mathbf{v}, (A+H) \mathbf{v}\rangle
= \langle \mathbf{v}, A \mathbf{v}\rangle + \langle \mathbf{v}, H \mathbf{v}\rangle
\leq \lambda_j(A) + \langle \mathbf{v}, H \mathbf{v}\rangle.
\]</div>
<p>Moreover, by <em>Cauchy-Schwarz</em>, since <span class="math notranslate nohighlight">\(\|\mathbf{v}\|=1\)</span></p>
<div class="math notranslate nohighlight">
\[
\langle \mathbf{v}, H \mathbf{v}\rangle \leq \|\mathbf{v}\| \|H\mathbf{v}\| \leq \|H\|_2
\]</div>
<p>which proves the claim. <span class="math notranslate nohighlight">\(\square\)</span></p>
</section>
<section id="weighted-case">
<h3><span class="section-number">5.8.2.3. </span>Weighted case<a class="headerlink" href="#weighted-case" title="Link to this heading">#</a></h3>
<p>The concepts we have introduced can also be extended to weighted graphs, that is, graphs with weights on the edges. These weights might be a measure of the strength of the connection for instance. In this section, we briefly describe this extension, which is the basis for a <a class="reference external" href="https://en.wikipedia.org/wiki/Calculus_on_finite_weighted_graphs">discrete calculus</a>.</p>
<p><strong>DEFINITION</strong> <strong>(Weighted Graph or Digraph)</strong> A weighted graph (or weighted digraph) is a triple <span class="math notranslate nohighlight">\(G = (V, E, w)\)</span> where <span class="math notranslate nohighlight">\((V, E)\)</span> is a graph (or directed graph) and <span class="math notranslate nohighlight">\(w : E \to \mathbb{R}_+\)</span> is a function that assigns positive real weights to the edges. For ease of notation, we write <span class="math notranslate nohighlight">\(w_e = w_{ij} = w(i,j)\)</span> for the weight of edge <span class="math notranslate nohighlight">\(e = \{i,j\}\)</span> (or <span class="math notranslate nohighlight">\(e = (i,j)\)</span> in the directed case). <span class="math notranslate nohighlight">\(\natural\)</span></p>
<p>As we did for graphs, we denote the vertices <span class="math notranslate nohighlight">\(\{1,\ldots, n\}\)</span> and the edges <span class="math notranslate nohighlight">\(\{e_1,\ldots, e_{m}\}\)</span>, where <span class="math notranslate nohighlight">\(n = |V|\)</span> and <span class="math notranslate nohighlight">\(m =|E|\)</span>. Properties of graphs can be generalized naturally. For instance, one defines the degree of a vertex <span class="math notranslate nohighlight">\(i\)</span> as, in the undirected case,</p>
<div class="math notranslate nohighlight">
\[
\delta(i)
= \sum_{j:\{i,j\} \in E} w_{ij}.
\]</div>
<p>Similarly, in the directed case, the out-degree and in-degree are</p>
<div class="math notranslate nohighlight">
\[
\delta^+(i)
= \sum_{j: (i,j) \in E} w_{ij}
\qquad
\text{and}
\qquad
\delta^+(i)
= \sum_{j: (j,i) \in E} w_{ij}.
\]</div>
<p>In the undirected case, the adjacency matrix is generalized as follows. (A similar generalization holds for the directed case.)</p>
<p><strong>DEFINITION</strong> <strong>(Adjacency Matrix for Weighted Graph)</strong> Let <span class="math notranslate nohighlight">\(G = (V, E, w)\)</span> be a weighted graph with <span class="math notranslate nohighlight">\(n = |V|\)</span> vertices. The adjacency matrix <span class="math notranslate nohighlight">\(A\)</span> of <span class="math notranslate nohighlight">\(G\)</span> is the <span class="math notranslate nohighlight">\(n\times n\)</span> symmetric matrix
defined as</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
A_{ij} 
= 
\begin{cases}
w_{ij} &amp; \text{if $\{i,j\} \in E$}\\ 
0 &amp; \text{o.w.}
\end{cases}
\end{align*}\]</div>
<p><span class="math notranslate nohighlight">\(\natural\)</span></p>
<p>A similar generalization holds for the directed case.</p>
<p><strong>DEFINITION</strong> <strong>(Adjacency Matrix for Weighted Digraph)</strong> Let <span class="math notranslate nohighlight">\(G = (V, E, w)\)</span> be a weighted digraph with <span class="math notranslate nohighlight">\(n = |V|\)</span> vertices. The adjacency matrix <span class="math notranslate nohighlight">\(A\)</span> of <span class="math notranslate nohighlight">\(G\)</span> is the <span class="math notranslate nohighlight">\(n\times n\)</span> matrix
defined as</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
A_{ij} 
= 
\begin{cases}
w_{ij} &amp; \text{if $(i,j) \in E$}\\ 
0 &amp; \text{o.w.}
\end{cases}
\end{align*}\]</div>
<p><span class="math notranslate nohighlight">\(\natural\)</span></p>
<p><strong>Laplacian matrix for weighted graphs</strong> In the case of a weighted graph, the Laplacian can then be defined as follows.</p>
<p><strong>DEFINITION</strong> <strong>(Laplacian for Weighted Graph)</strong> Let <span class="math notranslate nohighlight">\(G = (V, E, w)\)</span> be a weighted graph with <span class="math notranslate nohighlight">\(n = |V|\)</span> vertices and adjacency matrix <span class="math notranslate nohighlight">\(A\)</span>. Let <span class="math notranslate nohighlight">\(D = \mathrm{diag}(\delta(1), \ldots, \delta(n))\)</span> be the weighted degree matrix. The Laplacian matrix associated to <span class="math notranslate nohighlight">\(G\)</span> is defined as <span class="math notranslate nohighlight">\(L = D - A\)</span>. <span class="math notranslate nohighlight">\(\natural\)</span></p>
<p>It can be shown (Try it!) that the Laplacian quadratic form satisfies in the weighted case</p>
<div class="math notranslate nohighlight">
\[
\langle \mathbf{x}, L \mathbf{x} \rangle
= \sum_{\{i,j\} \in E} w_{ij} (x_i - x_j)^2
\]</div>
<p>for <span class="math notranslate nohighlight">\(\mathbf{x} = (x_1,\ldots,x_n) \in \mathbb{R}^n\)</span>.</p>
<p>As a positive semidefinite matrix (Exercise: Why?), the weighted Laplacian has an orthonormal basis of eigenvectors with nonnegative eigenvalues that satisfy the variational characterization we derived above. In particular, if we denote the eigenvalues <span class="math notranslate nohighlight">\(0 = \mu_1 \leq \mu_2 \leq \cdots \leq \mu_n\)</span>, it follows from <em>Courant-Fischer</em> that</p>
<div class="math notranslate nohighlight">
\[
\mu_2 
= \min\left\{
\sum_{\{u, v\} \in E} w_{uv} (x_u - x_v)^2 \,:\,
\mathbf{x} = (x_1, \ldots, x_n) \in \mathbb{R}^n, \sum_{u=1}^n x_u = 0,
\sum_{u = 1}^n x_u^2 = 1
\right\}.
\]</div>
<p>If we generalize the cut ratio as</p>
<div class="math notranslate nohighlight">
\[
\phi(S)
= \frac{\sum_{i \in S, j \in S^c} w_{ij}}{\min\{|S|, |S^c|\}}
\]</div>
<p>for <span class="math notranslate nohighlight">\(\emptyset \neq S \subset V\)</span> and let</p>
<div class="math notranslate nohighlight">
\[
\phi_G
= \min\left\{
\phi(S)\,:\, \emptyset \neq S \subset V
\right\}
\]</div>
<p>it can be shown (Try it!) that</p>
<div class="math notranslate nohighlight">
\[
\mu_2 \leq 2 \phi_G
\]</div>
<p>as in the unweighted case.</p>
<p><strong>Normalized Laplacian</strong> Other variants of the Laplacian matrix have also been studied. We introduced the normalized Laplacian next. Recall that in the weighted case, the degree is defined as <span class="math notranslate nohighlight">\(\delta(i) = \sum_{j:\{i,j\} \in E} w_{i,j}\)</span>.</p>
<p><strong>DEFINITION</strong> <strong>(Normalized Laplacian)</strong> The normalized Laplacian of <span class="math notranslate nohighlight">\(G = (V,E,w)\)</span> with adjacency matrix <span class="math notranslate nohighlight">\(A\)</span> and degree matrix <span class="math notranslate nohighlight">\(D\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L} = I - D^{-1/2} A D^{-1/2}.
\]</div>
<p><span class="math notranslate nohighlight">\(\natural\)</span></p>
<p>Using our previous observations about multiplication by diagonal matrices, the entries of <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> are</p>
<div class="math notranslate nohighlight">
\[
(\mathcal{L})_{i,j} 
= (I - (D^{-1/2} A D^{-1/2})_{i,j}
= 1 - \frac{a_{i,j}}{\sqrt{\delta(i) \delta(j)}}.
\]</div>
<p>We also note the following relation to the Laplacian matrix:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L} 
= D^{-1/2} L D^{-1/2}.
\]</div>
<p>We check that the normalized Laplacian is symmetric:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\mathcal{L}^T 
&amp;= I^T - (D^{-1/2} A D^{-1/2})^T\\
&amp;= I - (D^{-1/2})^T A^T (D^{-1/2})^T\\
&amp;= I - D^{-1/2} A D^{-1/2}\\
&amp;= \mathcal{L}.
\end{align*}\]</div>
<p>It is also positive semidefinite. Indeed,</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}^T \mathcal{L} \mathbf{x}
= \mathbf{x}^T D^{-1/2} L D^{-1/2} \mathbf{x}
= (D^{-1/2} \mathbf{x})^T L (D^{-1/2} \mathbf{x})
\geq 0,
\]</div>
<p>by the properties of the Laplacian matrix.</p>
<p>Hence by the <em>Spectral Theorem</em>, we can write</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}
= \sum_{i=1}^n
\eta_i \mathbf{z}_i \mathbf{z}_i^T,
\]</div>
<p>where the <span class="math notranslate nohighlight">\(\mathbf{z}_i\)</span>s are orthonormal eigenvectors of <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> and the eigenvalues satisfy <span class="math notranslate nohighlight">\(0 \leq \eta_1 \leq \eta_2 \leq \cdots \leq \eta_n\)</span>.</p>
<p>One more observation: because the constant vector is eigenvector of <span class="math notranslate nohighlight">\(L\)</span> with eigenvalue <span class="math notranslate nohighlight">\(0\)</span>, we get that <span class="math notranslate nohighlight">\(D^{1/2} \mathbf{1}\)</span> is an eigenvector of <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> with eigenvalue <span class="math notranslate nohighlight">\(0\)</span>. So <span class="math notranslate nohighlight">\(\eta_1 = 0\)</span> and we set</p>
<div class="math notranslate nohighlight">
\[
(\mathbf{z}_1)_i 
= \left(\frac{D^{1/2} \mathbf{1}}{\|D^{1/2} \mathbf{1}\|_2}\right)_i
= \sqrt{\frac{\delta(i)}{\sum_{i\in V} \delta(i)}}, \quad \forall i \in [n],
\]</div>
<p>which makes <span class="math notranslate nohighlight">\(\mathbf{z}_1\)</span> into a unit norm vector.</p>
<p>The relationship to the Laplacian matrix immediately implies (prove it!) that</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}^T \mathcal{L} \mathbf{x}
= \sum_{\{i,j\} \in E} w_{ij} \left(\frac{x_i}{\sqrt{\delta(i)}} - \frac{x_j}{\sqrt{\delta(j)}}\right)^2,
\]</div>
<p>for <span class="math notranslate nohighlight">\(\mathbf{x} = (x_1,\ldots,x_n)^T \in \mathbb{R}^n\)</span>.</p>
<p>Through the change of variables</p>
<div class="math notranslate nohighlight">
\[
y_i = \frac{x_i}{\sqrt{\delta(i)}},
\]</div>
<p><em>Courant-Fischer</em> gives this time (Why?)</p>
<div class="math notranslate nohighlight">
\[
\eta_2
= \min\left\{
\sum_{\{u, v\} \in E} w_{uv} (y_u - y_v)^2 \,:\,
\mathbf{y} = (y_1, \ldots, y_n)^T \in \mathbb{R}^n, \sum_{u=1}^n \delta(u) y_u = 0,
\sum_{u = 1}^n \delta(u) y_u^2 = 1
\right\}.
\]</div>
<p>For a subset of vertices <span class="math notranslate nohighlight">\(S \subseteq V\)</span>, let</p>
<div class="math notranslate nohighlight">
\[
|S|_w
= \sum_{i \in S} \delta(i),
\]</div>
<p>which we refer to as the volume of <span class="math notranslate nohighlight">\(S\)</span>. It is measure of the size of <span class="math notranslate nohighlight">\(S\)</span> weighted by the degrees.</p>
<p>If we consider the normalized cut ratio, or bottleneck ratio,</p>
<div class="math notranslate nohighlight">
\[
\phi^N(S)
= \frac{\sum_{i \in S, j \in S^c} w_{ij}}{\min\{|S|_w, |S^c|_w\}}
\]</div>
<p>for <span class="math notranslate nohighlight">\(\emptyset \neq S \subset V\)</span> and let</p>
<div class="math notranslate nohighlight">
\[
\phi^N_G
= \min\left\{
\phi^N(S)\,:\, \emptyset \neq S \subset V
\right\}
\]</div>
<p>it can be shown (Try it!) that</p>
<div class="math notranslate nohighlight">
\[
\eta_2 \leq 2 \phi^N_G.
\]</div>
<p>The normalized cut ratio is similar to the cut ratio, except that the notion of balance of the cut is measured in terms of volume. Note that this concept is also useful in the unweighted case.</p>
<p>We will an application of the normalized Laplacian later in this chapter.</p>
</section>
<section id="image-segmentation">
<h3><span class="section-number">5.8.2.4. </span>Image segmentation<a class="headerlink" href="#image-segmentation" title="Link to this heading">#</a></h3>
<p>We give a different, more involved application of the ideas developed in this topic to image segmentation. Let us quote Wikipedia:</p>
<blockquote>
<div><p>In computer vision, image segmentation is the process of partitioning a digital image into multiple segments (sets of pixels, also known as image objects). The goal of segmentation is to simplify and/or change the representation of an image into something that is more meaningful and easier to analyze. Image segmentation is typically used to locate objects and boundaries (lines, curves, etc.) in images. More precisely, image segmentation is the process of assigning a label to every pixel in an image such that pixels with the same label share certain characteristics.</p>
</div></blockquote>
<p>Throughout, we will use the <a class="reference external" href="https://scikit-image.org"><code class="docutils literal notranslate"><span class="pre">scikit-image</span></code></a> library for processing images.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">io</span><span class="p">,</span> <span class="n">segmentation</span><span class="p">,</span> <span class="n">color</span>
<span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">graph</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
</pre></div>
</div>
</div>
</div>
<p>As an example, here is a picture of cell nuclei taken through optical microscopy as part of some medical experiment. It is taken from <a class="reference external" href="https://www.kaggle.com/c/data-science-bowl-2018/data">here</a>. Here we used the function <a class="reference external" href="https://scikit-image.org/docs/dev/api/skimage.io.html#skimage.io.imread"><code class="docutils literal notranslate"><span class="pre">skimage.io.imread</span></code></a> to load an image from file.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;cell-nuclei.png&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/0accf47ed82b1d8f703ff13ffeaa3b86ea7f2bf8182762182fc6d4ae4763fba6.png" src="../../_images/0accf47ed82b1d8f703ff13ffeaa3b86ea7f2bf8182762182fc6d4ae4763fba6.png" />
</div>
</div>
<p>Suppose that, as part of this experiment, we have a large number of such images and need to keep track of the cell nuclei in some way (maybe count how many there are, or track them from frame to frame). A natural pre-processing step is to identify the cell nuclei in the image. We use image segmentation for this purpose.</p>
<p>We will come back to the example below. Let us start with some further examples.</p>
<p>We will first work with the following <a class="reference external" href="https://www.dhs.wisconsin.gov/areaadmin/index.htm">map of Wisconsin regions</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;wisconsin-regions.png&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/02aae9577d9ede741f8e9bafe938fe1f02e1b4f4bc08d4269dcc40b9ccb61151.png" src="../../_images/02aae9577d9ede741f8e9bafe938fe1f02e1b4f4bc08d4269dcc40b9ccb61151.png" />
</div>
</div>
<p>A color image such as this one is encoded as a <span class="math notranslate nohighlight">\(3\)</span>-dimensional array (or <a class="reference external" href="https://en.wikipedia.org/wiki/Tensor">tensor</a>), meaning that it is an array with <span class="math notranslate nohighlight">\(3\)</span> indices (unlike matrices which have only two indices).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(709, 652, 3)
</pre></div>
</div>
</div>
</div>
<p>The first two indices capture the position of a pixel. The third index capture the <a class="reference external" href="https://en.wikipedia.org/wiki/RGB_color_model">RGB color model</a>. Put differently, each pixel in the image has three numbers (between 0 and 255) attached to it that encodes its color.</p>
<p>For instance, at position <span class="math notranslate nohighlight">\((300,400)\)</span> the RGB color is:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img</span><span class="p">[</span><span class="mi">300</span><span class="p">,</span><span class="mi">400</span><span class="p">,:]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([111, 172, 232], dtype=uint8)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">img</span><span class="p">[</span><span class="mi">300</span><span class="p">,</span><span class="mi">400</span><span class="p">,:],(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/f163f47bc2a0d1399c133af4099ee192e9e53a392412b6f893948154b334c506.png" src="../../_images/f163f47bc2a0d1399c133af4099ee192e9e53a392412b6f893948154b334c506.png" />
</div>
</div>
<p>To perform image segmentation using the spectral graph theory we have developed, we transform our image into a graph.</p>
<p>The first step is to coarsen the image by creating super-pixels, or regions of pixels that are close and have similar color. For this purpose, we will use <a class="reference external" href="https://scikit-image.org/docs/stable/api/skimage.segmentation.html#skimage.segmentation.slic"><code class="docutils literal notranslate"><span class="pre">skimage.segmentation.slic</span></code></a>, which in essence uses <span class="math notranslate nohighlight">\(k\)</span>-means clustering on the color space to identify blobs of pixels that are in close proximity and have similar colors. It takes as imput a number of super-pixels desired (<code class="docutils literal notranslate"><span class="pre">n_segments</span></code>), a compactness parameter (<code class="docutils literal notranslate"><span class="pre">compactness</span></code>) and a smoothing parameter (<code class="docutils literal notranslate"><span class="pre">sigma</span></code>). The output is a label assignment for each pixel in the form of a <span class="math notranslate nohighlight">\(2\)</span>-dimensional array.</p>
<p>On the choice of the parameter <code class="docutils literal notranslate"><span class="pre">compactness</span></code> via <a class="reference external" href="https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.slic">scikit-image</a>:</p>
<blockquote>
<div><p>Balances color proximity and space proximity. Higher values give more weight to space proximity, making superpixel shapes more square/cubic. This parameter depends strongly on image contrast and on the shapes of objects in the image. We recommend exploring possible values on a log scale, e.g., 0.01, 0.1, 1, 10, 100, before refining around a chosen value.</p>
</div></blockquote>
<p>The parameter <code class="docutils literal notranslate"><span class="pre">sigma</span></code> controls the level of <a class="reference external" href="https://en.wikipedia.org/wiki/Gaussian_blur">blurring</a> applied to the image as a pre-processing step. In practice, experimentation is required to choose good parameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">labels1</span> <span class="o">=</span> <span class="n">segmentation</span><span class="o">.</span><span class="n">slic</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> 
                            <span class="n">compactness</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> 
                            <span class="n">n_segments</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> 
                            <span class="n">sigma</span><span class="o">=</span><span class="mf">2.</span><span class="p">,</span> 
                            <span class="n">start_label</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">labels1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 0  0  0 ...  8  8  8]
 [ 0  0  0 ...  8  8  8]
 [ 0  0  0 ...  8  8  8]
 ...
 [77 77 77 ... 79 79 79]
 [77 77 77 ... 79 79 79]
 [77 77 77 ... 79 79 79]]
</pre></div>
</div>
</div>
</div>
<p>A neat way to vizualize the super-pixels is to use the function <a class="reference external" href="https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.label2rgb"><code class="docutils literal notranslate"><span class="pre">skimage.color.label2rgb</span></code></a> which takes as input an image and an array of labels. In the mode <code class="docutils literal notranslate"><span class="pre">kind='avg'</span></code>, it outputs a new image where the color of each pixel is replaced with the average color of its label (that is, the average of the RGB color over all pixels with the same label). As they say, an image is worth a thousand words - let’s just see what it does.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">out1</span> <span class="o">=</span> <span class="n">color</span><span class="o">.</span><span class="n">label2rgb</span><span class="p">(</span><span class="n">labels1</span><span class="p">,</span> <span class="n">img</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;avg&#39;</span><span class="p">,</span> <span class="n">bg_label</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">out1</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(709, 652, 3)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">out1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/6433bf1882e58e79cba96f43776a7a0d10bcc79e039e3696517e467870f1a0df.png" src="../../_images/6433bf1882e58e79cba96f43776a7a0d10bcc79e039e3696517e467870f1a0df.png" />
</div>
</div>
<p>Recall that our goal is to turn our original image into a graph. After the first step of creating super-pixels, the second step is to form a graph whose nodes are the super-pixels. Edges are added between adjacent super-pixels and a weight is given to each edge which reflects the difference in mean color between the two.</p>
<p>We use <a class="reference external" href="https://scikit-image.org/docs/stable/api/skimage.graph.html#skimage.graph.rag_mean_color"><code class="docutils literal notranslate"><span class="pre">skimage.graph.rag_mean_color</span></code></a>. In mode <code class="docutils literal notranslate"><span class="pre">similarity</span></code>, it uses the following weight formula (quoting the documentation):</p>
<blockquote>
<div><p>The weight between two adjacent regions is exp(-d^2/sigma) where d=|c1-c2|, where c1 and c2 are the mean colors of the two regions. It represents how similar two regions are.</p>
</div></blockquote>
<p>The output, which is known as a region adjacency graph (RAG), is a <code class="docutils literal notranslate"><span class="pre">NetworkX</span></code> graph and can be manipulated using that package.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">rag_mean_color</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">labels1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;similarity&#39;</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="n">nx</span><span class="o">.</span><span class="n">spring_layout</span><span class="p">(</span><span class="n">g</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/130b3010c4211461bc01b866978469ebe601c7424362249fd299c1a7e98a8831.png" src="../../_images/130b3010c4211461bc01b866978469ebe601c7424362249fd299c1a7e98a8831.png" />
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">scikit-image</span></code> also provides a more effective way of vizualizing a RAG, using the function <a class="reference external" href="https://scikit-image.org/docs/dev/api/skimage.future.graph.html#skimage.future.graph.show_rag"><code class="docutils literal notranslate"><span class="pre">skimage.future.graph.show_rag</span></code></a>. Here the graph is super-imposed on the image and the edge weights are depicted by their color.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">lc</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">show_rag</span><span class="p">(</span><span class="n">labels1</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">lc</span><span class="p">,</span> <span class="n">fraction</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/dfbd8ff7a07a87e84cce4016110f06b629eb0cbef95819256736fa60b244e8cf.png" src="../../_images/dfbd8ff7a07a87e84cce4016110f06b629eb0cbef95819256736fa60b244e8cf.png" />
</div>
</div>
<p>We can apply the spectral clustering techniques we have developed in this chapter. Next we compute a spectral decomposition of the weighted Laplacian and plot the eigenvalues.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">L</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">laplacian_matrix</span><span class="p">(</span><span class="n">g</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 9.93627574e-01 -9.93627545e-01  0.00000000e+00 ...  0.00000000e+00
   0.00000000e+00  0.00000000e+00]
 [-9.93627545e-01  1.98331432e+00 -9.89686777e-01 ...  0.00000000e+00
   0.00000000e+00  0.00000000e+00]
 [ 0.00000000e+00 -9.89686777e-01  1.72084919e+00 ...  0.00000000e+00
   0.00000000e+00  0.00000000e+00]
 ...
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  4.03242708e-05
   0.00000000e+00  0.00000000e+00]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00
   7.93893423e-01  0.00000000e+00]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00
   0.00000000e+00  1.99992197e+00]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">LA</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">w</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/72220c65efaa518e54ab6a7f975d2b78119d4de7930e1b5a59e4de5562cca969.png" src="../../_images/72220c65efaa518e54ab6a7f975d2b78119d4de7930e1b5a59e4de5562cca969.png" />
</div>
</div>
<p>From the theory, this suggests that there are roughly 15 components in this graph. We project to <span class="math notranslate nohighlight">\(15\)</span> dimensions and apply <span class="math notranslate nohighlight">\(k\)</span>-means clustering to find segments. Rather than using our own implementation, we use <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"><code class="docutils literal notranslate"><span class="pre">sklearn.cluster.KMeans</span></code></a> from the <a class="reference external" href="https://scikit-learn.org/stable/index.html"><code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code></a> library. That implementation uses the <a class="reference external" href="https://en.wikipedia.org/wiki/K-means%2B%2B"><span class="math notranslate nohighlight">\(k\)</span>-means<span class="math notranslate nohighlight">\(++\)</span></a> initialization, which is particularly effective in practice. A label assignment for each node can be accessed using <code class="docutils literal notranslate"><span class="pre">labels_</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ndims</span> <span class="o">=</span> <span class="mi">15</span> <span class="c1"># number of dimensions to project to</span>
<span class="n">nsegs</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># number of segments</span>

<span class="n">top</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">w</span><span class="p">)[</span><span class="mi">1</span><span class="p">:</span><span class="n">ndims</span><span class="p">]</span>
<span class="n">topvecs</span> <span class="o">=</span> <span class="n">v</span><span class="p">[:,</span><span class="n">top</span><span class="p">]</span>
<span class="n">topvals</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="n">top</span><span class="p">]</span>

<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">nsegs</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">12345</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">topvecs</span><span class="p">)</span>
<span class="n">assign_seg</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>
<span class="nb">print</span><span class="p">(</span><span class="n">assign_seg</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1 1 1 1 1 1 1 1 1 2 9 1 1 2 1 1 1 9 8 1 9 6 9 2 1 9 1 9 2 9 9 2 2 4 1 2 9
 9 2 4 3 2 4 4 2 2 9 2 4 3 1 5 2 4 3 4 2 0 5 4 5 3 3 4 0 0 0 5 5 1 5 1 3 0
 0 0 5 5 7 3 5]
</pre></div>
</div>
</div>
</div>
<p>To vizualize the segmentation, we assign to each segment (i.e., collection of super-pixels) a random color. This can be done using <a class="reference external" href="https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.label2rgb"><code class="docutils literal notranslate"><span class="pre">skimage.color.label2rgb</span></code></a> again, this time in mode <code class="docutils literal notranslate"><span class="pre">kind='overlay'</span></code>. First, we assign to each pixel from the original image its label under this clustering. Recall that <code class="docutils literal notranslate"><span class="pre">labels1</span></code> assigns to each pixel its super-pixel (represented by a node of the RAG), so that applying <code class="docutils literal notranslate"><span class="pre">assign_seg</span></code> element-wise to <code class="docutils literal notranslate"><span class="pre">labels1</span></code> results is assigning a cluster to each pixel. In code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">labels2</span> <span class="o">=</span> <span class="n">assign_seg</span><span class="p">[</span><span class="n">labels1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">labels2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[1 1 1 ... 1 1 1]
 [1 1 1 ... 1 1 1]
 [1 1 1 ... 1 1 1]
 ...
 [5 5 5 ... 3 3 3]
 [5 5 5 ... 3 3 3]
 [5 5 5 ... 3 3 3]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">out2</span> <span class="o">=</span> <span class="n">color</span><span class="o">.</span><span class="n">label2rgb</span><span class="p">(</span><span class="n">labels2</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;overlay&#39;</span><span class="p">,</span> <span class="n">bg_label</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">out2</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(709, 652, 3)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">out2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/f1bd793e0949104fb55a052bf68a372f744830334d620d5b24aa0a829fb2e7f3.png" src="../../_images/f1bd793e0949104fb55a052bf68a372f744830334d620d5b24aa0a829fb2e7f3.png" />
</div>
</div>
<p>As you can see, the result is reasonable but far from perfect.</p>
<p>For ease of use, we encapsulate the main steps above in sub-routines.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">imgseg_rag</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">compactness</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">n_spixels</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">)):</span>
    <span class="n">labels1</span> <span class="o">=</span> <span class="n">segmentation</span><span class="o">.</span><span class="n">slic</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> 
                                <span class="n">compactness</span><span class="o">=</span><span class="n">compactness</span><span class="p">,</span> 
                                <span class="n">n_segments</span><span class="o">=</span><span class="n">n_spixels</span><span class="p">,</span> 
                                <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> 
                                <span class="n">start_label</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">out1</span> <span class="o">=</span> <span class="n">color</span><span class="o">.</span><span class="n">label2rgb</span><span class="p">(</span><span class="n">labels1</span><span class="p">,</span> <span class="n">img</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;avg&#39;</span><span class="p">,</span> <span class="n">bg_label</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">rag_mean_color</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">labels1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;similarity&#39;</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">out1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">labels1</span><span class="p">,</span> <span class="n">g</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">imgseg_eig</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>
    <span class="n">L</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">laplacian_matrix</span><span class="p">(</span><span class="n">g</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
    <span class="n">w</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">LA</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">w</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">w</span><span class="p">,</span><span class="n">v</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">imgseg_labels</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">n_dims</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_segments</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">top</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">w</span><span class="p">)[</span><span class="mi">1</span><span class="p">:</span><span class="n">n_dims</span><span class="p">]</span>
    <span class="n">topvecs</span> <span class="o">=</span> <span class="n">v</span><span class="p">[:,</span><span class="n">top</span><span class="p">]</span>
    <span class="n">topvals</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="n">top</span><span class="p">]</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">n_segments</span><span class="p">,</span> 
                    <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">topvecs</span><span class="p">)</span>
    <span class="n">assign_seg</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>
    <span class="n">labels2</span> <span class="o">=</span> <span class="n">assign_seg</span><span class="p">[</span><span class="n">labels1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">labels2</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">imgseg_viz</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">labels2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">)):</span>
    <span class="n">out2</span> <span class="o">=</span> <span class="n">color</span><span class="o">.</span><span class="n">label2rgb</span><span class="p">(</span><span class="n">labels2</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;overlay&#39;</span><span class="p">,</span> <span class="n">bg_label</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">out2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s try a more complicated image. This one is taken from <a class="reference external" href="https://www.reddit.com/r/aww/comments/169s6e/badgers_can_be_cute_too/">here</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;two-badgers.jpg&#39;</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/e756f9fd40ba2c28f31cfca1836a6c1812ff76d46afb0d60fe37179a419e9abd.png" src="../../_images/e756f9fd40ba2c28f31cfca1836a6c1812ff76d46afb0d60fe37179a419e9abd.png" />
</div>
</div>
<p>Recall that the choice of parameters requires significant fidgeting.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">labels1</span><span class="p">,</span> <span class="n">g</span> <span class="o">=</span> <span class="n">imgseg_rag</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> 
                        <span class="n">compactness</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> 
                        <span class="n">n_spixels</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> 
                        <span class="n">sigma</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> 
                        <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/98a936f7906a7623fd9a1d5724735886b66fa8cad6a25eaf7401a8a4757af4ff.png" src="../../_images/98a936f7906a7623fd9a1d5724735886b66fa8cad6a25eaf7401a8a4757af4ff.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">imgseg_eig</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/fa5fe7dfb100454def041e4349e782ca80d2bfff0d0429dac34ed8055c5c5f51.png" src="../../_images/fa5fe7dfb100454def041e4349e782ca80d2bfff0d0429dac34ed8055c5c5f51.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">labels2</span> <span class="o">=</span> <span class="n">imgseg_labels</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">n_dims</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">n_segments</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">535</span><span class="p">)</span>
<span class="n">imgseg_viz</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">labels2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/38fd95bbea74053d3410dcdd8dee5e02ad10b75cf74ec8eeac61aad4a80b5e41.png" src="../../_images/38fd95bbea74053d3410dcdd8dee5e02ad10b75cf74ec8eeac61aad4a80b5e41.png" />
</div>
</div>
<p>Again, the results are far from perfect - but not unreasonable.</p>
<p>Finally, we return to our medical example. We first reload the image and find super-pixels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;cell-nuclei.png&#39;</span><span class="p">)</span>
<span class="n">labels1</span><span class="p">,</span> <span class="n">g</span> <span class="o">=</span> <span class="n">imgseg_rag</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">compactness</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span><span class="n">n_spixels</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span><span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/3ddf57ce3246e2e397659d79c78a47ad98d7ef97ba099fca9439090dc6cf83d9.png" src="../../_images/3ddf57ce3246e2e397659d79c78a47ad98d7ef97ba099fca9439090dc6cf83d9.png" />
</div>
</div>
<p>We then form the weighted Laplacian and plot its eigenvalues. This time, about <span class="math notranslate nohighlight">\(40\)</span> dimensions seem appropriate.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">imgseg_eig</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/51dc0dbdfd43bfd3c9e813a5a527e17a29b4e160d1599fc79837eb82f05baace.png" src="../../_images/51dc0dbdfd43bfd3c9e813a5a527e17a29b4e160d1599fc79837eb82f05baace.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">labels2</span> <span class="o">=</span> <span class="n">imgseg_labels</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">n_dims</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">n_segments</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">535</span><span class="p">)</span>
<span class="n">imgseg_viz</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">labels2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/307e2266cb4da8938e10f8edd6db9db0400b5976763f47079dc3964a45d82096.png" src="../../_images/307e2266cb4da8938e10f8edd6db9db0400b5976763f47079dc3964a45d82096.png" />
</div>
</div>
<p>This method is quite finicky. The choice of parameters affects the results significantly. You should see for yourself.</p>
<p>We mention that <code class="docutils literal notranslate"><span class="pre">scikit-image</span></code> has an implementation of a closely related method, Normalized Cut, <a class="reference external" href="https://scikit-image.org/docs/dev/api/skimage.graph.html#skimage.graph.cut_normalized"><code class="docutils literal notranslate"><span class="pre">skimage.graph.cut_normalized</span></code></a>. Rather than performing <span class="math notranslate nohighlight">\(k\)</span>-means after projection, it recursively performs <span class="math notranslate nohighlight">\(2\)</span>-way cuts on the RAG and resulting subgraphs.</p>
<p>We try it next. The results are similar as you can see.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">labels2</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">cut_normalized</span><span class="p">(</span><span class="n">labels1</span><span class="p">,</span> <span class="n">g</span><span class="p">)</span>
<span class="n">imgseg_viz</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">labels2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/783cc1bf1cde12e0f572f92ba128cd49d457e8b5fc3ea06477afe07475a282ba.png" src="../../_images/783cc1bf1cde12e0f572f92ba128cd49d457e8b5fc3ea06477afe07475a282ba.png" />
</div>
</div>
<p>There are many other image segmentation methods. See for example <a class="reference external" href="https://scikit-image.org/docs/dev/api/skimage.segmentation.html#module-skimage.segmentation">here</a>.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chap05_specgraph/supp"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../exercises/roch-mmids-specgraph-exercises.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">5.7. </span>Exercises</p>
      </div>
    </a>
    <a class="right-next"
       href="../../chap06_prob/00_intro/roch-mmids-prob-intro.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">6. </span>Probabilistic models: from simple to complex</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quizzes-solutions-code-etc">5.8.1. Quizzes, solutions, code, etc.</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#just-the-code">5.8.1.1. Just the code</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#self-assessment-quizzes">5.8.1.2. Self-assessment quizzes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#auto-quizzes">5.8.1.3. Auto-quizzes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#solutions-to-odd-numbered-warm-up-exercises">5.8.1.4. Solutions to odd-numbered warm-up exercises</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-outcomes">5.8.1.5. Learning outcomes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-sections">5.8.2. Additional sections</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#spectral-properties-of-sbm">5.8.2.1. Spectral properties of SBM</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#weyls-inequality">5.8.2.2. Weyl’s inequality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#weighted-case">5.8.2.3. Weighted case</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#image-segmentation">5.8.2.4. Image segmentation</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Sebastien Roch
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>