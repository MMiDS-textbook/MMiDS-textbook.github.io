

<!DOCTYPE html>


<html data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>1.3. Clustering: an objective, an algorithm and a guarantee &#8212; MMiDS Online Book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chap01_intro/03_clustering/roch-mmids-intro-3clustering';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="1.4. Some observations about high-dimensional data" href="../04_highdim/roch-mmids-intro-4highdim.html" />
    <link rel="prev" title="1.2. Background: review of basic linear algebra, calculus, and probability" href="../02_review/roch-mmids-intro-2review.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/mmids-cover.png" class="logo__image only-light" alt="MMiDS Online Book - Home"/>
    <script>document.write(`<img src="../../_static/mmids-cover.png" class="logo__image only-dark" alt="MMiDS Online Book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">MMiDS</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../00_intro/roch-mmids-intro-0intro.html">1. Introduction</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../01_motiv/roch-mmids-intro-1motiv.html">1.1. Motivating example: species delimitation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02_review/roch-mmids-intro-2review.html">1.2. Background: review of basic linear algebra, calculus, and probability</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">1.3. Clustering: an objective, an algorithm and a guarantee</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04_highdim/roch-mmids-intro-4highdim.html">1.4. Some observations about high-dimensional data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../05_adv/roch-mmids-intro-5adv.html">1.5. Advanced material</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../chap02_ls/00_intro/roch-mmids-ls-intro.html">2. Least squares</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/01_motiv/roch-mmids-ls-1motiv.html">2.1. Motivating example: predicting sales</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/02_subspaces/roch-mmids-ls-2spaces.html">2.2. Background: linear spaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/03_orthog/roch-mmids-ls-3orthog.html">2.3. A key concept: orthogonality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/04_overdetermined/roch-mmids-ls-4overdetermined.html">2.4. Overdetermined linear systems and regression analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/05_qr/roch-mmids-ls-5qr.html">2.5. QR decomposition and Householder transformations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/06_adv/roch-mmids-ls-6adv.html">2.6. Advanced material</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Clustering: an objective, an algorithm and a guarantee</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-k-means-objective">1.3.1. The k-means objective</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-k-means-algorithm-and-its-analysis">1.3.2. The k-means algorithm and its analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#penguins-dataset">1.3.3. Penguins dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#matrix-form-of-k-means-clustering">1.3.4. Matrix form of k-means clustering</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="clustering-an-objective-an-algorithm-and-a-guarantee">
<h1><span class="section-number">1.3. </span>Clustering: an objective, an algorithm and a guarantee<a class="headerlink" href="#clustering-an-objective-an-algorithm-and-a-guarantee" title="Permalink to this headline">#</a></h1>
<p>Consider the following fundamental problem in data science. We are given <span class="math notranslate nohighlight">\(n\)</span> vectors <span class="math notranslate nohighlight">\(\mathbf{x}_1,\ldots,\mathbf{x}_n\)</span> in <span class="math notranslate nohighlight">\(\mathbb{R}^d\)</span>. Our goal is to find a good <a href="https://en.wikipedia.org/wiki/Cluster_analysis">clustering</a>: loosely speaking, we want to partition these data points into <span class="math notranslate nohighlight">\(k\)</span> disjoint subsets - or clusters - with small pairwise distances within clusters and large pairwise distances across clusters.</p>
<p>To make this rather vague problem more precise, we consider a specific objective function known as the <span class="math notranslate nohighlight">\(k\)</span>-means objective. Our approach here will be typical of how one might approach a mathematical data science problem. We will first formulate the problem as an optimization problem, then derive an algorithm to solve it, and finally provide some rigorous guarantees about the output.</p>
<p><img alt="Data points forming three clusters" src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Cluster-2.svg/640px-Cluster-2.svg.png" /></p>
<p><strong>Figure:</strong> Data points forming three clusters (<a class="reference external" href="https://commons.wikimedia.org/wiki/File:Cluster-2.svg">Source</a>)</p>
<p>But first, we need to define precisely what we are trying to extract from the data. What is the mathematical structure of the solution sought? Fix a number of clusters <span class="math notranslate nohighlight">\(k\)</span>. Formally, we define a clustering as a partition.</p>
<p><strong>DEFINITION</strong> <strong>(Partition)</strong> A partition of <span class="math notranslate nohighlight">\([n] = \{1,\ldots,n\}\)</span> of size <span class="math notranslate nohighlight">\(k\)</span> is a collection of non-empty subsets <span class="math notranslate nohighlight">\(C_1,\ldots,C_k \subseteq [n]\)</span> that:</p>
<ul class="simple">
<li><p>are pairwise disjoint, i.e., <span class="math notranslate nohighlight">\(C_i \cap C_j = \emptyset\)</span>, <span class="math notranslate nohighlight">\(\forall i \neq j\)</span></p></li>
<li><p>cover all of <span class="math notranslate nohighlight">\([n]\)</span>, i.e., <span class="math notranslate nohighlight">\(\cup_{i=1}^k C_i = [n]\)</span>.</p></li>
</ul>
<p><span class="math notranslate nohighlight">\(\natural\)</span></p>
<p><strong>EXAMPLE:</strong> Suppose we are given <span class="math notranslate nohighlight">\(8\)</span> data points in <span class="math notranslate nohighlight">\(\mathbb{R}^2\)</span> as follows:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
&amp;\mathbf{x}_1 = \begin{pmatrix}1\\0\end{pmatrix},
\mathbf{x}_2 = \begin{pmatrix}-2\\0\end{pmatrix},
\mathbf{x}_3 = \begin{pmatrix}-2\\1\end{pmatrix},
\mathbf{x}_4 = \begin{pmatrix}1\\-3\end{pmatrix},\\
&amp;\mathbf{x}_5 = \begin{pmatrix}-10\\10\end{pmatrix},
\mathbf{x}_6 = \begin{pmatrix}2\\-2\end{pmatrix},
\mathbf{x}_7 = \begin{pmatrix}-3\\1\end{pmatrix},
\mathbf{x}_8 = \begin{pmatrix}3\\-1\end{pmatrix}.
\end{align*}\]</div>
<p>So here <span class="math notranslate nohighlight">\(n=8\)</span> and <span class="math notranslate nohighlight">\(d = 2\)</span>. Assume we look for <span class="math notranslate nohighlight">\(k = 3\)</span> clusters. Then a valid clustering would be for instance:</p>
<div class="math notranslate nohighlight">
\[
C_1 = \{1, 4, 6, 8\}, C_2 = \{2, 3, 7\}, C_3 = \{5\},
\]</div>
<p>which corresponds to assigning data points <span class="math notranslate nohighlight">\(\mathbf{x}_1, \mathbf{x}_4, \mathbf{x}_6, \mathbf{x}_8\)</span> to the first cluster, data points <span class="math notranslate nohighlight">\(\mathbf{x}_2, \mathbf{x}_3, \mathbf{x}_7\)</span> to the second cluster and data point <span class="math notranslate nohighlight">\(\mathbf{x}_5\)</span> to the third cluster. Note in particular that the sets <span class="math notranslate nohighlight">\(C_1, C_2, C_3\)</span> satisfy the conditions of a partition, i.e., they are disjoint and cover all of <span class="math notranslate nohighlight">\([8] = \{1,2,\ldots,8\}\)</span>. Or put differently, each data point is assigned to one and exactly one cluster. <span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p>We number the clusters <span class="math notranslate nohighlight">\(C_1,\ldots,C_k\)</span> for notational convenience, but their order is meaningless. Two partitions are the same if they are the same family of subsets. E.g., in the previous example,
<span class="math notranslate nohighlight">\(C_1 = \{1, 4, 6, 8\}, C_2 = \{2, 3, 7\}, C_3 = \{5\}\)</span> and <span class="math notranslate nohighlight">\(C_1 = \{5\}, C_2 = \{1, 4, 6, 8\}, C_3 = \{2, 3, 7\}\)</span> are equivalent clusterings.</p>
<section id="the-k-means-objective">
<h2><span class="section-number">1.3.1. </span>The k-means objective<a class="headerlink" href="#the-k-means-objective" title="Permalink to this headline">#</a></h2>
<p>Under the <span class="math notranslate nohighlight">\(k\)</span>-means objective, the “cost” of <span class="math notranslate nohighlight">\(C_1,\ldots,C_k\)</span> is then defined as</p>
<div class="math notranslate nohighlight">
\[
\mathcal{G}(C_1,\ldots,C_k) = \min_{\boldsymbol{\mu}_1,\ldots,\boldsymbol{\mu}_k \in \mathbb{R}^d} 
\sum_{i=1}^k \sum_{j \in C_i} \|\mathbf{x}_j - \boldsymbol{\mu}_i\|^2.
\]</div>
<p>Here <span class="math notranslate nohighlight">\(\boldsymbol{\mu}_i \in \mathbb{R}^d\)</span> is the representative – or center – of cluster <span class="math notranslate nohighlight">\(C_i\)</span>. Note that <span class="math notranslate nohighlight">\(\boldsymbol{\mu}_i\)</span> need not be one of the <span class="math notranslate nohighlight">\(\mathbf{x}_j\)</span>’s.</p>
<p>Our goal is to find a partition <span class="math notranslate nohighlight">\(C_1,\ldots,C_k\)</span> that minimizes <span class="math notranslate nohighlight">\(\mathcal{G}(C_1,\ldots,C_k)\)</span>, i.e., solves the problem</p>
<div class="math notranslate nohighlight">
\[
\min_{C_1,\ldots,C_k} \mathcal{G}(C_1,\ldots,C_k)
\]</div>
<p>over all partitions of <span class="math notranslate nohighlight">\([n]\)</span> of size <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p>To quote <a class="reference external" href="https://en.wikipedia.org/wiki/Cluster_analysis#Centroid-based_clustering">Wikipedia</a>:</p>
<blockquote>
<div><p>In centroid-based clustering, clusters are represented by a central vector, which may not necessarily be a member of the data set. When the number of clusters is fixed to k, k-means clustering gives a formal definition as an optimization problem: find the k cluster centers and assign the objects to the nearest cluster center, such that the squared distances from the cluster are minimized.</p>
</div></blockquote>
<p><img alt="Illustration of k-means clustering" src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d1/KMeans-density-data.svg/477px-KMeans-density-data.svg.png" /></p>
<p><strong>Figure:</strong> Illustration of k-means clustering (<a class="reference external" href="https://commons.wikimedia.org/wiki/File:KMeans-density-data.svg">Source</a>)</p>
<p>In general, the problem is <a href="https://en.wikipedia.org/wiki/NP-hardness">NP-hard</a>, that is, roughly speaking no “fast” algorithm is expected to exist to solve it. The <span class="math notranslate nohighlight">\(k\)</span>-means algorithm is a popular heuristic. It is based on the idea that the following two sub-problems are easy to solve:</p>
<ol class="arabic simple">
<li><p>finding the optimal representatives for a fixed partition;</p></li>
<li><p>finding the optimal partition for a fixed set of representatives.</p></li>
</ol>
<p>One then alternates between the two (perhaps until progress falls below a tolerance). This is reasonable since our goal, as we pointed out above, is to solve the minimization problem</p>
<div class="math notranslate nohighlight">
\[
\min_{C_1,\ldots,C_k} \min_{\boldsymbol{\mu}_1,\ldots,\boldsymbol{\mu}_k \in \mathbb{R}^d} 
\sum_{i=1}^k \sum_{j \in C_i} \|\mathbf{x}_j - \boldsymbol{\mu}_i\|^2
\]</div>
<p>where <span class="math notranslate nohighlight">\(C_1,\ldots,C_k\)</span> ranges over all partitions of <span class="math notranslate nohighlight">\([n]\)</span> of size <span class="math notranslate nohighlight">\(k\)</span>. Fixing partition <span class="math notranslate nohighlight">\(C_1,\ldots,C_k\)</span> and miniminizing over <span class="math notranslate nohighlight">\(\boldsymbol{\mu}_1,\ldots,\boldsymbol{\mu}_k \in \mathbb{R}^d\)</span> corresponds to solving the first problem above, while fixing <span class="math notranslate nohighlight">\(\boldsymbol{\mu}_1,\ldots,\boldsymbol{\mu}_k \in \mathbb{R}^d\)</span> and miniminizing over partitions <span class="math notranslate nohighlight">\(C_1,\ldots,C_k\)</span> corresponds to solving the second problem.</p>
<p><strong>A useful observation: minimizing a quadratic function</strong> To elaborate on the first step above, we review an elementary fact about <a class="reference external" href="https://en.wikipedia.org/wiki/Quadratic_function">quadratic functions</a>.</p>
<p>Consider the function</p>
<div class="math notranslate nohighlight">
\[
q(x) = a x^2 + b x + c.
\]</div>
<p>When <span class="math notranslate nohighlight">\(a &gt; 0\)</span>, <span class="math notranslate nohighlight">\(q\)</span> has a unique minimum.</p>
<p><strong>LEMMA</strong> <strong>(Minimum of a Quadratic Function)</strong> Let <span class="math notranslate nohighlight">\(q(x) = a x^2 + b x + c\)</span> where <span class="math notranslate nohighlight">\(a &gt; 0\)</span> and <span class="math notranslate nohighlight">\(x \in \mathbb{R}\)</span>. The unique global minimum of <span class="math notranslate nohighlight">\(q\)</span> is attained at</p>
<div class="math notranslate nohighlight">
\[
x^* = -\frac{b}{2a}.
\]</div>
<p><span class="math notranslate nohighlight">\(\flat\)</span></p>
<p><em>Proof:</em> By the <em>First-Order Necessary Condition</em>, a global minimizer of <span class="math notranslate nohighlight">\(q\)</span> (which is necessarily a local minimizer) satisfies the condition</p>
<div class="math notranslate nohighlight">
\[
\frac{\mathrm{d}}{\mathrm{d}x} q(x) = 2 a x + b = 0,
\]</div>
<p>whose unique solution is</p>
<div class="math notranslate nohighlight">
\[
x^*= -\frac{b}{2a}.
\]</div>
<p>To see that <span class="math notranslate nohighlight">\(x^*\)</span> is indeed a global minimizer, we re-write <span class="math notranslate nohighlight">\(q\)</span> as</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
q(x) 
&amp;= a \left(x^2 + 2 \left[\frac{b}{2a}\right] x\right) + c\\
&amp;= a \left(x^2 + 2 \left[\frac{b}{2a}\right] x + \left[\frac{b}{2a}\right]^2\right) - a \left[\frac{b}{2a}\right]^2 + c\\
&amp;= a (x - x^*)^2 + \left[c - \frac{b^2}{4a}\right].
\end{align*}\]</div>
<p>Clearly, any other <span class="math notranslate nohighlight">\(x\)</span> gives a higher value for <span class="math notranslate nohighlight">\(q\)</span>. The step on the second line above is called <a class="reference external" href="https://en.wikipedia.org/wiki/Completing_the_square"><em>Completing the Square</em></a>. <span class="math notranslate nohighlight">\(\square\)</span></p>
<p><strong>NUMERICAL CORNER:</strong> Here’s a numerical example. We first define a quadratic function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">q</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">c</span>
</pre></div>
</div>
</div>
</div>
<p>We plot it for different values of the coefficients.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">q</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">x</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">q</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="n">x</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">q</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="n">x</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;y1&#39;</span><span class="p">,</span> <span class="s1">&#39;y2&#39;</span><span class="p">,</span> <span class="s1">&#39;y3&#39;</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/c9f31a3bf007f9a7956428b0544f91b920bdfa2913ffe1a371f43c086e970a6d.png" src="../../_images/c9f31a3bf007f9a7956428b0544f91b920bdfa2913ffe1a371f43c086e970a6d.png" />
</div>
</div>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
<p><strong>Sub-problem 1: finding the optimal representatives</strong> We denote by <span class="math notranslate nohighlight">\(|C_i|\)</span> the number of elements in <span class="math notranslate nohighlight">\(C_i\)</span>.</p>
<p><strong>EXAMPLE:</strong> <strong>(continued)</strong> Continuing the example above, the sizes of the clusters are respectively <span class="math notranslate nohighlight">\(|C_1| = 4, |C_2| = 3, |C_3| = 1\)</span>. Note in particulat that <span class="math notranslate nohighlight">\(|C_1| + |C_2| + |C_3| = 8 = n\)</span>, as follows from the fact that <span class="math notranslate nohighlight">\(C_1, C_2, C_3\)</span> is a partition. <span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p><strong>LEMMA</strong> <strong>(Optimal Representatives)</strong> Fix a partition <span class="math notranslate nohighlight">\(C_1,\ldots,C_k\)</span>. The optimal representatives under the objective</p>
<div class="math notranslate nohighlight">
\[
G(C_1,\ldots,C_k; \boldsymbol{\mu}_1, \ldots, \boldsymbol{\mu}_k)
= \sum_{i=1}^k \sum_{j \in C_i} \|\mathbf{x}_j - \boldsymbol{\mu}_i\|^2,
\]</div>
<p>are the centroids</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\mu}_i^* = \frac{1}{|C_i|} \sum_{j\in C_i} \mathbf{x}_j.
\]</div>
<p><span class="math notranslate nohighlight">\(\flat\)</span></p>
<p><em>Proof idea:</em> The objective <span class="math notranslate nohighlight">\(G\)</span> can be written as a sum, where each term is a quadratic function in one component of one of the <span class="math notranslate nohighlight">\(\boldsymbol{\mu}_i\)</span>’s. Each of these terms is minimized by the average of the corresponding components of the <span class="math notranslate nohighlight">\(\mathbf{x}_j\)</span>’s belonging <span class="math notranslate nohighlight">\(C_i\)</span>.</p>
<p><strong>EXAMPLE:</strong> <strong>(continued)</strong> Continuing with the previous example, we compute the optimal representatives for the fixed partition <span class="math notranslate nohighlight">\(C_1, C_2, C_3\)</span> above. We get</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\boldsymbol{\mu}_1^*
&amp;= \frac{1}{4}[\mathbf{x}_1 + \mathbf{x}_4 + \mathbf{x}_6 + \mathbf{x}_8]\\
&amp;= \frac{1}{4}\left[\begin{pmatrix}1\\0\end{pmatrix} +
\begin{pmatrix}1\\-3\end{pmatrix} +
\begin{pmatrix}2\\-2\end{pmatrix} +
\begin{pmatrix}3\\-1\end{pmatrix}
\right]
= \begin{pmatrix}7/4\\-3/2\end{pmatrix},\\
\boldsymbol{\mu}_2^*
&amp;= \frac{1}{3}[\mathbf{x}_2 + \mathbf{x}_3 + \mathbf{x}_7]\\
&amp;= \frac{1}{3}\left[\begin{pmatrix}-2\\0\end{pmatrix}+
\begin{pmatrix}-2\\1\end{pmatrix}+
\begin{pmatrix}-3\\1\end{pmatrix}
\right]
= \begin{pmatrix}-7/3\\2/3\end{pmatrix},\\
\boldsymbol{\mu}_3^*
&amp;= \frac{1}{1}[\mathbf{x}_5]
= \begin{pmatrix}-10\\10\end{pmatrix}.
\end{align*}\]</div>
<p><span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p><em>Proof:</em> <em>(Optimal Representatives)</em> Using the notation <span class="math notranslate nohighlight">\(\mathbf{x}_j = (x_{j1},\ldots,x_{jd})^T\)</span> and similarly for <span class="math notranslate nohighlight">\(\boldsymbol{\mu}_i\)</span>, note that we can expand the <span class="math notranslate nohighlight">\(k\)</span>-means objective as</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\sum_{i=1}^k \sum_{j \in C_i} \|\mathbf{x}_j - \boldsymbol{\mu}_i\|^2
&amp;= \sum_{i=1}^k \sum_{j \in C_i} \sum_{m=1}^d (x_{jm} - \mu_{im})^2\\
&amp;= \sum_{i=1}^k \sum_{m=1}^d \left[\sum_{j \in C_i} (x_{jm} - \mu_{im})^2\right].
\end{align*}\]</div>
<p>The expression in square brackets is a quadratic function in <span class="math notranslate nohighlight">\(\mu_{im}\)</span></p>
<div class="math notranslate nohighlight">
\[
q_{im}(\mu_{im})
= \left\{\sum_{j \in C_i} x_{jm}^2\right\} + \left\{- 2 \sum_{j \in C_i} x_{jm}\right\} \mu_{im}  + \left\{|C_i| \right\} \mu_{im}^2,
\]</div>
<p>and therefore, by the formula for the <em>Minimum of a Quadratic Function</em>,
is minimized at</p>
<div class="math notranslate nohighlight">
\[
\mu_{im}^* 
= - \frac{- 2 \sum_{j \in C_i} x_{jm}}{2 |C_i|}
= \frac{1}{|C_i|} \sum_{j \in C_i} x_{jm}.
\]</div>
<p>Since each term <span class="math notranslate nohighlight">\(q_{im}(\mu_{im})\)</span> in the sum over <span class="math notranslate nohighlight">\(i, m\)</span> making up the objective function <span class="math notranslate nohighlight">\(G\)</span> is strictly minimized at <span class="math notranslate nohighlight">\(\boldsymbol{\mu}_1^*,\ldots, \boldsymbol{\mu}_k^*\)</span>, so is <span class="math notranslate nohighlight">\(G\)</span>. <span class="math notranslate nohighlight">\(\square\)</span></p>
<p><strong>Sub-problem 2: finding the optimal partition</strong> Given <span class="math notranslate nohighlight">\(n\)</span> vectors <span class="math notranslate nohighlight">\(\mathbf{x}_1,\ldots,\mathbf{x}_n\)</span> in <span class="math notranslate nohighlight">\(\mathbb{R}^d\)</span> and a partition <span class="math notranslate nohighlight">\(C_1, \ldots, C_k \subseteq [n]\)</span>, it will be useful to have some notation for the corresponding cluster assignment: we define <span class="math notranslate nohighlight">\(c(j) = i\)</span> if <span class="math notranslate nohighlight">\(j \in C_i\)</span>.</p>
<p><strong>EXAMPLE:</strong> <strong>(continued)</strong> Continuing the example above, the clusters
<span class="math notranslate nohighlight">\(
C_1 = \{1, 4, 6, 8\}, C_2 = \{2, 3, 7\}, C_3 = \{5\}
\)</span>
correspond to the assignment</p>
<div class="math notranslate nohighlight">
\[
c(1) = 1, c(2) = 2, c(3) = 2, c(4) = 1, c(5) = 3, c(6) = 1, c(7) = (2), c(8) = 1. 
\]</div>
<p><span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p><strong>LEMMA</strong> <strong>(Optimal Clustering)</strong> Fix the representatives <span class="math notranslate nohighlight">\(\boldsymbol{\mu}_1,\ldots,\boldsymbol{\mu}_k\)</span>. An optimal partition under  the objective</p>
<div class="math notranslate nohighlight">
\[
G(C_1,\ldots,C_k; \boldsymbol{\mu}_1, \ldots, \boldsymbol{\mu}_k)
= \sum_{i=1}^k \sum_{j \in C_i} \|\mathbf{x}_j - \boldsymbol{\mu}_i\|^2,
\]</div>
<p>is obtained as follows. For each <span class="math notranslate nohighlight">\(j\)</span>, find the <span class="math notranslate nohighlight">\(\boldsymbol{\mu}_i\)</span> that minimizes <span class="math notranslate nohighlight">\(\|\mathbf{x}_j - \boldsymbol{\mu}_i\|\)</span> (picking one arbitrarily in the case of ties) and assign <span class="math notranslate nohighlight">\(\mathbf{x}_j\)</span> to <span class="math notranslate nohighlight">\(C_i\)</span> (i.e., add <span class="math notranslate nohighlight">\(j\)</span> to <span class="math notranslate nohighlight">\(C_i\)</span>). <span class="math notranslate nohighlight">\(\flat\)</span></p>
<p><em>Proof:</em> If <span class="math notranslate nohighlight">\(c\)</span> is the cluster assignment associated to <span class="math notranslate nohighlight">\(C_1,\ldots,C_k\)</span>, then we can re-write the objective as</p>
<div class="math notranslate nohighlight">
\[
\sum_{i=1}^k \sum_{j \in C_i} \|\mathbf{x}_j - \boldsymbol{\mu}_i\|^2
= \sum_{j=1}^n \|\mathbf{x}_j - \boldsymbol{\mu}_{c(j)}\|^2,
\]</div>
<p>By definition, when the <span class="math notranslate nohighlight">\(\boldsymbol{\mu}_i\)</span>’s are fixed, each term in the sum on the right-hand side is minimized separately by the assignment in the statement. Hence so is the sum itself. Note that we used the fact that the square root is non-decreasing to conclude that minimizing <span class="math notranslate nohighlight">\(\|\mathbf{x}_j - \boldsymbol{\mu}_i\|^2\)</span> or its square root <span class="math notranslate nohighlight">\(\|\mathbf{x}_j - \boldsymbol{\mu}_i\|\)</span> are equivalent. <span class="math notranslate nohighlight">\(\square\)</span></p>
<p><strong>EXAMPLE:</strong> <strong>(continued)</strong> Continuing the example above, suppose that we choose representatives</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\boldsymbol{\mu}_1 = \begin{pmatrix}-2\\1\end{pmatrix},
\boldsymbol{\mu}_2 = \begin{pmatrix}2\\-1\end{pmatrix},
\boldsymbol{\mu}_3 = \begin{pmatrix}-10\\10\end{pmatrix}.
\end{split}\]</div>
<p>Then we find the cluster assignment of <span class="math notranslate nohighlight">\(\mathbf{x}_1\)</span> by computing its squared distance to each representative:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\|\mathbf{x}_1 - \boldsymbol{\mu}_1\|
= \left\|\begin{pmatrix}1\\0\end{pmatrix} - \begin{pmatrix}-2\\1\end{pmatrix}\right\|
= \sqrt{(1-(-2))^2 + (0-1)^2}
= \sqrt{10},
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\|\mathbf{x}_1 - \boldsymbol{\mu}_2\|
= \left\|\begin{pmatrix}1\\0\end{pmatrix} - \begin{pmatrix}2\\-1\end{pmatrix}\right\|
= \sqrt{(1-2)^2 + (0-(-1))^2}
= \sqrt{2},
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\|\mathbf{x}_1 - \boldsymbol{\mu}_3\|
= \left\|\begin{pmatrix}1\\0\end{pmatrix} - \begin{pmatrix}-10\\10\end{pmatrix}\right\|
= \sqrt{(1-(-10))^2 + (0-10)^2}
= \sqrt{221}.
\end{split}\]</div>
<p>The minimum is achieved for <span class="math notranslate nohighlight">\(\boldsymbol{\mu}_2\)</span> so we assign <span class="math notranslate nohighlight">\(\mathbf{x}_1\)</span> to <span class="math notranslate nohighlight">\(C_2\)</span>, i.e., <span class="math notranslate nohighlight">\(1 \in C_2\)</span> and <span class="math notranslate nohighlight">\(c(1) = 2\)</span>. <span class="math notranslate nohighlight">\(\lhd\)</span></p>
</section>
<section id="the-k-means-algorithm-and-its-analysis">
<h2><span class="section-number">1.3.2. </span>The k-means algorithm and its analysis<a class="headerlink" href="#the-k-means-algorithm-and-its-analysis" title="Permalink to this headline">#</a></h2>
<p>We are now ready to describe the <a href="https://en.wikipedia.org/wiki/K-means_clustering"><span class="math notranslate nohighlight">\(k\)</span>-means algorithm</a>, also known as Lloyd’s algorithm. We start from a random assignment of clusters. (An alternative <a class="reference external" href="https://en.wikipedia.org/wiki/K-means_clustering#Initialization_methods">initialization strategy</a> is to choose <span class="math notranslate nohighlight">\(k\)</span> representatives at random among the data points.) We then alternate between the optimal choices in the lemmas. In lieu of pseudo-code, we write out the algorithm in Python.</p>
<p>The input <code class="docutils literal notranslate"><span class="pre">X</span></code> is assumed to be a collection of <span class="math notranslate nohighlight">\(n\)</span> vectors <span class="math notranslate nohighlight">\(\mathbf{x}_1, \ldots, \mathbf{x}_n \in \mathbb{R}^d\)</span> stacked into a matrix, with one row for each data point. The other input, <code class="docutils literal notranslate"><span class="pre">k</span></code>, is the desired number of clusters. There is an optional input <code class="docutils literal notranslate"><span class="pre">maxiter</span></code> for the maximum number of iterations, which is set to <span class="math notranslate nohighlight">\(10\)</span> by default.</p>
<p>We first define separate functions for the two main steps. To find the minimum of an array, we use the function <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.argmin.html"><code class="docutils literal notranslate"><span class="pre">numpy.argmin</span></code></a>. We also use <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html"><code class="docutils literal notranslate"><span class="pre">numpy.linalg.norm</span></code></a> to compute the Euclidean distance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">opt_reps</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">assign</span><span class="p">):</span>
    <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">reps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
        <span class="n">in_i</span> <span class="o">=</span> <span class="p">[</span><span class="n">j</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">if</span> <span class="n">assign</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span>             
        <span class="n">reps</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">in_i</span><span class="p">,:],</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_i</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">reps</span>

<span class="k">def</span> <span class="nf">opt_clust</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">reps</span><span class="p">):</span>
    <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="n">assign</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">dist_to_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">LA</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">j</span><span class="p">,:]</span> <span class="o">-</span> <span class="n">reps</span><span class="p">[</span><span class="n">i</span><span class="p">,:])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">)])</span>
        <span class="n">assign</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dist_to_i</span><span class="p">)</span>
        <span class="n">dist</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">dist_to_i</span><span class="p">[</span><span class="n">assign</span><span class="p">[</span><span class="n">j</span><span class="p">]]</span>
    <span class="n">G</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dist</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">assign</span>
</pre></div>
</div>
</div>
</div>
<p>The main function follows. Below, <code class="docutils literal notranslate"><span class="pre">rng.integers(0,k,n)</span></code> is an array of <code class="docutils literal notranslate"><span class="pre">n</span></code> uniformly chosen integers between <code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">k-1</span></code> (inclusive). (See <a class="reference external" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.integers.html">random.Generator.integers</a> for details.)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">kmeans</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">assign</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
    <span class="n">reps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">d</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">for</span> <span class="nb">iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">maxiter</span><span class="p">):</span>
        <span class="c1"># Step 1: Optimal representatives for fixed clusters</span>
        <span class="n">reps</span> <span class="o">=</span> <span class="n">opt_reps</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">assign</span><span class="p">)</span> 
        <span class="c1"># Step 2: Optimal clusters for fixed representatives</span>
        <span class="n">assign</span> <span class="o">=</span> <span class="n">opt_clust</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">reps</span><span class="p">)</span> 
    <span class="k">return</span> <span class="n">assign</span>
</pre></div>
</div>
</div>
</div>
<p><strong>NUMERICAL CORNER:</strong> We apply our implementation of <span class="math notranslate nohighlight">\(k\)</span>-means to the example above. We fix <code class="docutils literal notranslate"><span class="pre">k</span></code> to <span class="math notranslate nohighlight">\(3\)</span>. Here the data matrix <code class="docutils literal notranslate"><span class="pre">X</span></code> is the following:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],[</span><span class="o">-</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],[</span><span class="o">-</span><span class="mf">2.</span><span class="p">,</span><span class="mf">1.</span><span class="p">],[</span><span class="mf">1.</span><span class="p">,</span><span class="o">-</span><span class="mf">3.</span><span class="p">],[</span><span class="o">-</span><span class="mf">10.</span><span class="p">,</span><span class="mf">10.</span><span class="p">],[</span><span class="mf">2.</span><span class="p">,</span><span class="o">-</span><span class="mf">2.</span><span class="p">],[</span><span class="o">-</span><span class="mf">3.</span><span class="p">,</span><span class="mf">1.</span><span class="p">],[</span><span class="mf">3.</span><span class="p">,</span><span class="o">-</span><span class="mf">1.</span><span class="p">]])</span>
<span class="n">assign</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>162.7
74.8611111111111
9.083333333333334
9.083333333333334
9.083333333333334
9.083333333333334
9.083333333333334
9.083333333333334
9.083333333333334
9.083333333333334
</pre></div>
</div>
</div>
</div>
<p>We vizualize the output by coloring the points according to their cluster assignment.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">assign</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/94d3751b2fd916d3f1160f34789334d34e9781f9c68819a5e01bb5a7d3fed29b.png" src="../../_images/94d3751b2fd916d3f1160f34789334d34e9781f9c68819a5e01bb5a7d3fed29b.png" />
</div>
</div>
<p>We can compute the final representatives (optimal for the final assignment) by using the subroutine <code class="docutils literal notranslate"><span class="pre">opt_reps</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">opt_reps</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">assign</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ -2.33333333   0.66666667]
 [  1.75        -1.5       ]
 [-10.          10.        ]]
</pre></div>
</div>
</div>
</div>
<p>Each row is the center of the corresponding cluster. Note these match with the ones we previously computed. Indeed, the clustering is the same (although not necessarily in the same order).</p>
<p><span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p>The <span class="math notranslate nohighlight">\(k\)</span>-means algorithm is only a heuristic. In particular, it is not guaranteed to find the global minimum of the <span class="math notranslate nohighlight">\(k\)</span>-means objective. However, it is guaranteed to improve the objective at every iteration, or more precisely, not to make it worse.</p>
<p><strong>THEOREM</strong> <strong>(Convergence of <span class="math notranslate nohighlight">\(k\)</span>-means cost)</strong> The sequence of objective function values produced by the <span class="math notranslate nohighlight">\(k\)</span>-means algorithm is non-increasing. <span class="math notranslate nohighlight">\(\sharp\)</span></p>
<p><em>Proof idea:</em> By the <em>Optimal Representatives</em> and <em>Optimal Clustering</em> lemmas, each step does not increase the objective.</p>
<p><em>Proof:</em> Let <span class="math notranslate nohighlight">\(C_1',\ldots,C_k'\)</span> be the current clusters, with representatives <span class="math notranslate nohighlight">\(\boldsymbol{\mu}_1',\ldots,\boldsymbol{\mu}_k'\)</span>. After Step 1, the new representatives are <span class="math notranslate nohighlight">\(\boldsymbol{\mu}_1'',\ldots,\boldsymbol{\mu}_k''\)</span>. By the <em>Optimal Representatives Lemma</em>, they satisfy</p>
<div class="math notranslate nohighlight">
\[
\sum_{i=1}^k \sum_{j \in C_i'} \|\mathbf{x}_j - \boldsymbol{\mu}_i''\|^2
\leq \sum_{i=1}^k \sum_{j \in C_i'} \|\mathbf{x}_j - \boldsymbol{\mu}_i'\|^2.
\]</div>
<p>After Step 2, the new clusters are <span class="math notranslate nohighlight">\(C_1'',\ldots,C_k''\)</span>. By the <em>Optimal Clustering Lemma</em>, they satisfy</p>
<div class="math notranslate nohighlight">
\[
\sum_{i=1}^k \sum_{j \in C_i''} \|\mathbf{x}_j - \boldsymbol{\mu}_i''\|^2
\leq \sum_{i=1}^k \sum_{j \in C_i'} \|\mathbf{x}_j - \boldsymbol{\mu}_i''\|^2.
\]</div>
<p>Combining these two inequalities gives</p>
<div class="math notranslate nohighlight">
\[
\sum_{i=1}^k \sum_{j \in C_i''} \|\mathbf{x}_j - \boldsymbol{\mu}_i''\|^2
\leq \sum_{i=1}^k \sum_{j \in C_i'} \|\mathbf{x}_j - \boldsymbol{\mu}_i'\|^2,
\]</div>
<p>as claimed. <span class="math notranslate nohighlight">\(\square\)</span></p>
<p>The sequence of objective values is monotone and bounded from below by <span class="math notranslate nohighlight">\(0\)</span>. <a class="reference external" href="https://en.wikipedia.org/wiki/Monotone_convergence_theorem#Convergence_of_a_monotone_sequence_of_real_numbers">Hence it converges</a>. Note that the limit depends on the starting point.</p>
</section>
<section id="penguins-dataset">
<h2><span class="section-number">1.3.3. </span>Penguins dataset<a class="headerlink" href="#penguins-dataset" title="Permalink to this headline">#</a></h2>
<p>We will test our implementation of <span class="math notranslate nohighlight">\(k\)</span>-means on the penguins dataset introduced earlier in the chapter.</p>
<p>We first extract the columns and combine them into a data matrix <code class="docutils literal notranslate"><span class="pre">X</span></code>. As we did previously, we also remove the rows with missing values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># USE PATH TO penguins-measurements.csv</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../../utils/data/penguins-measurements.csv&#39;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;bill_length_mm&#39;</span><span class="p">,</span> <span class="s1">&#39;bill_depth_mm&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;flipper_length_mm&#39;</span><span class="p">,</span> <span class="s1">&#39;body_mass_g&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We  visualize a two-dimensional slice of the data.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">3</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;bill_depth_mm&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;body_mass_g&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/c6cff5a8ac0075f25123e250437b3b45ec2d9a8130f77b452433bf03f79724fa.png" src="../../_images/c6cff5a8ac0075f25123e250437b3b45ec2d9a8130f77b452433bf03f79724fa.png" />
</div>
</div>
<p>Observe that the features have quite different scales (tens versus thousands in the plot above). In such a case, it is common to standardize the data so that each feature has roughly the same scale. That is accomplished by, for each column of <code class="docutils literal notranslate"><span class="pre">X</span></code>, subtracting its empirical mean and dividing by its empirical standard deviation. We do this next.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Compute mean for each column</span>
<span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Compute standard deviation for each column</span>
<span class="n">X</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span> <span class="c1"># Standardize each column</span>
</pre></div>
</div>
</div>
</div>
<p>Now we run the <span class="math notranslate nohighlight">\(k\)</span>-means algorithm with <span class="math notranslate nohighlight">\(k=2\)</span> clusters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">assign</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1338.2046936914157
820.9361062178352
603.8787658966849
575.2587351391593
567.7837494880662
565.7076453796291
565.7076453796291
565.7076453796291
565.7076453796291
565.7076453796291
</pre></div>
</div>
</div>
</div>
<p>We vizualize the output as we did before.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">3</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">assign</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;bill_depth_mm (standardized)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;body_mass_g (standardized)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/f243dd6e44ff8e1615a117d283831c8aa1500fc36756749acc5e304c8627efbd.png" src="../../_images/f243dd6e44ff8e1615a117d283831c8aa1500fc36756749acc5e304c8627efbd.png" />
</div>
</div>
<p>This clustering looks quite good. Nevertheless recall that:</p>
<ol class="arabic simple">
<li><p>in this plot we are looking at only two of the four variables while <span class="math notranslate nohighlight">\(k\)</span>-means uses all of them,</p></li>
<li><p>we are not guaranteed to find the best solution,</p></li>
<li><p>our objective function is somewhat arbitrary, and</p></li>
<li><p>it is not clear what the right choice of <span class="math notranslate nohighlight">\(k\)</span> is.</p></li>
</ol>
<p>In fact, the original dataset provided the correct answer. Despite what the figure above may lead us to believe, there are in reality three separate species. So let’s try with <span class="math notranslate nohighlight">\(k=3\)</span> clusters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">assign</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1312.344945158482
577.1700837839458
428.50397345437966
392.2616692426171
383.3452894259011
380.76115947528945
379.50930154236835
379.3925027555175
379.3925027555175
379.3925027555175
</pre></div>
</div>
</div>
</div>
<p>The output does not seem quite right.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">3</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">assign</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;bill_depth_mm (standardized)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;body_mass_g (standardized)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/5a480d1958ee9237a0dc9b93c800ac029b8d7e613e349ce92bdb7151e89f2a12.png" src="../../_images/5a480d1958ee9237a0dc9b93c800ac029b8d7e613e349ce92bdb7151e89f2a12.png" />
</div>
</div>
<p>But, remembering the warnings mentioned previously, let’s look at a different two-dimensional slice.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">3</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">assign</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;bill_length_mm (standardized)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;body_mass_g (standardized)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/35d8fa0c262f3ea2f0302d7e41ee396ac8ff4b15ef21536eab78a055e8b92114.png" src="../../_images/35d8fa0c262f3ea2f0302d7e41ee396ac8ff4b15ef21536eab78a055e8b92114.png" />
</div>
</div>
<p>Let’s load up the truth and compare. We only keep those samples that were not removed because of missing values (see <a class="reference external" href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html"><code class="docutils literal notranslate"><span class="pre">pandas.DataFrame.iloc</span></code></a>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># USE PATH TO penguins-species.csv</span>
<span class="n">df_truth</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../../utils/data/penguins-species.csv&#39;</span><span class="p">)</span> 
<span class="n">df_truth</span> <span class="o">=</span> <span class="n">df_truth</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
<span class="n">df_truth</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>species</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Adelie</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Adelie</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Adelie</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Adelie</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Adelie</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The species are:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">species</span> <span class="o">=</span> <span class="n">df_truth</span><span class="p">[</span><span class="s1">&#39;species&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">species</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;Adelie&#39; &#39;Chinstrap&#39; &#39;Gentoo&#39;]
</pre></div>
</div>
</div>
</div>
<p>To plot the outcome, we color the species blue-green-red using a <a class="reference external" href="https://docs.python.org/3/tutorial/datastructures.html#dictionaries">dictionary</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">species2color</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Adelie&#39;</span><span class="p">:</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;Chinstrap&#39;</span><span class="p">:</span> <span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="s1">&#39;Gentoo&#39;</span><span class="p">:</span> <span class="s1">&#39;r&#39;</span><span class="p">}</span>
<span class="n">truth</span> <span class="o">=</span> <span class="n">species</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">species2color</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, we can compare the output to the truth. The match is quite excellent – but not perfect.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">3</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">truth</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;truth&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">3</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">assign</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;kmeans&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/27678916e193fe9a3430b6b3e3248532c164dcbeb1ec1585051b5af9b881d80e.png" src="../../_images/27678916e193fe9a3430b6b3e3248532c164dcbeb1ec1585051b5af9b881d80e.png" />
</div>
</div>
<p>Determining the appropriate number of clusters is not a straighforward problem. To quote <a class="reference external" href="https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set">Wikipedia</a>:</p>
<blockquote>
<div><p>The correct choice of <span class="math notranslate nohighlight">\(k\)</span> is often ambiguous, with interpretations depending on the shape and scale of the distribution of points in a data set and the desired clustering resolution of the user. In addition, increasing <span class="math notranslate nohighlight">\(k\)</span> without penalty will always reduce the amount of error in the resulting clustering, to the extreme case of zero error if each data point is considered its own cluster (i.e., when <span class="math notranslate nohighlight">\(k\)</span> equals the number of data points, <span class="math notranslate nohighlight">\(n\)</span>). Intuitively then, the optimal choice of <span class="math notranslate nohighlight">\(k\)</span> will strike a balance between maximum compression of the data using a single cluster, and maximum accuracy by assigning each data point to its own cluster. If an appropriate value of <span class="math notranslate nohighlight">\(k\)</span> is not apparent from prior knowledge of the properties of the data set, it must be chosen somehow. There are several categories of methods for making this decision.</p>
</div></blockquote>
<p>In practice, <a class="reference external" href="https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set">several heuristics</a> are in use. Other approaches to clustering, e.g. <a class="reference external" href="https://en.wikipedia.org/wiki/DBSCAN">DBSCAN</a> and <a class="reference external" href="https://en.wikipedia.org/wiki/Hierarchical_clustering">hierarchical clustering</a>, do not require a number of clusters as input.</p>
<p><strong>TRY IT!</strong> Run the analysis again, but this time <em>without the standardization step</em>. What do you observe? Is one feature more influential than the others on the final output? Why do you think that is?</p>
<p><span class="math notranslate nohighlight">\(\unlhd\)</span></p>
</section>
<section id="matrix-form-of-k-means-clustering">
<h2><span class="section-number">1.3.4. </span>Matrix form of k-means clustering<a class="headerlink" href="#matrix-form-of-k-means-clustering" title="Permalink to this headline">#</a></h2>
<p>In this section, we show that the <span class="math notranslate nohighlight">\(k\)</span>-means clustering objective can be written in matrix form. We start with some notation and definitions that will be useful throughout the course.</p>
<p>As we indicated before, for a collection of <span class="math notranslate nohighlight">\(n\)</span> data vectors <span class="math notranslate nohighlight">\(\mathbf{x}_1, \ldots, \mathbf{x}_n\)</span> in <span class="math notranslate nohighlight">\(\mathbb{R}^d\)</span>, it is often convenient to stack them up into a matrix</p>
<div class="math notranslate nohighlight">
\[\begin{split}
X =
\begin{bmatrix}
\mathbf{x}_1^T \\
\mathbf{x}_2^T \\
\vdots \\
\mathbf{x}_n^T \\
\end{bmatrix}
=
\begin{bmatrix}
x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1d} \\
x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2d} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{nd} \\
\end{bmatrix}.
\end{split}\]</div>
<p>We can do the same with cluster representatives. Given <span class="math notranslate nohighlight">\(\boldsymbol{\mu}_1,\ldots,\boldsymbol{\mu}_k\)</span> also in <span class="math notranslate nohighlight">\(\mathbb{R}^d\)</span>, we form the matrix</p>
<div class="math notranslate nohighlight">
\[\begin{split}
U =
\begin{bmatrix}
\boldsymbol{\mu}_1^T \\
\boldsymbol{\mu}_2^T \\
\vdots \\
\boldsymbol{\mu}_k^T \\
\end{bmatrix}
=
\begin{bmatrix}
\mu_{11} &amp; \mu_{12} &amp; \cdots &amp; \mu_{1d} \\
\mu_{21} &amp; \mu_{22} &amp; \cdots &amp; \mu_{2d} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\mu_{k1} &amp; \mu_{k2} &amp; \cdots &amp; \mu_{kd} \\
\end{bmatrix}.
\end{split}\]</div>
<p>Perhaps less obviously, cluster assignments can also be encoded in matrix form. Recall that, given a partition <span class="math notranslate nohighlight">\(C_1,\ldots,C_k\)</span> of <span class="math notranslate nohighlight">\([n]\)</span>, we define <span class="math notranslate nohighlight">\(c(j) = i\)</span> if <span class="math notranslate nohighlight">\(j \in C_i\)</span>. For <span class="math notranslate nohighlight">\(j=1,\ldots,n\)</span> and <span class="math notranslate nohighlight">\(\ell=1,\ldots,k\)</span>, set <span class="math notranslate nohighlight">\(Z_{j\ell} = 1\)</span> if <span class="math notranslate nohighlight">\(c(j) = \ell\)</span> and <span class="math notranslate nohighlight">\(0\)</span> otherwise, and let <span class="math notranslate nohighlight">\(Z\)</span> be the <span class="math notranslate nohighlight">\(n \times k\)</span> matrix with entries <span class="math notranslate nohighlight">\(Z = [Z_{j\ell}]_{j,\ell}\)</span>. That is, row <span class="math notranslate nohighlight">\(j\)</span> has exactly one entry with value <span class="math notranslate nohighlight">\(1\)</span>, corresponding to the assigned cluster <span class="math notranslate nohighlight">\(c(j)\)</span> of data point <span class="math notranslate nohighlight">\(\mathbf{x}_j\)</span>, and all other entries <span class="math notranslate nohighlight">\(0\)</span>.</p>
<p>With this notation, the representative of the cluster assigned to data point <span class="math notranslate nohighlight">\(\mathbf{x}_j\)</span> is obtained through a matrix product</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\mu}_{c(j)}^T 
= \sum_{\ell = 1}^k Z_{j\ell} \boldsymbol{\mu}_{\ell}^T
= \sum_{\ell = 1}^k Z_{j\ell} U_{\ell,\cdot}
= \left(Z U\right)_{j,\cdot}
\]</div>
<p>where we used that the <span class="math notranslate nohighlight">\(j\)</span>-th row of a matrix product is a linear combination of the rows of the second matrix, where the coefficients are the entries on the <span class="math notranslate nohighlight">\(j\)</span>-th row of the first one.</p>
<p><strong>EXAMPLE:</strong> <strong>(continued)</strong> Continuing with our previous example, the clusters
<span class="math notranslate nohighlight">\(
C_1 = \{1, 4, 6, 8\}, C_2 = \{2, 3, 7\}, C_3 = \{5\}
\)</span>
are encoded as the matrix</p>
<div class="math notranslate nohighlight">
\[\begin{split}
Z 
= \begin{bmatrix}
1 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0\\
0 &amp; 1 &amp; 0\\
1 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 1\\
1 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0\\
1 &amp; 0 &amp; 0
\end{bmatrix}.
\end{split}\]</div>
<p>Suppose again that the representatives are</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\boldsymbol{\mu}_1 = \begin{pmatrix}-2\\1\end{pmatrix},
\boldsymbol{\mu}_2 = \begin{pmatrix}2\\-1\end{pmatrix},
\boldsymbol{\mu}_3 = \begin{pmatrix}-10\\10\end{pmatrix}.
\end{split}\]</div>
<p>The corresponding matrix <span class="math notranslate nohighlight">\(U\)</span> is then</p>
<div class="math notranslate nohighlight">
\[\begin{split}
U 
= 
\begin{bmatrix}
-2 &amp; 1\\
2 &amp; -1\\
-10 &amp; 10
\end{bmatrix}.
\end{split}\]</div>
<p>Hence multiplying <span class="math notranslate nohighlight">\(Z\)</span> and <span class="math notranslate nohighlight">\(U\)</span> produces a matrix where each row is the representative of the assigned cluster of the corresponding data point</p>
<div class="math notranslate nohighlight">
\[\begin{split}
ZU 
= 
\begin{bmatrix}
1 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0\\
0 &amp; 1 &amp; 0\\
1 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 1\\
1 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0\\
1 &amp; 0 &amp; 0
\end{bmatrix}
\,
\begin{bmatrix}
-2 &amp; 1\\
2 &amp; -1\\
-10 &amp; 10
\end{bmatrix}
= 
\begin{bmatrix}
-2 &amp; 1\\
2 &amp; -1\\
2 &amp; -1\\
-2 &amp; 1\\
-10 &amp; 10\\
-2 &amp; 1\\
2 &amp; -1\\
-2 &amp; 1
\end{bmatrix}.
\end{split}\]</div>
<p><span class="math notranslate nohighlight">\(\lhd\)</span></p>
<p>Recall that the Frobenius norm of an <span class="math notranslate nohighlight">\(n \times m\)</span> matrix <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{n \times m}\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[
\|A\|_F
= \sqrt{\sum_{i=1}^n \sum_{j=1}^m A_{ij}^2}.
\]</div>
<p>Using the row notation, it can be written as the sum of the squared Euclidean norms of the rows</p>
<div class="math notranslate nohighlight">
\[
\|A\|_F^2 = \sum_{i=1}^n \|A_{i,\cdot}\|_2^2.
\]</div>
<p>For two matrices <span class="math notranslate nohighlight">\(A, B \in \mathbb{R}^{n \times m}\)</span>, the Frobenius norm of their difference <span class="math notranslate nohighlight">\(\|A - B\|_F\)</span> can be interpreted as a distance between <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>, that is, a measure of how dissimilar they are.</p>
<p>Finally, we return to the <span class="math notranslate nohighlight">\(k\)</span>-means objective. Using the notation introduced in this section and the equivalent formula for the objective <span class="math notranslate nohighlight">\(G\)</span> derived the proof of the <em>Optimal Clustering Lemma</em>, we note that</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
G(C_1,\ldots,C_k; \boldsymbol{\mu}_1, \ldots, \boldsymbol{\mu}_k)
&amp;= \sum_{i=1}^n \|\mathbf{x}_i - \boldsymbol{\mu}_{c(i)}\|^2\\
&amp;= \sum_{i=1}^n \sum_{\ell=1}^d \left(x_{i\ell} - (Z U)_{i\ell}\right)^2\\
&amp;= \|X - Z U \|^2_F,
\end{align*}\]</div>
<p>where we used the definition of the Frobenius norm.</p>
<p>In other words, minimizing the <span class="math notranslate nohighlight">\(k\)</span>-means objective is equivalent to finding a matrix factorization of the form <span class="math notranslate nohighlight">\(ZU\)</span> that is a good fit to the data matrix <span class="math notranslate nohighlight">\(X\)</span> in Frobenius norm. This formulation expresses in a more compact form the idea of representing <span class="math notranslate nohighlight">\(X\)</span> as a combination of a small number of representatives. Matrix factorization will come back repeatedly in this course.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chap01_intro/03_clustering"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../02_review/roch-mmids-intro-2review.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">1.2. </span>Background: review of basic linear algebra, calculus, and probability</p>
      </div>
    </a>
    <a class="right-next"
       href="../04_highdim/roch-mmids-intro-4highdim.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">1.4. </span>Some observations about high-dimensional data</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-k-means-objective">1.3.1. The k-means objective</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-k-means-algorithm-and-its-analysis">1.3.2. The k-means algorithm and its analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#penguins-dataset">1.3.3. Penguins dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#matrix-form-of-k-means-clustering">1.3.4. Matrix form of k-means clustering</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Sebastien Roch
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>