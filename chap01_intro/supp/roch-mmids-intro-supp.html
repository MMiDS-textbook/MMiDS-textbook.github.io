
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>1.6. Online supplementary material &#8212; MMiDS Textbook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-P5E8DW088F"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-P5E8DW088F');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-P5E8DW088F');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chap01_intro/supp/roch-mmids-intro-supp';</script>
    <link rel="canonical" href="https://mmids-textbook.github.io/chap01_intro/supp/roch-mmids-intro-supp.html" />
    <link rel="icon" href="https://mmids-textbook.github.io/favicon-32x32.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="2. Least squares: geometric, algebraic, and numerical aspects" href="../../chap02_ls/00_intro/roch-mmids-ls-intro.html" />
    <link rel="prev" title="1.5. Exercises" href="../exercises/roch-mmids-intro-exercises.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/mmids-cover-small.jpg" class="logo__image only-light" alt="MMiDS Textbook - Home"/>
    <script>document.write(`<img src="../../_static/mmids-cover-small.jpg" class="logo__image only-dark" alt="MMiDS Textbook - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    <b>MATHEMATICAL METHODS in DATA SCIENCE (with Python)</b>
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../00_intro/roch-mmids-intro-intro.html">1. Introduction: a first data science problem</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../01_motiv/roch-mmids-intro-motiv.html">1.1. Motivating example: identifying penguin species</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02_review/roch-mmids-intro-review.html">1.2. Background: quick refresher of matrix algebra, differential calculus, and elementary probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03_clustering/roch-mmids-intro-clustering.html">1.3. Clustering: an objective, an algorithm and a guarantee</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04_highdim/roch-mmids-intro-highdim.html">1.4. Some observations about high-dimensional data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/roch-mmids-intro-exercises.html">1.5. Exercises</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">1.6. Online supplementary material</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../chap02_ls/00_intro/roch-mmids-ls-intro.html">2. Least squares: geometric, algebraic, and numerical aspects</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/01_motiv/roch-mmids-ls-motiv.html">2.1. Motivating example: predicting sales</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/02_spaces/roch-mmids-ls-spaces.html">2.2. Background: review of vector spaces and matrix inverses</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/03_orthog/roch-mmids-ls-orthog.html">2.3. Geometry of least squares: the orthogonal projection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/04_qr/roch-mmids-ls-qr.html">2.4. QR decomposition and Householder transformations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/05_regression/roch-mmids-ls-regression.html">2.5. Application: regression analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/exercises/roch-mmids-ls-exercises.html">2.6. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap02_ls/supp/roch-mmids-ls-supp.html">2.7. Online supplementary material</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../chap03_opt/00_intro/roch-mmids-opt-intro.html">3. Optimization theory and algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/01_motiv/roch-mmids-opt-motiv.html">3.1. Motivating example:  analyzing customer satisfaction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/02_several/roch-mmids-opt-several.html">3.2. Background: review of differentiable functions of several variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/03_optimality/roch-mmids-opt-optimality.html">3.3. Optimality conditions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/04_convexity/roch-mmids-opt-convexity.html">3.4. Convexity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/05_gd/roch-mmids-opt-gd.html">3.5. Gradient descent and its convergence analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/06_logistic/roch-mmids-opt-logistic.html">3.6. Application: logistic regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/exercises/roch-mmids-opt-exercises.html">3.7. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap03_opt/supp/roch-mmids-opt-supp.html">3.8. Online supplementary material</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../chap04_svd/00_intro/roch-mmids-svd-intro.html">4. Singular value decomposition</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/01_motiv/roch-mmids-svd-motiv.html">4.1. Motivating example: visualizing viral evolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/02_spectral/roch-mmids-svd-spectral.html">4.2. Background: review of matrix rank  and spectral decomposition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/03_svd/roch-mmids-svd-svd.html">4.3. Approximating subspaces and the SVD</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/04_power/roch-mmids-svd-power.html">4.4. Power iteration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/05_pca/roch-mmids-svd-pca.html">4.5. Application: principal components analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/06_further/roch-mmids-svd-further.html">4.6. Further applications of the SVD: low-rank approximations and ridge regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/exercises/roch-mmids-svd-exercises.html">4.7. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap04_svd/supp/roch-mmids-svd-supp.html">4.8. Online supplementary material</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../chap05_specgraph/00_intro/roch-mmids-specgraph-intro.html">5. Spectral graph theory</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chap05_specgraph/01_motiv/roch-mmids-specgraph-motiv.html">5.1. Motivating example: uncovering social groups</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap05_specgraph/02_graph/roch-mmids-specgraph-graph.html">5.2. Background: basic concepts in graph theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap05_specgraph/03_extremal/roch-mmids-specgraph-extremal.html">5.3. Variational characterization of eigenvalues</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap05_specgraph/04_laplacian/roch-mmids-specgraph-laplacian.html">5.4. Spectral properties of the Laplacian matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap05_specgraph/05_partitioning/roch-mmids-specgraph-partitioning.html">5.5. Application: graph partitioning via spectral clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap05_specgraph/06_sbm/roch-mmids-specgraph-sbm.html">5.6. Erdős-Rényi random graph and stochastic blockmodel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap05_specgraph/exercises/roch-mmids-specgraph-exercises.html">5.7. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap05_specgraph/supp/roch-mmids-specgraph-supp.html">5.8. Online supplementary material</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../chap06_prob/00_intro/roch-mmids-prob-intro.html">6. Probabilistic models: from simple to complex</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chap06_prob/01_motiv/roch-mmids-prob-motiv.html">6.1. Motivating example: tracking location</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap06_prob/02_parametric/roch-mmids-prob-parametric.html">6.2. Background: introduction to parametric families and maximum likelihood estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap06_prob/03_joint/roch-mmids-prob-joint.html">6.3. Modeling more complex dependencies 1: using conditional independence</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap06_prob/04_em/roch-mmids-prob-em.html">6.4. Modeling more complex dependencies 2: marginalizing out an unobserved variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap06_prob/05_kalman/roch-mmids-prob-kalman.html">6.5. Application: linear-Gaussian models and Kalman filtering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap06_prob/exercises/roch-mmids-prob-exercises.html">6.6. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap06_prob/supp/roch-mmids-prob-supp.html">6.7. Online supplementary material</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../chap07_rwmc/00_intro/roch-mmids-rwmc-intro.html">7. Random walks on graphs and Markov chains</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/01_motiv/roch-mmids-rwmc-motiv.html">7.1. Motivating example: discovering mathematical topics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/02_mcdefs/roch-mmids-rwmc-mcdefs.html">7.2. Background: elements of finite Markov chains</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/03_stat/roch-mmids-rwmc-stat.html">7.3. Limit behavior 1: stationary distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/04_mclimit/roch-mmids-rwmc-mclimit.html">7.4. Limit behavior 2: convergence to equilibrium</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/05_pagerank/roch-mmids-rwmc-pagerank.html">7.5. Application: random walks on graphs and PageRank</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/06_gibbs/roch-mmids-rwmc-gibbs.html">7.6. Further applications: Gibbs sampling and generating images</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/exercises/roch-mmids-rwmc-exercises.html">7.7. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap07_rwmc/supp/roch-mmids-rwmc-supp.html">7.8. Online supplementary material</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../chap08_nn/00_intro/roch-mmids-nn-intro.html">8. Neural networks, backpropagation and stochastic gradient descent</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../chap08_nn/01_motiv/roch-mmids-nn-motiv.html">8.1. Motivating example:  classifying natural images</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap08_nn/02_chain/roch-mmids-nn-chain.html">8.2. Background: Jacobian, chain rule, and a brief introduction to automatic differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap08_nn/03_backprop/roch-mmids-nn-backprop.html">8.3. Building blocks of AI 1: backpropagation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap08_nn/04_sgd/roch-mmids-nn-sgd.html">8.4. Building blocks of AI 2: stochastic gradient descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap08_nn/05_nn/roch-mmids-nn-nn.html">8.5. Building blocks of AI 3: neural networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap08_nn/exercises/roch-mmids-nn-exercises.html">8.6. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../chap08_nn/supp/roch-mmids-nn-supp.html">8.7. Online supplementary material</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/MMiDS-textbook/MMiDS-textbook.github.io" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/issues/new?title=Issue%20on%20page%20%2Fchap01_intro/supp/roch-mmids-intro-supp.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/chap01_intro/supp/roch-mmids-intro-supp.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Online supplementary material</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quizzes-solutions-code-etc">1.6.1. Quizzes, solutions, code, etc.</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#just-the-code">1.6.1.1. Just the code</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#self-assessment-quizzes">1.6.1.2. Self-assessment quizzes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#auto-quizzes">1.6.1.3. Auto-quizzes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#solutions-to-odd-numbered-warm-up-exercises">1.6.1.4. Solutions to odd-numbered warm-up exercises</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-outcomes">1.6.1.5. Learning outcomes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-sections">1.6.2. Additional sections</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-more-rigorous-analysis-of-clustering-in-high-dimension">1.6.2.1. A more rigorous analysis of clustering in high dimension</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p><span class="math notranslate nohighlight">\(\newcommand{\bmu}{\boldsymbol{\mu}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bSigma}{\boldsymbol{\Sigma}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bfbeta}{\boldsymbol{\beta}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bflambda}{\boldsymbol{\lambda}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bgamma}{\boldsymbol{\gamma}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bsigma}{{\boldsymbol{\sigma}}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bpi}{\boldsymbol{\pi}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\btheta}{{\boldsymbol{\theta}}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bphi}{\boldsymbol{\phi}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\balpha}{\boldsymbol{\alpha}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\blambda}{\boldsymbol{\lambda}}\)</span>
<span class="math notranslate nohighlight">\(\renewcommand{\P}{\mathbb{P}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\E}{\mathbb{E}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\indep}{\perp\!\!\!\perp} \newcommand{\bx}{\mathbf{x}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bp}{\mathbf{p}}\)</span>
<span class="math notranslate nohighlight">\(\renewcommand{\bx}{\mathbf{x}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bX}{\mathbf{X}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\by}{\mathbf{y}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bY}{\mathbf{Y}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bz}{\mathbf{z}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bZ}{\mathbf{Z}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bw}{\mathbf{w}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bW}{\mathbf{W}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bv}{\mathbf{v}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bV}{\mathbf{V}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bfg}{\mathbf{g}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bfh}{\mathbf{h}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\horz}{\rule[.5ex]{2.5ex}{0.5pt}}\)</span>
<span class="math notranslate nohighlight">\(\renewcommand{\S}{\mathcal{S}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\X}{\mathcal{X}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\var}{\mathrm{Var}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\pa}{\mathrm{pa}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\Z}{\mathcal{Z}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bh}{\mathbf{h}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bb}{\mathbf{b}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bc}{\mathbf{c}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\cE}{\mathcal{E}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\cP}{\mathcal{P}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bbeta}{\boldsymbol{\beta}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bLambda}{\boldsymbol{\Lambda}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\cov}{\mathrm{Cov}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\bfk}{\mathbf{k}}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\idx}[1]{}\)</span>
<span class="math notranslate nohighlight">\(\newcommand{\xdi}{}\)</span></p>
<section id="online-supplementary-material">
<h1><span class="section-number">1.6. </span>Online supplementary material<a class="headerlink" href="#online-supplementary-material" title="Link to this heading">#</a></h1>
<section id="quizzes-solutions-code-etc">
<h2><span class="section-number">1.6.1. </span>Quizzes, solutions, code, etc.<a class="headerlink" href="#quizzes-solutions-code-etc" title="Link to this heading">#</a></h2>
<section id="just-the-code">
<h3><span class="section-number">1.6.1.1. </span>Just the code<a class="headerlink" href="#just-the-code" title="Link to this heading">#</a></h3>
<p>An interactive Jupyter notebook featuring the code in this chapter can be accessed below (Google Colab recommended). You are encouraged to tinker with it. Some suggested computational exercises are scattered throughout. The notebook is also available as a slideshow.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_intro_notebook.ipynb">Notebook</a> (<a class="reference external" href="https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/just_the_code/roch_mmids_chap_intro_notebook.ipynb">Open In Colab</a>)</p></li>
<li><p><a class="reference external" href="https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/just_the_code/roch_mmids_chap_intro_notebook_slides.slides.html">Slideshow</a></p></li>
</ul>
</section>
<section id="self-assessment-quizzes">
<h3><span class="section-number">1.6.1.2. </span>Self-assessment quizzes<a class="headerlink" href="#self-assessment-quizzes" title="Link to this heading">#</a></h3>
<p>A more extensive web version of the self-assessment quizzes is available by following the links below.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_1_2.html">Section 1.2</a></p></li>
<li><p><a class="reference external" href="https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_1_3.html">Section 1.3</a></p></li>
<li><p><a class="reference external" href="https://raw.githack.com/MMiDS-textbook/MMiDS-textbook.github.io/main/quizzes/self-assessment/quiz_1_4.html">Section 1.4</a></p></li>
</ul>
</section>
<section id="auto-quizzes">
<h3><span class="section-number">1.6.1.3. </span>Auto-quizzes<a class="headerlink" href="#auto-quizzes" title="Link to this heading">#</a></h3>
<p>Automatically generated quizzes for this chapter can be accessed here (Google Colab recommended).</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-intro-autoquiz.ipynb">Auto-quizzes</a>
(<a class="reference external" href="https://colab.research.google.com/github/MMiDS-textbook/MMiDS-textbook.github.io/blob/main/quizzes/auto_quizzes/roch-mmids-intro-autoquiz.ipynb">Open In Colab</a>)</p></li>
</ul>
</section>
<section id="solutions-to-odd-numbered-warm-up-exercises">
<h3><span class="section-number">1.6.1.4. </span>Solutions to odd-numbered warm-up exercises<a class="headerlink" href="#solutions-to-odd-numbered-warm-up-exercises" title="Link to this heading">#</a></h3>
<p><em>(with help from Claude, Gemini, and ChatGPT)</em></p>
<p>Answer and justification for E1.2.1: The Euclidean norm <span class="math notranslate nohighlight">\(\|\mathbf{x}\|_2\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
\|\mathbf{x}\|_2 = \sqrt{x_1^2 + x_2^2} = \sqrt{6^2 + 8^2} = \sqrt{36 + 64} = \sqrt{100} = 10.
\]</div>
<p>Answer and justification for E1.2.3: The transpose <span class="math notranslate nohighlight">\(A^T\)</span> is obtained by switching rows and columns</p>
<div class="math notranslate nohighlight">
\[\begin{split}
A^T = \begin{pmatrix}1 &amp; 4 \\ 2 &amp; 5 \\ 3 &amp; 6\end{pmatrix}
\end{split}\]</div>
<p>Answer and justification for E1.2.5: A matrix <span class="math notranslate nohighlight">\(A\)</span> is symmetric if <span class="math notranslate nohighlight">\(A = A^T\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
A^T = \begin{pmatrix}2 &amp; 0 \\ 0 &amp; 3\end{pmatrix} = A.
\end{split}\]</div>
<p>Thus, <span class="math notranslate nohighlight">\(A\)</span> is symmetric.</p>
<p>Answer and justification for E1.2.7: <span class="math notranslate nohighlight">\(\frac{\partial f}{\partial x} = \lim_{h \to 0} \frac{f(x+h, y) - f(x, y)}{h} = \lim_{h \to 0} \frac{(x+h)^2 + (x+h)y + y^2 - (x^2 + xy + y^2)}{h} = \lim_{h \to 0} \frac{2xh + h^2 + hy}{h} = 2x + y\)</span>.</p>
<p><span class="math notranslate nohighlight">\(\frac{\partial f}{\partial y} = \lim_{h \to 0} \frac{f(x, y+h) - f(x, y)}{h} = \lim_{h \to 0} \frac{x^2 + x(y+h) + (y+h)^2 - (x^2 + xy + y^2)}{h} = \lim_{h \to 0} \frac{xh + 2yh + h^2}{h} = x + 2y\)</span>.</p>
<p>Answer and justification E1.2.9: By <em>Taylor’s Theorem</em>, <span class="math notranslate nohighlight">\(f(x) = f(a) + (x - a)f'(a) + \frac{1}{2}(x - a)^2f''(\xi)\)</span> for some <span class="math notranslate nohighlight">\(\xi\)</span> between <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(x\)</span>. Here, <span class="math notranslate nohighlight">\(f(1) = 1^3 - 3 \cdot 1^2 + 2 \cdot 1 = 0\)</span>, <span class="math notranslate nohighlight">\(f'(x) = 3x^2 - 6x + 2\)</span>, so <span class="math notranslate nohighlight">\(f'(1) = 3 - 6 + 2 = -1\)</span>, and <span class="math notranslate nohighlight">\(f''(x) = 6x - 6\)</span>. Therefore,
<span class="math notranslate nohighlight">\(f(x) = 0 + (x - 1)(-1) + \frac{1}{2}(x - 1)^2(6\xi - 6)\)</span> for some <span class="math notranslate nohighlight">\(\xi\)</span> between <span class="math notranslate nohighlight">\(1\)</span> and <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>Answer and justification for E1.2.11: First, compute <span class="math notranslate nohighlight">\(\E[X^2]\)</span></p>
<div class="math notranslate nohighlight">
\[
\E[X^2] = \sum_{x} x^2 \cdot P(X = x) = 1^2 \cdot 0.4 + 2^2 \cdot 0.6 = 0.4 + 4 \cdot 0.6 = 0.4 + 2.4 = 2.8.
\]</div>
<p>Then, use the formula <span class="math notranslate nohighlight">\(\mathrm{Var}[X] = \E[X^2] - (\E[X])^2\)</span></p>
<div class="math notranslate nohighlight">
\[
\mathrm{Var}[X] = 2.8 - (1.6)^2 = 2.8 - 2.56 = 0.24.
\]</div>
<p>Answer and justification for E1.2.13: By <em>Chebyshev’s inequality</em>, <span class="math notranslate nohighlight">\(\P[|X - \mathbb{E}[X]| \geq \alpha] \leq \frac{\mathrm{Var}[X]}{\alpha^2}\)</span> for any <span class="math notranslate nohighlight">\(\alpha &gt; 0\)</span>. Here, <span class="math notranslate nohighlight">\(\alpha = 4\)</span>, so
<span class="math notranslate nohighlight">\(\P[|X - 3| \geq 4] \leq \frac{4}{4^2} = \frac{1}{4}\)</span>.</p>
<p>Answer and justification for E1.2.15: The covariance matrix of <span class="math notranslate nohighlight">\(X\)</span> is <span class="math notranslate nohighlight">\(\begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{pmatrix}\)</span>. Since <span class="math notranslate nohighlight">\(X_1\)</span> and <span class="math notranslate nohighlight">\(X_2\)</span> are independent, their covariance is zero. The variance of each is 1 since they are standard normal.</p>
<p>Answer and justification for E1.2.17: <span class="math notranslate nohighlight">\(\mathbb{E}[AX] = A\mathbb{E}[X] = A\mu_X = \begin{pmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{pmatrix} \begin{pmatrix} 1 \\ 2 \end{pmatrix} = \begin{pmatrix} 5 \\ 11 \end{pmatrix}\)</span>, <span class="math notranslate nohighlight">\(\text{Cov}[AX] = A\text{Cov}[X]A^T = A\Sigma_XA^T = \begin{pmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{pmatrix} \begin{pmatrix} 3 &amp; 1 \\ 1 &amp; 4 \end{pmatrix} \begin{pmatrix} 1 &amp; 3 \\ 2 &amp; 4 \end{pmatrix} = \begin{pmatrix} 11 &amp; 19 \\ 19 &amp; 35 \end{pmatrix}\)</span></p>
<p>Answer and justification for E1.2.19: For any non-zero vector <span class="math notranslate nohighlight">\(z = \begin{pmatrix} z_1 \\ z_2 \end{pmatrix}\)</span>, we have</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
z^TAz &amp;= \begin{pmatrix} z_1 &amp; z_2 \end{pmatrix} \begin{pmatrix} 2 &amp; -1 \\ -1 &amp; 2 \end{pmatrix} \begin{pmatrix} z_1 \\ z_2 \end{pmatrix} \\
&amp;= \begin{pmatrix} z_1 &amp; z_2 \end{pmatrix} \begin{pmatrix} 2z_1 - z_2 \\ -z_1 + 2z_2 \end{pmatrix} \\
&amp;= 2z_1^2 - 2z_1z_2 + 2z_2^2 \\
&amp;= z_1^2 + (z_1 - z_2)^2 + z_2^2 &gt; 0
\end{align*}\]</div>
<p>since <span class="math notranslate nohighlight">\((z_1 - z_2)^2 \geq 0\)</span>, and either <span class="math notranslate nohighlight">\(z_1^2 &gt; 0\)</span> or <span class="math notranslate nohighlight">\(z_2^2 &gt; 0\)</span> (since <span class="math notranslate nohighlight">\(z \neq 0\)</span>). Therefore, <span class="math notranslate nohighlight">\(A\)</span> is positive definite.</p>
<p>Answer and justification for E1.3.1: <span class="math notranslate nohighlight">\(\boldsymbol{\mu}_1^* = \frac{1}{2}(\mathbf{x}_1 + \mathbf{x}_4) = (\frac{3}{2}, 1)\)</span>, <span class="math notranslate nohighlight">\(\boldsymbol{\mu}_2^* = \frac{1}{2}(\mathbf{x}_2 + \mathbf{x}_3) = (-\frac{1}{2}, 0)\)</span>.</p>
<p>Answer and justification for E1.3.3: <span class="math notranslate nohighlight">\(C_1 = \{1, 5\}\)</span>, <span class="math notranslate nohighlight">\(C_2 = \{3\}\)</span>, <span class="math notranslate nohighlight">\(C_3 = \{2, 4\}\)</span>.</p>
<p>Answer and justification for E1.3.5: Expanding the squared norms and cancelling terms yields the equivalent inequality.</p>
<p>Answer and justification for E1.3.7: Expand <span class="math notranslate nohighlight">\(\|A + B\|_F^2 = \sum_{i=1}^n \sum_{j=1}^m (A_{ij} + B_{ij})^2\)</span> and simplify.</p>
<p>Answer and justification for E1.3.9:  <span class="math notranslate nohighlight">\(q(x) = 3(x-1)^2 + 2\)</span>, minimum value is 2 at <span class="math notranslate nohighlight">\(x = 1\)</span>.</p>
<p>Answer and justification for E1.3.11: <span class="math notranslate nohighlight">\(\|A\|_F = \sqrt{14}\)</span>.</p>
<p>Answer and justification for E1.4.1: Since <span class="math notranslate nohighlight">\(X_i\)</span> is uniformly distributed on <span class="math notranslate nohighlight">\([-1/2, 1/2]\)</span>, its probability density function is <span class="math notranslate nohighlight">\(f_{X_i}(x) = 1\)</span> for <span class="math notranslate nohighlight">\(x \in [-1/2, 1/2]\)</span> and 0 otherwise. Therefore,</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}[X_i] = \int_{-1/2}^{1/2} x f_{X_i}(x) dx = \int_{-1/2}^{1/2} x dx = 0\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\text{Var}[X_i] = \mathbb{E}[X_i^2] - (\mathbb{E}[X_i])^2 = \int_{-1/2}^{1/2} x^2 dx = \frac{1}{12}.\]</div>
<p>Answer and justification for E1.4.3: We have</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}[\|X\|^2] = \mathbb{E}\left[\sum_{i=1}^d X_i^2\right] = \sum_{i=1}^d \mathbb{E}[X_i^2] = \sum_{i=1}^d 1 = d.\]</div>
<p>Answer and justification for E1.4.5: By <em>Chebyshev’s inequality</em>, <span class="math notranslate nohighlight">\(P[|X - 1| \geq 3] \leq \frac{\mathrm{Var}[X]}{3^2} = \frac{4}{9}\)</span>.</p>
<p>Answer and justification for E1.4.7: By <em>Chebyshev’s inequality</em>, <span class="math notranslate nohighlight">\(\P[|X| \geq 2\sqrt{d}] \leq \frac{\mathrm{Var}[X]}{(2\sqrt{d})^2} = \frac{1}{4d}\)</span>. For <span class="math notranslate nohighlight">\(d = 1\)</span>, <span class="math notranslate nohighlight">\(\P[|X| \geq 2] \leq \frac{1}{4}\)</span>. For <span class="math notranslate nohighlight">\(d = 10\)</span>, <span class="math notranslate nohighlight">\(P[|X| \geq 2\sqrt{10}] \leq \frac{1}{40}\)</span>. For <span class="math notranslate nohighlight">\(d = 100\)</span>, <span class="math notranslate nohighlight">\(\P[|X| \geq 20] \leq \frac{1}{400}\)</span>.</p>
</section>
<section id="learning-outcomes">
<h3><span class="section-number">1.6.1.5. </span>Learning outcomes<a class="headerlink" href="#learning-outcomes" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Compute norms of vectors and matrices, and inner products between vectors.</p></li>
<li><p>Utilize properties of norms and inner products, including the Cauchy-Schwarz inequality and the triangle inequality.</p></li>
<li><p>Perform basic matrix operations, including addition, scalar multiplication, multiplication, and transposition.</p></li>
<li><p>Compute matrix-vector and matrix-matrix products and interpret their geometric and algebraic significance.</p></li>
<li><p>Explain the concept of a descent direction and its relationship to optimization.</p></li>
<li><p>Use Taylor’s Theorem to approximate functions and analyze the error terms in these approximations.</p></li>
<li><p>Define and compute partial derivatives and gradients for functions of multiple variables.</p></li>
<li><p>State and apply Chebyshev’s inequality to quantify the concentration of a random variable around its mean.</p></li>
<li><p>Compute the expectation, variance, and covariance of random variables and vectors.</p></li>
<li><p>Define and give examples of positive semidefinite matrices.</p></li>
<li><p>Explain the properties and significance of the covariance matrix of a random vector.</p></li>
<li><p>Describe and generate samples from a spherical Gaussian distribution.</p></li>
<li><p>Write Python code to compute norms, inner products, and perform matrix operations.</p></li>
<li><p>Use Python to simulate random variables, calculate their statistical properties, and visualize distributions and the law of large numbers.</p></li>
<li><p>Formulate the k-means clustering problem as an optimization problem.</p></li>
<li><p>Describe the k-means algorithm and its iterative steps for finding cluster centers and assignments.</p></li>
<li><p>Derive the optimal cluster representatives (centroids) for a fixed partition.</p></li>
<li><p>Derive the optimal partition (cluster assignments) for fixed representatives.</p></li>
<li><p>Analyze the convergence properties of the k-means algorithm and understand its limitations in finding global optima.</p></li>
<li><p>Apply the k-means algorithm to real-world datasets, such as the penguins dataset, and interpret the results.</p></li>
<li><p>Express the k-means objective function in matrix form and relate it to matrix factorization.</p></li>
<li><p>Understand the importance of data preprocessing steps like standardization for k-means.</p></li>
<li><p>Recognize the limitations of k-means, such as its sensitivity to initialization and the need to specify the number of clusters in advance.</p></li>
<li><p>Discuss the challenges of determining the optimal number of clusters in k-means clustering.</p></li>
<li><p>Understand the challenges of clustering high-dimensional data using the k-means algorithm and recognize how the increasing dimensionality can cause the noise to overwhelm the signal, making it difficult to distinguish between clusters.</p></li>
<li><p>Comprehend the concept of concentration of measure in high-dimensional spaces, specifically the counterintuitive fact that most of the volume of a high-dimensional cube is concentrated in its corners, making it appear like a “spiky ball.”</p></li>
<li><p>Apply Chebyshev’s inequality to derive the probability that a randomly selected point from a high-dimensional cube falls within the inscribed ball, and understand how this probability decreases as the dimensionality increases.</p></li>
<li><p>Analyze the behavior of the norm of a standard Normal vector in high-dimensional spaces and prove, using Chebyshev’s inequality, that the norm is highly likely to be close to the square root of the dimension, despite the joint probability density function being maximized at the origin.</p></li>
<li><p>Use Chebyshev’s inequality to derive probabilistic bounds in high-dimensional settings.</p></li>
<li><p>Simulate high-dimensional data to empirically verify theoretical results.</p></li>
</ul>
<p><span class="math notranslate nohighlight">\(\aleph\)</span></p>
</section>
</section>
<section id="additional-sections">
<h2><span class="section-number">1.6.2. </span>Additional sections<a class="headerlink" href="#additional-sections" title="Link to this heading">#</a></h2>
<section id="a-more-rigorous-analysis-of-clustering-in-high-dimension">
<h3><span class="section-number">1.6.2.1. </span>A more rigorous analysis of clustering in high dimension<a class="headerlink" href="#a-more-rigorous-analysis-of-clustering-in-high-dimension" title="Link to this heading">#</a></h3>
<p>In this optional section, we give one formal statement of the phenomenon described in the previous subsection.</p>
<p><strong>THEOREM</strong> Let <span class="math notranslate nohighlight">\(\mathbf{X}_1, \mathbf{X}_2, \mathbf{Y}_1\)</span> be independent spherical <span class="math notranslate nohighlight">\(d\)</span>-dimensional Gaussians with mean <span class="math notranslate nohighlight">\(-w_d \mathbf{e}_1\)</span> and variance <span class="math notranslate nohighlight">\(1\)</span>, where <span class="math notranslate nohighlight">\(\{w_d\}\)</span> is a monotone sequence in <span class="math notranslate nohighlight">\(d\)</span>. Let <span class="math notranslate nohighlight">\(\mathbf{Y}_2\)</span> be an indepedent spherical <span class="math notranslate nohighlight">\(d\)</span>-dimensional Gaussian with mean <span class="math notranslate nohighlight">\(w_d \mathbf{e}_1\)</span> and variance <span class="math notranslate nohighlight">\(1\)</span>. Then, letting <span class="math notranslate nohighlight">\(\Delta_d = \|\mathbf{Y}_1 - \mathbf{Y}_2\|^2 - \|\mathbf{X}_1 - \mathbf{X}_2\|^2\)</span>, as <span class="math notranslate nohighlight">\(d \to +\infty\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\frac{\mathbb{E}[\Delta_d]}{\sqrt{\mathrm{Var}[\Delta_d]}} \to
\begin{cases}
0, &amp; \text{if $w_d \ll d^{1/4}$}\\
+\infty, &amp; \text{if $w_d \gg d^{1/4}$}
\end{cases}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(w_d \ll d^{1/4}\)</span> means <span class="math notranslate nohighlight">\(w_d/d^{1/4} \to 0\)</span>. <span class="math notranslate nohighlight">\(\sharp\)</span></p>
<p>The ratio is the statement is referred to as the <a class="reference external" href="https://en.wikipedia.org/wiki/Signal-to-noise_ratio">signal-to-noise ratio</a>.</p>
<p>To prove the claim, we will need the following property.</p>
<p><strong>LEMMA</strong> Let <span class="math notranslate nohighlight">\(W\)</span> be a real-valued random variable symmetric about zero, that is, such that <span class="math notranslate nohighlight">\(W\)</span> and <span class="math notranslate nohighlight">\(-W\)</span> are identically distributed. Then for all odd <span class="math notranslate nohighlight">\(k\)</span>, <span class="math notranslate nohighlight">\(\mathbb{E}[W^k] = 0\)</span>. <span class="math notranslate nohighlight">\(\flat\)</span></p>
<p><em>Proof:</em> By the symmetry,</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}[W^k] = \mathbb{E}[(-W)^k] = \mathbb{E}[(-1)^k W^k] = - \mathbb{E}[W^k].
\]</div>
<p>The only way to satisfy this equation is to have <span class="math notranslate nohighlight">\(\mathbb{E}[W^k] = 0\)</span>. <span class="math notranslate nohighlight">\(\square\)</span></p>
<p>Returning to the proof of the claim:</p>
<p><em>Proof idea:</em> <em>(Theorem)</em> The only coordinate contributing to <span class="math notranslate nohighlight">\(\mathbb{E}[\Delta_d]\)</span> is the first one by linearity of expectation, while all coordinates contribute to <span class="math notranslate nohighlight">\(\mathrm{Var}[\Delta_d]\)</span>. More specifically, a calculation shows that the former is <span class="math notranslate nohighlight">\(c_0 w^2\)</span> while the latter is <span class="math notranslate nohighlight">\(c_1 w^2 + c_2 d\)</span>, where <span class="math notranslate nohighlight">\(c_0, c_1, c_2\)</span> are constants.</p>
<p><em>Proof:</em> <em>(Claim)</em> Write <span class="math notranslate nohighlight">\(w := w_d\)</span> and <span class="math notranslate nohighlight">\(\Delta := \Delta_d\)</span> to simplify the notation. There are two steps:</p>
<p><em>(1) Expectation of <span class="math notranslate nohighlight">\(\Delta\)</span>:</em> By defintion, the random variables <span class="math notranslate nohighlight">\(X_{1,i} - X_{2,i}\)</span>, <span class="math notranslate nohighlight">\(i = 1,\ldots, d\)</span>, and <span class="math notranslate nohighlight">\(Y_{1,i} - Y_{2,i}\)</span>, <span class="math notranslate nohighlight">\(i = 2,\ldots, d\)</span>, are identically distributed. So, by linearity of expectation,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\mathbb{E}[\Delta]
&amp;= \sum_{i=1}^d \mathbb{E}[(Y_{1,i} - Y_{2,i})^2] - \sum_{i=1}^d \mathbb{E}[(X_{1,i} - X_{2,i})^2]\\
&amp;= \mathbb{E}[(Y_{1,1} - Y_{2,1})^2] - \mathbb{E}[(X_{1,1} - X_{2,1})^2].
\end{align*}\]</div>
<p>Further, we can write <span class="math notranslate nohighlight">\(Y_{1,1} - Y_{1,2} \sim (Z_1 -w) - (Z_2+w)\)</span> where <span class="math notranslate nohighlight">\(Z_1, Z_2 \sim N(0,1)\)</span> are independent, where here <span class="math notranslate nohighlight">\(\sim\)</span> indicates equality in distribution. Hence, we have</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\mathbb{E}[(Y_{1,1} - Y_{2,1})^2]
&amp;= \mathbb{E}[(Z_1 - Z_2 - 2w)^2]\\
&amp;= \mathbb{E}[(Z_1 - Z_2)^2] 
- 4w \,\mathbb{E}[Z_1 - Z_2]
+ 4 w^2.
\end{align*}\]</div>
<p>Similarly, <span class="math notranslate nohighlight">\(X_{1,1} - X_{1,2} \sim Z_1 - Z_2\)</span> so <span class="math notranslate nohighlight">\(\mathbb{E}[(X_{1,1} - X_{2,1})^2] = \mathbb{E}[(Z_1 - Z_2)^2]\)</span>. Since <span class="math notranslate nohighlight">\(\mathbb{E}[Z_1 - Z_2] = 0\)</span>, we finally get <span class="math notranslate nohighlight">\(\mathbb{E}[\Delta] = 4 w^2\)</span>.</p>
<p><em>(2) Variance of <span class="math notranslate nohighlight">\(\Delta\)</span>:</em> Using the observations from (1) and the independence of the coordinates we get</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\mathrm{Var}[\Delta]
&amp;= \sum_{i=1}^d \mathrm{Var}[(Y_{1,i} - Y_{2,i})^2] + \sum_{i=1}^d \mathrm{Var}[(X_{1,i} - X_{2,i})^2]\\
&amp;= \mathrm{Var}[(Z_1 - Z_2 - 2w)^2] 
+ (2d-1) \,\mathrm{Var}[(Z_1 - Z_2)^2].
\end{align*}\]</div>
<p>By the <em>Variance of a Sum</em>,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\mathrm{Var}[(Z_1 - Z_2 - 2w)^2]
&amp;= \mathrm{Var}[(Z_1 - Z_2)^2 - 4w(Z_1 - Z_2) + 4w^2]\\ 
&amp;= \mathrm{Var}[(Z_1 - Z_2)^2 - 4w(Z_1 - Z_2)]\\
&amp;= \mathrm{Var}[(Z_1 - Z_2)^2] 
+ 16 w^2 \mathrm{Var}[Z_1 - Z_2]\\
&amp;\quad - 8w \,\mathrm{Cov}[(Z_1 - Z_2)^2, Z_1 - Z_2].
\end{align*}\]</div>
<p>Because <span class="math notranslate nohighlight">\(Z_1\)</span> and <span class="math notranslate nohighlight">\(Z_2\)</span> are independent, <span class="math notranslate nohighlight">\(\mathrm{Var}[Z_1 - Z_2]
= \mathrm{Var}[Z_1] + \mathrm{Var}[Z_2] = 2\)</span>. Moreover, the random variable <span class="math notranslate nohighlight">\((Z_1 - Z_2)\)</span> is symmetric, so</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\mathrm{Cov}[(Z_1 - Z_2)^2, Z_1 - Z_2]
&amp;= \mathbb{E}[(Z_1 - Z_2)^3]\\ 
&amp; \quad - \mathbb{E}[(Z_1 - Z_2)^2] \,\mathbb{E}[Z_1 - Z_2]\\
&amp;= 0.
\end{align*}\]</div>
<p>Finally,</p>
<div class="math notranslate nohighlight">
\[
\mathrm{Var}[\Delta]
= 32 w^2 
+ 2d \,\mathrm{Var}[(Z_1 - Z_2)^2]
\]</div>
<p><em>Putting everything together:</em></p>
<div class="math notranslate nohighlight">
\[
\frac{\mathbb{E}[\Delta]}{\sqrt{\mathrm{Var}[\Delta]}}
=
\frac{4 w^2}{\sqrt{32 w^2 
+ 2d \,\mathrm{Var}[(Z_1 - Z_2)^2]}}.
\]</div>
<p>Taking <span class="math notranslate nohighlight">\(d \to +\infty\)</span> gives the claim. <span class="math notranslate nohighlight">\(\square\)</span></p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chap01_intro/supp"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../exercises/roch-mmids-intro-exercises.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">1.5. </span>Exercises</p>
      </div>
    </a>
    <a class="right-next"
       href="../../chap02_ls/00_intro/roch-mmids-ls-intro.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">2. </span>Least squares: geometric, algebraic, and numerical aspects</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quizzes-solutions-code-etc">1.6.1. Quizzes, solutions, code, etc.</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#just-the-code">1.6.1.1. Just the code</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#self-assessment-quizzes">1.6.1.2. Self-assessment quizzes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#auto-quizzes">1.6.1.3. Auto-quizzes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#solutions-to-odd-numbered-warm-up-exercises">1.6.1.4. Solutions to odd-numbered warm-up exercises</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-outcomes">1.6.1.5. Learning outcomes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-sections">1.6.2. Additional sections</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-more-rigorous-analysis-of-clustering-in-high-dimension">1.6.2.1. A more rigorous analysis of clustering in high dimension</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Sebastien Roch
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>