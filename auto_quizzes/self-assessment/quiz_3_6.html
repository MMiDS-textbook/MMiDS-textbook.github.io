<!DOCTYPE html>
<html>
<head>
    <title>Self-Assessment Questions for Section 3.6</title>
    <style>
        .question {
            margin-bottom: 20px;
        }
        .options {
            list-style-type: none;
            padding: 0;
        }
        .options li {
            margin-bottom: 10px;
        }
        .feedback {
            margin-top: 10px;
            font-weight: bold;
        }
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <h1>Self-Assessment Questions for Section 3.6</h1>

    <p>Before moving on, you may wish to quickly test your knowledge by going over the following review questions.</p>

    <div id="quiz-container">
        <div class="question">
            <p>What is the primary goal of logistic regression?</p>
            <ul class="options">
                <li><label><input type="radio" name="q0" value="0"> a) To predict a continuous outcome variable.</label></li>
                <li><label><input type="radio" name="q0" value="1"> b) To classify data points into multiple categories.</label></li>
                <li><label><input type="radio" name="q0" value="2"> c) To model the probability of a binary outcome.</label></li>
                <li><label><input type="radio" name="q0" value="3"> d) To find the optimal linear combination of features.</label></li>
            </ul>
            <div class="feedback" id="feedback0"></div>
        </div>

        <div class="question">
            <p>Which loss function is commonly used in logistic regression?</p>
            <ul class="options">
                <li><label><input type="radio" name="q1" value="0"> a) Mean squared error</label></li>
                <li><label><input type="radio" name="q1" value="1"> b) Mean absolute error</label></li>
                <li><label><input type="radio" name="q1" value="2"> c) Hinge loss</label></li>
                <li><label><input type="radio" name="q1" value="3"> d) Cross-entropy loss</label></li>
            </ul>
            <div class="feedback" id="feedback1"></div>
        </div>

        <div class="question">
            <p>What is the relationship between maximizing the likelihood function and minimizing the cross-entropy loss in logistic regression?</p>
            <ul class="options">
                <li><label><input type="radio" name="q2" value="0"> a) They are unrelated concepts.</label></li>
                <li><label><input type="radio" name="q2" value="1"> b) Maximizing the likelihood is equivalent to minimizing the cross-entropy loss.</label></li>
                <li><label><input type="radio" name="q2" value="2"> c) Minimizing the cross-entropy loss is a first step towards maximizing the likelihood.</label></li>
                <li><label><input type="radio" name="q2" value="3"> d) Maximizing the likelihood is a special case of minimizing the cross-entropy loss.</label></li>
            </ul>
            <div class="feedback" id="feedback2"></div>
        </div>

        <div class="question">
            <p>Which of the following is the correct expression for the sigmoid function, denoted by \( \sigma(z) \) in the text?</p>
            <ul class="options">
                <li><label><input type="radio" name="q3" value="0"> a) \( \sigma(z) = \frac{1}{1 + e^z} \)</label></li>
                <li><label><input type="radio" name="q3" value="1"> b) \( \sigma(z) = \frac{e^z}{1 + e^z} \)</label></li>
                <li><label><input type="radio" name="q3" value="2"> c) \( \sigma(z) = \frac{1}{1 - e^{-z}} \)</label></li>
                <li><label><input type="radio" name="q3" value="3"> d) \( \sigma(z) = \frac{1}{1 + e^{-z}} \)</label></li>
            </ul>
            <div class="feedback" id="feedback3"></div>
        </div>

        <div class="question">
            <p>Which of the following is the correct formula for the logistic regression objective function (cross-entropy loss)?</p>
            <ul class="options">
                <li><label><input type="radio" name="q4" value="0"> a) \( \ell(x; A, b) = \frac{1}{n} \sum_{i=1}^n \log(1 + \exp(-b_i \alpha_i^T x)) \)</label></li>
                <li><label><input type="radio" name="q4" value="1"> b) \( \ell(x; A, b) = \frac{1}{n} \sum_{i=1}^n (b_i - \sigma(\alpha_i^T x))^2 \)</label></li>
                <li><label><input type="radio" name="q4" value="2"> c) \( \ell(x; A, b) = \frac{1}{n} \sum_{i=1}^n \{-b_i \log(\sigma(\alpha_i^T x)) - (1 - b_i) \log(1 - \sigma(\alpha_i^T x))\} \)</label></li>
                <li><label><input type="radio" name="q4" value="3"> d) \( \ell(x; A, b) = \frac{1}{n} \sum_{i=1}^n b_i \alpha_i^T x \)</label></li>
            </ul>
            <div class="feedback" id="feedback4"></div>
        </div>

        <div class="question">
            <p>Which of the following is the correct gradient of the logistic regression objective function?</p>
            <ul class="options">
                <li><label><input type="radio" name="q5" value="0"> a) \( \nabla \ell(x; A, b) = -\frac{1}{n} \sum_{i=1}^n (b_i - \sigma(\alpha_i^T x)) \alpha_i \)</label></li>
                <li><label><input type="radio" name="q5" value="1"> b) \( \nabla \ell(x; A, b) = -\frac{1}{n} \sum_{i=1}^n b_i \alpha_i \)</label></li>
                <li><label><input type="radio" name="q5" value="2"> c) \( \nabla \ell(x; A, b) = -\frac{1}{n} \sum_{i=1}^n \sigma(\alpha_i^T x) \alpha_i \)</label></li>
                <li><label><input type="radio" name="q5" value="3"> d) \( \nabla \ell(x; A, b) = -\frac{1}{n} \sum_{i=1}^n (1 - b_i) \alpha_i \)</label></li>
            </ul>
            <div class="feedback" id="feedback5"></div>
        </div>

        <div class="question">
            <p>What is the purpose of standardizing the input features in the airline customer satisfaction dataset example?</p>
            <ul class="options">
                <li><label><input type="radio" name="q6" value="0"> a) To ensure the objective function is convex.</label></li>
                <li><label><input type="radio" name="q6" value="1"> b) To speed up the convergence of gradient descent.</label></li>
                <li><label><input type="radio" name="q6" value="2"> c) To allow comparison of the influence of different features on the prediction.</label></li>
                <li><label><input type="radio" name="q6" value="3"> d) To handle missing data in the dataset.</label></li>
            </ul>
            <div class="feedback" id="feedback6"></div>
        </div>

        <div class="question">
            <p>Which of the following is true about the convergence of gradient descent for logistic regression?</p>
            <ul class="options">
                <li><label><input type="radio" name="q7" value="0"> a) Gradient descent is guaranteed to converge to the global minimum of the objective function.</label></li>
                <li><label><input type="radio" name="q7" value="1"> b) Gradient descent may converge to a local minimum of the objective function.</label></li>
                <li><label><input type="radio" name="q7" value="2"> c) Gradient descent may not converge at all.</label></li>
                <li><label><input type="radio" name="q7" value="3"> d) The convergence of gradient descent depends on the choice of the initial point.</label></li>
            </ul>
            <div class="feedback" id="feedback7"></div>
        </div>

        <div class="question">
            <p>Which of the following is a valid reason for adding a column of 1's to the feature matrix in logistic regression?</p>
            <ul class="options">
                <li><label><input type="radio" name="q8" value="0"> a) To ensure the objective function is convex.</label></li>
                <li><label><input type="radio" name="q8" value="1"> b) To allow for an intercept term in the model.</label></li>
                <li><label><input type="radio" name="q8" value="2"> c) To standardize the input features.</label></li>
                <li><label><input type="radio" name="q8" value="3"> d) To handle missing data in the dataset.</label></li>
            </ul>
            <div class="feedback" id="feedback8"></div>
        </div>
    </div>

    <script>
        document.querySelectorAll('.options').forEach((optionsList, index) => {
            const correctOptions = [2, 3, 1, 3, 2, 0, 2, 0, 1];

            optionsList.addEventListener('change', (event) => {
                const selectedOption = parseInt(event.target.value);
                const feedbackDiv = document.getElementById('feedback' + index);
                let feedbackText = '';

                if (selectedOption === correctOptions[index]) {
                    feedbackText = "Excellent! " + getCorrectFeedback(index);
                } else {
                    feedbackText = "Try again.";
                }

                feedbackDiv.innerHTML = feedbackText;
                feedbackDiv.style.color = selectedOption === correctOptions[index] ? 'green' : 'red';

                MathJax.typesetPromise([feedbackDiv]); 
            });
        });

        function getCorrectFeedback(index) {
            switch (index) {
                case 0:
                    return "The text states that the goal of logistic regression is to 'find a function of the features that approximates the probability of the label.'";
                case 1:
                    return "The text refers to the 'cross-entropy loss' as the function to be minimized in logistic regression.";
                case 2:
                    return "The text states: 'We seek to maximize the probability of observing the data... which is given by... Taking a logarithm, multiplying by -1/n and substituting the sigmoid function, we want to minimize the cross-entropy loss.'";
                case 3:
                    return "The text defines the sigmoid function as \\(\\sigma(z) = \\frac{1}{1 + e^{-z}}\\).";
                case 4:
                    return "The text states: 'Hence, we want to solve the minimization problem \\(\\min_{x \\in \\mathbb{R}^d} \\ell(x; A, b)\\),' where \\(\\ell(x; A, b) = \\frac{1}{n} \\sum_{i=1}^n \\{-b_i \\log(\\sigma(\\alpha_i^T x)) - (1 - b_i) \\log(1 - \\sigma(\\alpha_i^T x))\\}\\).";
                case 5:
                    return "The text derives the gradient as: \\(\\nabla \\ell(x; A, b) = -\\frac{1}{n} \\sum_{i=1}^n (b_i - \\sigma(\\alpha_i^T x)) \\alpha_i\\).";
                case 6:
                    return "The text states: 'We also standardize the columns by subtracting their mean and dividing by their standard deviation. This will allow to compare the influence of different features on the prediction.'";
                case 7:
                    return "Since the logistic regression objective function is convex (as proven in Lemma 1), gradient descent is guaranteed to converge to the global minimum, regardless of the initial point.";
                case 8:
                    return "The text states: 'To allow an affine function of the features, we add a column of 1's as we have done before.'";
                default:
                    return "";
            }
        }
    </script>
</body>
</html>
